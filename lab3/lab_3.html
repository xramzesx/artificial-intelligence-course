<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>lab_3</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0px solid transparent;
  border-right: 0px solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0px solid transparent;
  border-bottom: 0px solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
	border:1px solid transparent;
  background-color: transparent;
  position: absolute;
	z-index:1;
	right:3%;
	top: 0;
	bottom: 0;
	margin: auto;
	padding: 7px 0;
	display: none;
	vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
	content: "X";
	display: block;
	width: 15px;
	height: 15px;
	text-align: center;
	color:#000;
	font-weight: normal;
	font-size: 12px;
	cursor: pointer;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
  background: inherit;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-bottom:10px;
  margin-top:0; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  font-size:36px;
  line-height:40px; }

h2.bp3-heading, .bp3-running-text h2{
  font-size:28px;
  line-height:32px; }

h3.bp3-heading, .bp3-running-text h3{
  font-size:22px;
  line-height:25px; }

h4.bp3-heading, .bp3-running-text h4{
  font-size:18px;
  line-height:21px; }

h5.bp3-heading, .bp3-running-text h5{
  font-size:16px;
  line-height:19px; }

h6.bp3-heading, .bp3-running-text h6{
  font-size:14px;
  line-height:16px; }
.bp3-ui-text{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none; }

.bp3-monospace-text{
  font-family:monospace;
  text-transform:none; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  font-size:14px;
  line-height:1.5; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15);
    margin:20px 0; }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  color:#106ba3;
  text-decoration:none; }
  a:hover{
    color:#106ba3;
    cursor:pointer;
    text-decoration:underline; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  font-size:smaller;
  padding:2px 5px; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  color:#182026;
  display:block;
  font-size:13px;
  line-height:1.4;
  margin:10px 0;
  padding:13px 15px 12px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit;
    font-size:inherit;
    padding:0; }

.bp3-running-text kbd, .bp3-key{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-family:inherit;
  font-size:12px;
  height:24px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  line-height:24px;
  min-width:24px;
  padding:3px 6px;
  vertical-align:middle; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  margin:0 0 10px;
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    font-size:40px;
    margin-right:20px;
    margin-top:0; }

.bp3-alert-contents{
  word-break:break-word; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  cursor:default;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  height:30px;
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-breadcrumbs > li{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }
    .bp3-breadcrumbs > li::after{
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 00-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      content:"";
      display:block;
      height:16px;
      margin:0 5px;
      width:16px; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    font-size:inherit;
    font-weight:inherit;
    vertical-align:baseline; }

.bp3-breadcrumbs-collapsed{
  background:#ced9e0;
  border:none;
  border-radius:3px;
  cursor:pointer;
  margin-right:2px;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    content:"";
    display:block;
    height:16px;
    width:16px; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    color:#182026;
    text-decoration:none; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  min-height:30px;
  min-width:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      background-color:#106ba3;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      background-color:#0e5a8a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      background-color:#0d8050;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      background-color:#0a6640;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      background-color:#bf7326;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      background-color:#a66321;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      background-color:#c23030;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      background-color:#a82a2a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-height:40px;
    min-width:40px;
    font-size:16px;
    padding:5px 15px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      margin:0;
      position:absolute; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button.bp3-minimal:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button.bp3-outlined{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    border:1px solid rgba(24, 32, 38, 0.2);
    -webkit-box-sizing:border-box;
            box-sizing:border-box; }
    .bp3-button.bp3-outlined:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-outlined:active, .bp3-button.bp3-outlined.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-outlined{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-outlined:hover, .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-outlined:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover, .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover, .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover, .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover, .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled:hover{
      border-color:rgba(92, 112, 128, 0.1); }
    .bp3-dark .bp3-button.bp3-outlined{
      border-color:rgba(255, 255, 255, 0.4); }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        border-color:rgba(255, 255, 255, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      border-color:rgba(16, 107, 163, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        border-color:rgba(16, 107, 163, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        border-color:rgba(72, 175, 240, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          border-color:rgba(72, 175, 240, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      border-color:rgba(13, 128, 80, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        border-color:rgba(13, 128, 80, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        border-color:rgba(61, 204, 145, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          border-color:rgba(61, 204, 145, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      border-color:rgba(191, 115, 38, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        border-color:rgba(191, 115, 38, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        border-color:rgba(255, 179, 102, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          border-color:rgba(255, 179, 102, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      border-color:rgba(194, 48, 48, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        border-color:rgba(194, 48, 48, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        border-color:rgba(255, 115, 115, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          border-color:rgba(255, 115, 115, 0.2); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    border-bottom-right-radius:0;
    border-top-right-radius:0;
    margin-right:-1px; }
  .bp3-button-group.bp3-minimal .bp3-button{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      height:100%;
      width:unset; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  font-size:14px;
  line-height:1.5;
  background-color:rgba(138, 155, 168, 0.15);
  border-radius:3px;
  padding:10px 12px 9px;
  position:relative;
  width:100%; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout .bp3-heading{
    line-height:20px;
    margin-bottom:5px;
    margin-top:0; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  opacity:0.9;
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  width:100%; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }

.bp3-dialog{
  background:#ebf1f5;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text;
  width:500px; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    background:#293742;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-dialog-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding-left:20px;
  padding-right:5px;
  z-index:30; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    background:#30404d;
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  margin:20px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-multistep-dialog-panels{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }

.bp3-multistep-dialog-left-panel{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:1;
      -ms-flex:1;
          flex:1;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column; }
  .bp3-dark .bp3-multistep-dialog-left-panel{
    background:#202b33; }

.bp3-multistep-dialog-right-panel{
  background-color:#f5f8fa;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  border-radius:0 0 6px 0;
  -webkit-box-flex:3;
      -ms-flex:3;
          flex:3;
  min-width:0; }
  .bp3-dark .bp3-multistep-dialog-right-panel{
    background-color:#293742;
    border-left:1px solid rgba(16, 22, 26, 0.4); }

.bp3-multistep-dialog-footer{
  background-color:#ffffff;
  border-radius:0 0 6px 0;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  padding:10px; }
  .bp3-dark .bp3-multistep-dialog-footer{
    background:#30404d;
    border-top:1px solid rgba(16, 22, 26, 0.4); }

.bp3-dialog-step-container{
  background-color:#f5f8fa;
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-dialog-step-container{
    background:#293742;
    border-bottom:1px solid rgba(16, 22, 26, 0.4); }
  .bp3-dialog-step-container.bp3-dialog-step-viewed{
    background-color:#ffffff; }
    .bp3-dark .bp3-dialog-step-container.bp3-dialog-step-viewed{
      background:#30404d; }

.bp3-dialog-step{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#f5f8fa;
  border-radius:6px;
  cursor:not-allowed;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:4px;
  padding:6px 14px; }
  .bp3-dark .bp3-dialog-step{
    background:#293742; }
  .bp3-dialog-step-viewed .bp3-dialog-step{
    background-color:#ffffff;
    cursor:pointer; }
    .bp3-dark .bp3-dialog-step-viewed .bp3-dialog-step{
      background:#30404d; }
  .bp3-dialog-step:hover{
    background-color:#f5f8fa; }
    .bp3-dark .bp3-dialog-step:hover{
      background:#293742; }

.bp3-dialog-step-icon{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:rgba(92, 112, 128, 0.6);
  border-radius:50%;
  color:#ffffff;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:25px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:25px; }
  .bp3-dark .bp3-dialog-step-icon{
    background-color:rgba(167, 182, 194, 0.6); }
  .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-icon{
    background-color:#2b95d6; }
  .bp3-dialog-step-viewed .bp3-dialog-step-icon{
    background-color:#8a9ba8; }

.bp3-dialog-step-title{
  color:rgba(92, 112, 128, 0.6);
  -webkit-box-flex:1;
      -ms-flex:1;
          flex:1;
  padding-left:10px; }
  .bp3-dark .bp3-dialog-step-title{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-title{
    color:#2b95d6; }
  .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{
    color:#182026; }
    .bp3-dark .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{
      color:#f5f8fa; }
.bp3-drawer{
  background:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    height:50%;
    left:0;
    right:0;
    top:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-bottom{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-left{
    bottom:0;
    left:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-right{
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    background:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-drawer-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding:5px;
  padding-left:20px;
  position:relative; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  overflow:auto; }

.bp3-drawer-footer{
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  padding:10px 20px;
  position:relative; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  cursor:text;
  display:inline-block;
  max-width:100%;
  position:relative;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    bottom:-3px;
    left:-3px;
    position:absolute;
    right:-3px;
    top:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  color:inherit;
  display:inherit;
  font:inherit;
  letter-spacing:inherit;
  max-width:inherit;
  min-width:inherit;
  position:relative;
  resize:none;
  text-transform:inherit;
  vertical-align:top; }

.bp3-editable-text-input{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0;
  white-space:pre-wrap;
  width:100%; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    left:0;
    position:absolute;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    border-radius:inherit;
    z-index:2; }
    .bp3-control-group .bp3-input:focus{
      border-radius:3px;
      z-index:14; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    border-radius:inherit;
    z-index:4; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-left-container,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group .bp3-select:focus-within{
    z-index:5; }
  .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:-1px; }
  .bp3-control-group:not(.bp3-vertical) > .bp3-divider:not(:first-child){
    margin-left:6px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    border-radius:0 3px 3px 0;
    margin-right:0; }
  .bp3-control-group > :only-child{
    border-radius:3px;
    margin-right:0; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group .bp3-numeric-input:not(:first-child) .bp3-input-group{
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-control-group.bp3-fill{
    width:100%; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      border-radius:3px 3px 0 0;
      margin-top:0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  cursor:pointer;
  display:block;
  margin-bottom:10px;
  position:relative;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    left:0;
    opacity:0;
    position:absolute;
    top:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    cursor:pointer;
    display:inline-block;
    font-size:16px;
    height:1em;
    margin-right:10px;
    margin-top:-3px;
    position:relative;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none;
    vertical-align:middle;
    width:1em; }
    .bp3-control .bp3-control-indicator::before{
      content:"";
      display:block;
      height:1em;
      width:1em; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    background:#d8e1e8;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-left:10px;
    margin-top:1px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 00-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0012 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:auto; }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      background:#ffffff;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      height:calc(1em - 4px);
      left:0;
      margin:2px;
      position:absolute;
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      width:calc(1em - 4px); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    font-size:0.7em;
    text-align:center; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    line-height:0;
    margin-left:0.5em;
    margin-right:1.2em;
    visibility:hidden; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    line-height:1em;
    margin-left:1.2em;
    margin-right:0.5em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    line-height:1em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    line-height:0;
    visibility:hidden; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      background:#202b33;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  cursor:pointer;
  display:inline-block;
  height:30px;
  position:relative; }
  .bp3-file-input input{
    margin:0;
    min-width:200px;
    opacity:0; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      background:rgba(206, 217, 224, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(92, 112, 128, 0.6);
        cursor:not-allowed;
        outline:none; }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        background:rgba(57, 75, 89, 0.5);
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          -webkit-box-shadow:none;
                  box-shadow:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:rgba(92, 112, 128, 0.6);
  left:0;
  padding-right:80px;
  position:absolute;
  right:0;
  top:0;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-file-upload-input::after{
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026;
    min-height:24px;
    min-width:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    border-radius:3px;
    content:"Browse";
    line-height:24px;
    margin:3px;
    position:absolute;
    right:0;
    text-align:center;
    top:0;
    width:70px; }
    .bp3-file-upload-input::after:hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-file-upload-input:active::after{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-large .bp3-file-upload-input{
    font-size:16px;
    height:40px;
    line-height:40px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-height:30px;
      min-width:30px;
      line-height:30px;
      margin:5px;
      width:85px; }
  .bp3-dark .bp3-file-upload-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        background-color:#30404d;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        background-color:#202b33;
        background-image:none;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:active::after{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    color:#5c7080;
    font-size:12px;
    margin-top:5px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      line-height:40px;
      margin:0 10px 0 0; }
    .bp3-form-group.bp3-inline label.bp3-label{
      line-height:30px;
      margin:0 10px 0 0; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-input-left-container:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-input-left-container:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-height:24px;
    min-width:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-icon{
    z-index:1; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon{
    color:#5c7080; }
    .bp3-input-group > .bp3-input-left-container > .bp3-icon:empty,
    .bp3-input-group > .bp3-icon:empty{
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-height:30px;
    min-width:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle; }
  .bp3-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-input.bp3-large{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-bottom:15px;
  margin-top:0; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    font-weight:400;
    vertical-align:top;
    width:100%; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  min-height:0;
  padding:0;
  width:30px; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  -moz-appearance:none;
  -webkit-appearance:none;
  border-radius:3px;
  height:30px;
  padding:0 25px 0 10px;
  width:100%; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  background:none;
  -webkit-box-shadow:none;
          box-shadow:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    background:rgba(167, 182, 194, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026;
    text-decoration:none; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    background:rgba(115, 134, 148, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      color:rgba(167, 182, 194, 0.6);
      cursor:not-allowed; }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  font-size:16px;
  height:40px;
  padding-right:35px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    background-color:#202b33;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  background-color:rgba(206, 217, 224, 0.5);
  -webkit-box-shadow:none;
          box-shadow:none;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  color:#5c7080;
  pointer-events:none;
  position:absolute;
  right:7px;
  top:7px; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  letter-spacing:normal;
  position:relative;
  vertical-align:middle; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    right:12px;
    top:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select option:disabled, .bp3-dark
  .bp3-select option:disabled{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    text-align:left;
    vertical-align:top; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td,
  .bp3-running-text table tfoot tr:first-child th,
  table.bp3-html-table tfoot tr:first-child th,
  .bp3-running-text table tfoot tr:first-child td,
  table.bp3-html-table tfoot tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td,
  .bp3-dark .bp3-running-text table tfoot tr:first-child th,
  .bp3-running-text .bp3-dark table tfoot tr:first-child th,
  .bp3-dark table.bp3-html-table tfoot tr:first-child th,
  .bp3-dark .bp3-running-text table tfoot tr:first-child td,
  .bp3-running-text .bp3-dark table tfoot tr:first-child td,
  .bp3-dark table.bp3-html-table tfoot tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-bottom:6px;
  padding-top:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td,
table.bp3-html-table.bp3-html-table-bordered tfoot tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),
  table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table{ }
  .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
    background:rgba(92, 112, 128, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td,
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){
      -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
              box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
    background-color:rgba(92, 112, 128, 0.3);
    cursor:pointer; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
    background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  padding-bottom:0;
  top:40px; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-left:0;
  margin-right:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  font-family:"Icons20";
  font-size:inherit;
  font-style:normal;
  font-weight:400;
  line-height:1; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagnosis::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-lab-test::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }
  .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{ }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  background:#ffffff;
  border-radius:3px;
  color:#182026;
  list-style:none;
  margin:0;
  min-width:180px;
  padding:5px;
  text-align:left; }

.bp3-menu-divider{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px; }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  color:inherit;
  line-height:20px;
  padding:5px 7px;
  text-decoration:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    color:#5c7080;
    margin-top:2px; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit !important;
    color:rgba(92, 112, 128, 0.6) !important;
    cursor:not-allowed !important;
    outline:none !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    font-size:16px;
    line-height:22px;
    padding:9px 7px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-right:10px;
      margin-top:1px; }

button.bp3-menu-item{
  background:none;
  border:none;
  text-align:left;
  width:100%; }
.bp3-menu-header{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px;
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    line-height:17px;
    margin:0;
    padding:10px 7px 0 1px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    font-size:18px;
    padding-bottom:5px;
    padding-top:15px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item{ }
  .bp3-dark .bp3-menu-item.bp3-intent-primary{
    color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-success{
    color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning{
    color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger{
    color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item::before,
  .bp3-dark .bp3-menu-item > .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item .bp3-menu-item-label{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
    background-color:rgba(138, 155, 168, 0.3); }
  .bp3-dark .bp3-menu-item.bp3-disabled{
    color:rgba(167, 182, 194, 0.6) !important; }
    .bp3-dark .bp3-menu-item.bp3-disabled::before,
    .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  background-color:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  height:50px;
  padding:0 15px;
  position:relative;
  width:100%;
  z-index:10; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    left:0;
    position:fixed;
    right:0;
    top:0; }

.bp3-navbar-heading{
  font-size:16px;
  margin-right:15px; }

.bp3-navbar-group{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px;
  margin:0 10px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:100%;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  text-align:center;
  width:100%; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  bottom:0;
  left:0;
  position:static;
  right:0;
  top:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    overflow:hidden;
    position:fixed; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    overflow:auto;
    position:fixed; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  bottom:0;
  left:0;
  position:fixed;
  right:0;
  top:0;
  opacity:1;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  z-index:20; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }
  .bp3-panel-stack-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-panel-stack2{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack2-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack2-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack2-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack2-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack2-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack2-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack2-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack2-view{
    background-color:#30404d; }
  .bp3-panel-stack2-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack2-push .bp3-panel-stack2-enter, .bp3-panel-stack2-push .bp3-panel-stack2-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack2-push .bp3-panel-stack2-enter-active, .bp3-panel-stack2-push .bp3-panel-stack2-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-push .bp3-panel-stack2-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack2-push .bp3-panel-stack2-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-pop .bp3-panel-stack2-enter, .bp3-panel-stack2-pop .bp3-panel-stack2-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack2-pop .bp3-panel-stack2-enter-active, .bp3-panel-stack2-pop .bp3-panel-stack2-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-pop .bp3-panel-stack2-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack2-pop .bp3-panel-stack2-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  border-radius:3px;
  display:inline-block;
  z-index:20; }
  .bp3-popover .bp3-popover-arrow{
    height:30px;
    position:absolute;
    width:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      height:20px;
      margin:5px;
      width:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-bottom:17px;
    margin-top:-17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-left:-17px;
    margin-right:17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover .bp3-popover-content{
    border-radius:3px;
    position:relative; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  border-radius:2px;
  content:"";
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg); }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  left:0;
  position:absolute;
  right:0;
  top:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  background:rgba(92, 112, 128, 0.2);
  border-radius:40px;
  display:block;
  height:8px;
  overflow:hidden;
  position:relative;
  width:100%; }
  .bp3-progress-bar .bp3-progress-meter{
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    border-radius:40px;
    height:100%;
    position:absolute;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:100%; }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  color:transparent !important;
  cursor:default;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  height:40px;
  min-width:150px;
  width:100%;
  cursor:default;
  outline:none;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    cursor:not-allowed;
    opacity:0.5; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  height:6px;
  left:0;
  right:0;
  top:5px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  height:16px;
  left:0;
  position:absolute;
  top:0;
  width:16px; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab;
    z-index:2; }
  .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    background:#bfccd6;
    -webkit-box-shadow:none;
            box-shadow:none;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    background:#5c7080;
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-slider-handle .bp3-slider-label{
    background:#394b59;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    color:#f5f8fa;
    margin-left:8px; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      background:#e1e8ed;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-bottom-right-radius:0;
    border-top-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    border-bottom-left-radius:0;
    border-top-left-radius:0;
    margin-left:8px; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  font-size:12px;
  line-height:1;
  padding:2px 5px;
  position:absolute;
  vertical-align:top; }

.bp3-slider.bp3-vertical{
  height:150px;
  min-width:40px;
  width:40px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    bottom:0;
    height:auto;
    left:5px;
    top:0;
    width:6px; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-left:0;
      margin-top:-8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      height:8px;
      margin-left:0;
      width:16px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-bottom-right-radius:3px;
      border-top-left-radius:0; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      border-bottom-left-radius:0;
      border-bottom-right-radius:0;
      border-top-left-radius:3px;
      margin-bottom:8px; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round;
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      padding:0 10px;
      width:100%; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        background-color:rgba(19, 124, 189, 0.2);
        -webkit-box-shadow:none;
                box-shadow:none; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      background-color:rgba(19, 124, 189, 0.2);
      border-radius:3px;
      bottom:0;
      height:auto;
      left:0;
      right:0;
      top:0; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  border:none;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  list-style:none;
  margin:0;
  padding:0;
  position:relative; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:#182026;
  cursor:pointer;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  font-size:14px;
  line-height:30px;
  max-width:100%;
  position:relative;
  vertical-align:top; }
  .bp3-tab a{
    color:inherit;
    display:block;
    text-decoration:none; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    background-color:transparent !important;
    -webkit-box-shadow:none !important;
            box-shadow:none !important; }
  .bp3-tab[aria-disabled="true"]{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    font-size:16px;
    line-height:40px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  left:0;
  pointer-events:none;
  position:absolute;
  top:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    background-color:#106ba3;
    bottom:0;
    height:3px;
    left:0;
    position:absolute;
    right:0; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#5c7080;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  color:#f5f8fa;
  font-size:12px;
  line-height:16px;
  max-width:100%;
  min-height:20px;
  min-width:20px;
  padding:2px 6px;
  position:relative; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-left:8px;
    padding-right:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    font-size:14px;
    line-height:20px;
    min-height:30px;
    min-width:30px;
    padding:5px 10px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-left:12px;
      padding-right:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  background:none;
  border:none;
  color:inherit;
  cursor:pointer;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin-bottom:-2px;
  margin-right:-6px !important;
  margin-top:-2px;
  opacity:0.5;
  padding:2px;
  padding-left:0; }
  .bp3-tag-remove:hover{
    background:none;
    opacity:0.8;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:0 5px 0 0; }
    .bp3-large .bp3-tag-remove:empty::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  line-height:inherit;
  min-height:30px;
  padding-left:5px;
  padding-right:0; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    color:#5c7080;
    margin-left:2px;
    margin-right:7px;
    margin-top:7px; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    margin-right:7px;
    margin-top:5px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:20px;
    width:80px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-left:5px;
      margin-top:10px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-height:30px;
      min-width:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:20px 0 0;
  max-width:500px;
  min-width:300px;
  pointer-events:all;
  position:relative !important; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-delay:50ms;
            transition-delay:50ms;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    color:#5c7080;
    margin:12px;
    margin-right:0; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    background-color:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  left:0;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none;
  right:0;
  z-index:40; }
  .bp3-toast-container.bp3-toast-container-in-portal{
    position:fixed; }
  .bp3-toast-container.bp3-toast-container-inline{
    position:absolute; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0; }
  .bp3-toast-container.bp3-toast-container-bottom{
    bottom:0;
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-exit-active ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    height:22px;
    position:absolute;
    width:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      height:14px;
      margin:4px;
      width:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-bottom:11px;
    margin-top:-11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-left:-11px;
    margin-right:11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  list-style:none;
  margin:0;
  padding-left:0; }

.bp3-tree-root{
  background-color:transparent;
  cursor:default;
  padding-left:0;
  position:relative; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:30px;
  padding-right:5px;
  width:100%; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  cursor:pointer;
  padding:7px;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  margin-right:7px;
  position:relative; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  left:calc(50% - 250px);
  top:20vh;
  width:500px;
  z-index:21; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar .bp3-input{
    background-color:transparent;
    border-radius:0; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    background-color:transparent;
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}
.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}
.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}
.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-border-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0px;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-warn-color0);
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px 5px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FileDialog-Checkbox {
  margin-top: 35px;
  display: flex;
  flex-direction: row;
  align-items: end;
  width: 100%;
}

.jp-FileDialog-Checkbox > label {
  flex: 1 1 auto;
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
  overflow-x: auto;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 50px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -50px; margin-right: -50px;
  padding-bottom: 50px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 50px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
  outline: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -50px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .remote-caret {
  position: relative;
  border-left: 2px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .remote-caret > div {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -2px;
  font-size: 0.95em;
  background-color: rgb(250, 129, 0);
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 3;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .remote-caret.hide-name > div {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .remote-caret:hover > div {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
  margin: 8px 12px 0px 12px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: flex-start;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0px;
  padding-right: 2px;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 40px;
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent {
  width: 72px;
  background: var(--jp-brand-color1);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent:focus-visible {
  background-color: var(--jp-brand-color0);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent
  .jp-icon3 {
  fill: white;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileBrowser-filterBox {
  padding: 0px;
  flex: 0 0 auto;
  margin: 8px 12px 0px 12px;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing:focus-visible {
  border: 1px solid var(--jp-brand-color1);
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon:before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

body[data-format='mobile'] .jp-OutputArea-child {
  flex-direction: column;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

body[data-format='mobile'] .jp-OutputPrompt {
  flex: 0 0 auto;
  text-align: left;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

body[data-format='mobile'] .jp-OutputArea-child .jp-OutputArea-output {
  margin-left: var(--jp-notebook-padding);
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
  overflow: hidden;
}

body[data-format='mobile'] .jp-InputArea {
  flex-direction: column;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
  overflow: hidden;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

body[data-format='mobile'] .jp-InputArea-editor {
  margin-left: var(--jp-notebook-padding);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

body[data-format='mobile'] .jp-InputPrompt {
  flex: 0 0 auto;
  text-align: left;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

.jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
}

.jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-collapseHeadingButton {
  display: none;
}

.jp-MarkdownCell:hover .jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  position: absolute;
  right: 0;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook-render * {
  contain: none !important;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
  float: left;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt:before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body div {
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

.highlight  {
  margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.CodeMirror pre {
  margin: 0;
  padding: 0;
}

/* Using table instead of flexbox so that we can use break-inside property */
/* CSS rules under this comment should not be required anymore after we move to the JupyterLab 4.0 CSS */


.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  min-width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-OutputArea-child {
  display: table;
  width: 100%;
}

.jp-OutputPrompt {
  display: table-cell;
  vertical-align: top;
  min-width: var(--jp-cell-prompt-width);
}

body[data-format='mobile'] .jp-OutputPrompt {
  display: table-row;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
}

body[data-format='mobile'] .jp-OutputArea-child .jp-OutputArea-output {
  display: table-row;
}

.jp-OutputArea-output.jp-OutputArea-executeResult {
  width: 100%;
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }

  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}
</style>

<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">

<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Sieci-neuronowe">Sieci neuronowe<a class="anchor-link" href="#Sieci-neuronowe">&#182;</a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Wst%C4%99p">Wst&#281;p<a class="anchor-link" href="#Wst%C4%99p">&#182;</a></h2><p>Celem laboratorium jest zapoznanie się z podstawami sieci neuronowych oraz uczeniem głębokim (<em>deep learning</em>). Zapoznasz się na nim z następującymi tematami:</p>
<ul>
<li>treningiem prostych sieci neuronowych, w szczególności z:<ul>
<li>regresją liniową w sieciach neuronowych</li>
<li>optymalizacją funkcji kosztu</li>
<li>algorytmem spadku wzdłuż gradientu</li>
<li>siecią typu Multilayer Perceptron (MLP)</li>
</ul>
</li>
<li>frameworkiem PyTorch, w szczególności z:<ul>
<li>ładowaniem danych</li>
<li>preprocessingiem danych</li>
<li>pisaniem pętli treningowej i walidacyjnej</li>
<li>walidacją modeli</li>
</ul>
</li>
<li>architekturą i hiperaprametrami sieci MLP, w szczególności z:<ul>
<li>warstwami gęstymi (w pełni połączonymi)</li>
<li>funkcjami aktywacji</li>
<li>regularyzacją: L2, dropout</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Wykorzystywane-biblioteki">Wykorzystywane biblioteki<a class="anchor-link" href="#Wykorzystywane-biblioteki">&#182;</a></h2><p>Zaczniemy od pisania ręcznie prostych sieci w bibliotece Numpy, służącej do obliczeń numerycznych na CPU. Później przejdziemy do wykorzystywania frameworka PyTorch, służącego do obliczeń numerycznych na CPU, GPU oraz automatycznego różniczkowania, wykorzystywanego głównie do treningu sieci neuronowych.</p>
<p>Wykorzystamy PyTorcha ze względu na popularność, łatwość instalacji i użycia, oraz dużą kontrolę nad niskopoziomowymi aspektami budowy i treningu sieci neuronowych. Framework ten został stworzony do zastosowań badawczych i naukowych, ale ze względu na wygodę użycia stał się bardzo popularny także w przemyśle. W szczególności całkowicie zdominował przetwarzanie języka naturalnego (NLP) oraz uczenie na grafach.</p>
<p>Pierwszy duży framework do deep learningu, oraz obecnie najpopularniejszy, to TensorFlow, wraz z wysokopoziomową nakładką Keras. Są jednak szanse, że Google (autorzy) będzie go powoli porzucać na rzecz ich nowego frameworka JAX (<a href="https://www.reddit.com/r/MachineLearning/comments/vfl57t/d_google_quietly_moving_its_products_from/">dyskusja</a>, <a href="https://www.businessinsider.com/facebook-pytorch-beat-google-tensorflow-jax-meta-ai-2022-6?IR=T">artykuł Business Insidera</a>), który jest bardzo świeżym, ale ciekawym narzędziem.</p>
<p>Trzecia, ale znacznie mniej popularna od powyższych opcja to Apache MXNet.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Konfiguracja-w%C5%82asnego-komputera">Konfiguracja w&#322;asnego komputera<a class="anchor-link" href="#Konfiguracja-w%C5%82asnego-komputera">&#182;</a></h2><p>Jeżeli korzystasz z własnego komputera, to musisz zainstalować trochę więcej bibliotek (Google Colab ma je już zainstalowane).</p>
<p>Jeżeli nie masz GPU lub nie chcesz z niego korzystać, to wystarczy znaleźć odpowiednią komendę CPU <a href="https://pytorch.org/get-started/locally/">na stronie PyTorcha</a>. Dla Anacondy odpowiednia komenda została podana poniżej, dla pip'a znajdź ją na stronie.</p>
<p>Jeżeli chcesz korzystać ze wsparcia GPU (na tym laboratorium nie będzie potrzebne, na kolejnych może przyspieszyć nieco obliczenia), to musi być to odpowiednio nowa karta NVidii, mająca CUDA compatibility (<a href="https://developer.nvidia.com/cuda-gpus">lista</a>). Poza PyTorchem będzie potrzebne narzędzie NVidia CUDA w wersji 11.6 lub 11.7. Instalacja na Windowsie jest bardzo prosta (wystarczy ściągnąć plik EXE i zainstalować jak każdy inny program). Instalacja na Linuxie jest trudna i można względnie łatwo zepsuć sobie system, ale jeżeli chcesz spróbować, to <a href="https://www.youtube.com/results?search_query=nvidia+cuda+install+ubuntu+20.04">ten tutorial</a> jest bardzo dobry.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="for-conda-users">for conda users<a class="anchor-link" href="#for-conda-users">&#182;</a></h1><p>!conda install -y matplotlib pandas pytorch torchvision -c pytorch -c conda-forge</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>!pip3 install torch torchvision torchaudio --index-url <a href="https://download.pytorch.org/whl/cu118">https://download.pytorch.org/whl/cu118</a></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Wprowadzenie">Wprowadzenie<a class="anchor-link" href="#Wprowadzenie">&#182;</a></h2><p>Zanim zaczniemy naszą przygodę z sieciami neuronowymi, przyjrzyjmy się prostemu przykładowi regresji liniowej na syntetycznych danych:</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>&lt;matplotlib.collections.PathCollection at 0x219fe7b7c10&gt;</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>W przeciwieństwie do laboratorium 1, tym razem będziemy chcieli rozwiązać ten problem własnoręcznie, bez użycia wysokopoziomowego interfejsu Scikit-learn'a. W tym celu musimy sobie przypomnieć sformułowanie naszego <strong>problemu optymalizacyjnego (optimization problem)</strong>.</p>
<p>W przypadku prostej regresji liniowej (1 zmienna) mamy model postaci $\hat{y} = \alpha x + \beta$, z dwoma parametrami, których będziemy się uczyć. Miarą niedopasowania modelu o danych parametrach jest <strong>funkcja kosztu (cost function)</strong>, nazywana też funkcją celu. Najczęściej używa się <strong>błędu średniokwadratowego (mean squared error, MSE)</strong>:
$$\large
MSE = \frac{1}{N} \sum_{i}^{N} (y - \hat{y})^2
$$</p>
<p>Od jakich $\alpha$ i $\beta$ zacząć? W najprostszym wypadku wystarczy po prostu je wylosować jako niewielkie liczby zmiennoprzecinkowe.</p>
<h4 id="Zadanie-1-(0.5-punkt)">Zadanie 1 (0.5 punkt)<a class="anchor-link" href="#Zadanie-1-(0.5-punkt)">&#182;</a></h4><p>Uzupełnij kod funkcji <code>mse</code>, obliczającej błąd średniokwadratowy. Wykorzystaj Numpy'a w celu wektoryzacji obliczeń dla wydajności.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"MSE: </span><span class="si">{</span><span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"g"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>MSE: 0.133
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[&lt;matplotlib.lines.Line2D at 0x219fe8d7f70&gt;]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Losowe parametry radzą sobie nie najlepiej. Jak lepiej dopasować naszą prostą do danych? Zawsze możemy starać się wyprowadzić rozwiązanie analitycznie, i w tym wypadku nawet nam się uda. Jest to jednak szczególny i dość rzadki przypadek, a w szczególności nie będzie to możliwe w większych sieciach neuronowych.</p>
<p>Potrzebna nam będzie <strong>metoda optymalizacji (optimization method)</strong>, dającą wartości parametrów minimalizujące dowolną różniczkowalną funkcję kosztu. Zdecydowanie najpopularniejszy jest tutaj <strong>spadek wzdłuż gradientu (gradient descent)</strong>.</p>
<p>Metoda ta wywodzi się z prostych obserwacji, które tutaj przedstawimy. Bardziej szczegółowe rozwinięcie dla zainteresowanych: <a href="https://www.deeplearningbook.org/contents/numerical.html">sekcja 4.3 "Deep Learning Book"</a>, <a href="https://cs231n.github.io/optimization-1/">ten praktyczny kurs</a>, <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf">analiza oryginalnej publikacji Cauchy'ego</a> (oryginał w języku francuskim).</p>
<p>Pochodna jest dokładnie równa granicy funkcji. Dla małego $\epsilon$ można ją przybliżyć jako:
$$\large
\frac{f(x)}{dx} \approx \frac{f(x+\epsilon) - f(x)}{\epsilon}
$$</p>
<p>Przyglądając się temu równaniu widzimy, że:</p>
<ul>
<li>dla funkcji rosnącej ($f(x+\epsilon) &gt; f(x)$) wyrażenie $\frac{f(x)}{dx}$ będzie miało znak dodatni </li>
<li>dla funkcji malejącej ($f(x+\epsilon) &lt; f(x)$) wyrażenie $\frac{f(x)}{dx}$ będzie miało znak ujemny </li>
</ul>
<p>Widzimy więc, że potrafimy wskazać kierunek zmniejszenia wartości funkcji, patrząc na znak pochodnej. Zaobserwowano także, że amplituda wartości w $\frac{f(x)}{dx}$ jest tym większa, im dalej jesteśmy od minimum (maximum). Pochodna wyznacza więc, w jakim kierunku funkcja najszybciej rośnie, zaś przeciwny zwrot to ten, w którym funkcja najszybciej spada.</p>
<p>Stosując powyższe do optymalizacji, mamy:
$$\large
x_{t+1} = x_{t} -  \alpha * \frac{f(x)}{dx}
$$</p>
<p>$\alpha$ to niewielka wartość (rzędu zwykle $10^{-5}$ - $10^{-2}$), wprowadzona, aby trzymać się założenia o małej zmianie parametrów ($\epsilon$). Nazywa się ją <strong>stałą uczącą (learning rate)</strong> i jest zwykle najważniejszym hiperparametrem podczas nauki sieci.</p>
<p>Metoda ta zakłada, że używamy całego zbioru danych do aktualizacji parametrów w każdym kroku, co nazywa się po prostu GD (od <em>gradient descent</em>) albo <em>full batch GD</em>. Wtedy każdy krok optymalizacji nazywa się <strong>epoką (epoch)</strong>.</p>
<p>Im większa stała ucząca, tym większe nasze kroki podczas minimalizacji. Możemy więc uczyć szybciej, ale istnieje ryzyko, że będziemy "przeskakiwać" minima. Mniejsza stała ucząca to wolniejszy, ale dokładniejszy trening. Jednak nie zawsze ona pozwala osiągnąć lepsze wyniki, bo może okazać się, że utkniemy w minimum lokalnym. Można także zmieniać stałą uczącą podczas treningu, co nazywa się <strong>learning rate scheduling (LR scheduling)</strong>. Obrazowo:</p>
<p><img src="http://www.bdhammel.com/assets/learning-rate/lr-types.png" alt="learning_rate"></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p><img src="http://cdn-images-1.medium.com/max/640/1*eeIvlwkMNG1wSmj3FR6M2g.gif" alt="interactive LR"></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Policzmy więc pochodną dla naszej funkcji kosztu MSE. Pochodną liczymy po parametrach naszego modelu, bo to właśnie ich chcemy dopasować tak, żeby koszt był jak najmniejszy:</p>
$$\large
MSE = \frac{1}{N} \sum_{i}^{N} (y_i - \hat{y_i})^2
$$<p>W powyższym wzorze tylko $y_i$ jest zależny od $a$ oraz $b$. Możemy wykorzystać tu regułę łańcuchową (<em>chain rule</em>) i policzyć pochodne po naszych parametrach w sposób następujący:</p>
$$\large
\frac{\text{d} MSE}{\text{d} a} = \frac{1}{N} \sum_{i}^{N} \frac{\text{d} (y_i - \hat{y_i})^2}{\text{d} \hat{y_i}} \frac{\text{d} \hat{y_i}}{\text{d} a}
$$$$\large
\frac{\text{d} MSE}{\text{d} b} = \frac{1}{N} \sum_{i}^{N} \frac{\text{d} (y_i - \hat{y_i})^2}{\text{d} \hat{y_i}} \frac{\text{d} \hat{y_i}}{\text{d} b}
$$<p>Policzmy te pochodne po kolei:</p>
$$\large
\frac{\text{d} (y_i - \hat{y_i})^2}{\text{d} \hat{y_i}} = -2 \cdot (y_i - \hat{y_i})
$$$$\large
\frac{\text{d} \hat{y_i}}{\text{d} a} = x_i
$$$$\large
\frac{\text{d} \hat{y_i}}{\text{d} b} = 1
$$<p>Łącząc powyższe wyniki dostaniemy:</p>
$$\large
\frac{\text{d} MSE}{\text{d} a} = \frac{-2}{N} \sum_{i}^{N} (y_i - \hat{y_i}) \cdot {x_i}
$$$$\large
\frac{\text{d} MSE}{\text{d} b} = \frac{-2}{N} \sum_{i}^{N} (y_i - \hat{y_i})
$$<p>Aktualizacja parametrów wygląda tak:</p>
$$\large
a' = a - \alpha * \left( \frac{-2}{N} \sum_{i=1}^N (y_i - \hat{y}_i) \cdot x_i \right)
$$$$\large
b' = b - \alpha * \left( \frac{-2}{N} \sum_{i=1}^N (y_i - \hat{y}_i) \right)
$$<p>Liczymy więc pochodną funkcji kosztu, a potem za pomocą reguły łańcuchowej "cofamy się", dochodząc do tego, jak każdy z parametrów wpływa na błąd i w jaki sposób powinniśmy go zmienić. Nazywa się to <strong>propagacją wsteczną (backpropagation)</strong> i jest podstawowym mechanizmem umożliwiającym naukę sieci neuronowych za pomocą spadku wzdłuż gradientu. Więcej możesz o tym przeczytać <a href="https://cs231n.github.io/optimization-2/">tutaj</a>.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-2-(1.0-punkt)">Zadanie 2 (1.0 punkt)<a class="anchor-link" href="#Zadanie-2-(1.0-punkt)">&#182;</a></h4><p>Zaimplementuj funkcję realizującą jedną epokę treningową. Zauważ, że <code>x</code> oraz <code>y</code> są wektorami. Oblicz predykcję przy aktualnych parametrach oraz zaktualizuj je zgodnie z powyższymi wzorami.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="p">):</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span> <span class="o">-</span><span class="mi">2</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">errors</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> loss: "</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"final loss:"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>step 0 loss:  0.1330225119404028
step 100 loss:  0.012673197778527677
step 200 loss:  0.010257153540857817
step 300 loss:  0.0100948037549359
step 400 loss:  0.010083894412889118
step 500 loss:  0.010083161342973332
step 600 loss:  0.010083112083219709
step 700 loss:  0.010083108773135261
step 800 loss:  0.010083108550709076
step 900 loss:  0.01008310853576281
final loss: 0.010083108534760455
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"g"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[8]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[&lt;matplotlib.lines.Line2D at 0x219fe95e610&gt;]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Udało ci się wytrenować swoją pierwszą sieć neuronową. Czemu? Otóż neuron to po prostu wektor parametrów, a zwykle robimy iloczyn skalarny tych parametrów z wejściem. Dodatkowo na wyjście nakłada się <strong>funkcję aktywacji (activation function)</strong>, która przekształca wyjście. Tutaj takiej nie było, a właściwie była to po prostu funkcja identyczności.</p>
<p>Oczywiście w praktyce korzystamy z odpowiedniego frameworka, który w szczególności:</p>
<ul>
<li>ułatwia budowanie sieci, np. ma gotowe klasy dla warstw neuronów</li>
<li>ma zaimplementowane funkcje kosztu oraz ich pochodne</li>
<li>sam różniczkuje ze względu na odpowiednie parametry i aktualizuje je odpowiednio podczas treningu</li>
</ul>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Wprowadzenie-do-PyTorcha">Wprowadzenie do PyTorcha<a class="anchor-link" href="#Wprowadzenie-do-PyTorcha">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>PyTorch to w gruncie rzeczy narzędzie do algebry liniowej z <a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html">automatycznym rożniczkowaniem</a>, z możliwością przyspieszenia obliczeń z pomocą GPU. Na tych fundamentach zbudowany jest pełny framework do uczenia głębokiego. Można spotkać się ze stwierdzenie, że PyTorch to NumPy + GPU + opcjonalne różniczkowanie, co jest całkiem celne. Plus można łatwo debugować printem :)</p>
<p>PyTorch używa dynamicznego grafu obliczeń, który sami definiujemy w kodzie. Takie podejście jest bardzo wygodne, elastyczne i pozwala na łatwe eksperymentowanie. Odbywa się to potencjalnie kosztem wydajności, ponieważ pozostawia kwestię optymalizacji programiście. Więcej na ten temat dla zainteresowanych na końcu laboratorium.</p>
<p>Samo API PyTorcha bardzo przypomina Numpy'a, a podstawowym obiektem jest <code>Tensor</code>, klasa reprezentująca tensory dowolnego wymiaru. Dodatkowo niektóre tensory będą miały automatycznie obliczony gradient. Co ważne, tensor jest na pewnym urządzeniu, CPU lub GPU, a przenosić między nimi trzeba explicite.</p>
<p>Najważniejsze moduły:</p>
<ul>
<li><code>torch</code> - podstawowe klasy oraz funkcje, np. <code>Tensor</code>, <code>from_numpy()</code></li>
<li><code>torch.nn</code> - klasy związane z sieciami neuronowymi, np. <code>Linear</code>, <code>Sigmoid</code></li>
<li><code>torch.optim</code> - wszystko związane z optymalizacją, głównie spadkiem wzdłuż gradientu</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># elementwise sum</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones</span> <span class="o">+</span> <span class="n">noise</span><span class="p">)</span>

<span class="c1"># elementwise multiplication</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones</span> <span class="o">*</span> <span class="n">noise</span><span class="p">)</span>

<span class="c1"># dot product</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones</span> <span class="o">@</span> <span class="n">noise</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>tensor([1.4154, 1.8855, 1.2668, 1.9454, 1.3595, 1.6473, 1.9778, 1.1298, 1.7165,
        1.4596])
tensor([0.4154, 0.8855, 0.2668, 0.9454, 0.3595, 0.6473, 0.9778, 0.1298, 0.7165,
        0.4596])
tensor(5.8036)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_x</span><span class="p">,</span> <span class="n">_y</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># beware - shares memory with original Numpy array!</span>
<span class="c1"># very fast, but modifications are visible to original variable</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_y</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Jeżeli dla stworzonych przez nas tensorów chcemy śledzić operacje i obliczać gradient, to musimy oznaczyć <code>requires_grad=True</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">a</span><span class="p">,</span> <span class="n">b</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[13]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(tensor([0.0464], requires_grad=True), tensor([0.8258], requires_grad=True))</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>PyTorch zawiera większość powszechnie używanych funkcji kosztu, np. MSE. Mogą być one używane na 2 sposoby, z czego pierwszy jest popularniejszy:</p>
<ul>
<li>jako klasy wywoływalne z modułu <code>torch.nn</code></li>
<li>jako funkcje z modułu <code>torch.nn.functional</code></li>
</ul>
<p>Po wykonaniu poniższego kodu widzimy, że zwraca on nam tensor z dodatkowymi atrybutami. Co ważne, jest to skalar (0-wymiarowy tensor), bo potrzebujemy zwyczajnej liczby do obliczania propagacji wstecznych (pochodnych czątkowych).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[14]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>tensor(0.2003, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Atrybutu <code>grad_fn</code> nie używamy wprost, bo korzysta z niego w środku PyTorch, ale widać, że tensor jest "świadomy", że liczy się na nim pochodną. Możemy natomiast skorzystać z atrybutu <code>grad</code>, który zawiera faktyczny gradient. Zanim go jednak dostaniemy, to trzeba powiedzieć PyTorchowi, żeby policzył gradient. Służy do tego metoda <code>.backward()</code>, wywoływana na obiekcie zwracanym przez funkcję kosztu.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>tensor([0.1860])
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Ważne jest, że PyTorch nie liczy za każdym razem nowego gradientu, tylko dodaje go do istniejącego, czyli go akumuluje. Jest to przydatne w niektórych sieciach neuronowych, ale zazwyczaj trzeba go zerować. Jeżeli tego nie zrobimy, to dostaniemy coraz większe gradienty.</p>
<p>Do zerowania służy metoda <code>.zero_()</code>. W PyTorchu wszystkie metody modyfikujące tensor w miejscu mają <code>_</code> na końcu nazwy. Jest to dość niskopoziomowa operacja dla pojedynczych tensorów - zobaczymy za chwilę, jak to robić łatwiej dla całej sieci.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">a</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[17]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>tensor([0.3720])</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Zobaczmy, jak wyglądałaby regresja liniowa, ale napisana w PyTorchu. Jest to oczywiście bardzo niskopoziomowa implementacja - za chwilę zobaczymy, jak to wygląda w praktyce.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

    <span class="c1"># compute gradients</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># update parameters</span>
    <span class="n">a</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">a</span><span class="o">.</span><span class="n">grad</span>
    <span class="n">b</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">b</span><span class="o">.</span><span class="n">grad</span>

    <span class="c1"># zero gradients</span>
    <span class="n">a</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="n">b</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> loss: "</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"final loss:"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>step 0 loss:  tensor(0.2003, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 100 loss:  tensor(0.0162, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 200 loss:  tensor(0.0105, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 300 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 400 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 500 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 600 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 700 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 800 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
step 900 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
final loss: tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Trening modeli w PyTorchu jest dosyć schematyczny i najczęściej rozdziela się go na kilka bloków, dających razem <strong>pętlę uczącą (training loop)</strong>, powtarzaną w każdej epoce:</p>
<ol>
<li>Forward pass - obliczenie predykcji sieci</li>
<li>Loss calculation</li>
<li>Backpropagation - obliczenie pochodnych oraz zerowanie gradientów</li>
<li>Optimalization - aktualizacja wag</li>
<li>Other - ewaluacja na zbiorze walidacyjnym, logging etc.</li>
</ol>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># initialization</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>

<span class="c1"># training loop in each epoch</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># forward pass</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>

    <span class="c1"># loss calculation</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>

    <span class="c1"># backpropagation</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># optimization</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># zeroes all gradients - very convenient!</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
            <span class="n">best_model</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">b</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
            <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"final loss:"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>step 0 loss: 0.4044
step 100 loss: 0.0122
step 200 loss: 0.0102
step 300 loss: 0.0101
step 400 loss: 0.0101
step 500 loss: 0.0101
step 600 loss: 0.0101
step 700 loss: 0.0101
step 800 loss: 0.0101
step 900 loss: 0.0101
final loss: tensor(0.0101, dtype=torch.float64, grad_fn=&lt;MseLossBackward0&gt;)
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Przejdziemy teraz do budowy sieci neuronowej do klasyfikacji. Typowo implementuje się ją po prostu jako sieć dla regresji, ale zwracającą tyle wyników, ile mamy klas, a potem aplikuje się na tym funkcję sigmoidalną (2 klasy) lub softmax (&gt;2 klasy). W przypadku klasyfikacji binarnej zwraca się czasem tylko 1 wartość, przepuszczaną przez sigmoidę - wtedy wyjście z sieci to prawdopodobieństwo klasy pozytywnej.</p>
<p>Funkcją kosztu zwykle jest <strong>entropia krzyżowa (cross-entropy)</strong>, stosowana też w klasycznej regresji logistycznej. Co ważne, sieci neuronowe, nawet tak proste, uczą się szybciej i stabilniej, gdy dane na wejściu (a przynajmniej zmienne numeryczne) są <strong>ustandaryzowane (standardized)</strong>. Operacja ta polega na odjęciu średniej i podzieleniu przez odchylenie standardowe (tzw. <em>Z-score transformation</em>).</p>
<p><strong>Uwaga - PyTorch wymaga tensora klas będącego liczbami zmiennoprzecinkowymi!</strong></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Zbi%C3%B3r-danych">Zbi&#243;r danych<a class="anchor-link" href="#Zbi%C3%B3r-danych">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Na tym laboratorium wykorzystamy zbiór <a href="https://archive.ics.uci.edu/ml/datasets/adult">Adult Census</a>. Dotyczy on przewidywania na podstawie danych demograficznych, czy dany człowiek zarabia powyżej 50 tysięcy dolarów rocznie, czy też mniej. Jest to cenna informacja np. przy planowaniu kampanii marketingowych. Jak możesz się domyślić, zbiór pochodzi z czasów, kiedy inflacja była dużo niższa :)</p>
<p>Poniżej znajduje się kod do ściągnięcia i preprocessingu zbioru. Nie musisz go dokładnie analizować.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>--2023-11-25 22:56:18--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data
Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252
Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified
Saving to: &#39;adult.data.1&#39;

     0K .......... .......... .......... .......... ..........  145K
    50K .......... .......... .......... .......... ..........  546K
   100K .......... .......... .......... .......... ..........  591K
   150K .......... .......... .......... .......... .......... 15,5M
   200K .......... .......... .......... .......... ..........  293K
   250K .......... .......... .......... .......... .......... 16,8M
   300K .......... .......... .......... .......... ..........  598K
   350K .......... .......... .......... .......... .......... 15,2M
   400K .......... .......... .......... .......... .......... 22,5M
   450K .......... .......... .......... .......... ..........  611K
   500K .......... .......... .......... .......... .......... 19,3M
   550K .......... .......... .......... .......... .......... 24,4M
   600K .......... .......... .......... .......... .......... 21,9M
   650K .......... .......... .......... .......... .......... 1,95M
   700K .......... .......... .......... .......... ..........  868K
   750K .......... .......... .......... .......... .......... 29,0M
   800K .......... .......... .......... .......... .......... 37,4M
   850K .......... .......... .......... .......... .......... 37,5M
   900K .......... .......... .......... .......... .......... 26,5M
   950K .......... .......... .......... .......... ..........  659K
  1000K .......... .......... .......... .......... .......... 8,19M
  1050K .......... .......... .......... .......... .......... 25,5M
  1100K .......... .......... .......... .......... .......... 54,7M
  1150K .......... .......... .......... .......... .......... 35,5M
  1200K .......... .......... .......... .......... .......... 26,8M
  1250K .......... .......... .......... .......... .......... 37,7M
  1300K .......... .......... .......... .......... .......... 55,2M
  1350K .......... .......... .......... .......... .......... 2,67M
  1400K .......... .......... .......... .......... ..........  895K
  1450K .......... .......... .......... .......... .......... 6,53M
  1500K .......... .......... .......... .......... .......... 24,1M
  1550K .......... .......... .......... .......... .......... 21,7M
  1600K .......... .......... .......... .......... .......... 38,6M
  1650K .......... .......... .......... .......... .......... 16,0M
  1700K .......... .......... .......... .......... .......... 36,7M
  1750K .......... .......... .......... .......... .......... 27,6M
  1800K .......... .......... .......... .......... .......... 36,8M
  1850K .......... .......... .......... .......... .......... 39,6M
  1900K .......... .......... .......... .......... .......... 35,8M
  1950K .......... .......... .......... .......... ..........  818K
  2000K .......... .......... .......... .......... .......... 10,8M
  2050K .......... .......... .......... .......... .......... 23,9M
  2100K .......... .......... .......... .......... .......... 12,9M
  2150K .......... .......... .......... .......... .......... 46,5M
  2200K .......... .......... .......... .......... .......... 26,3M
  2250K .......... .......... .......... .......... .......... 72,5M
  2300K .......... .......... .......... .......... .......... 29,6M
  2350K .......... .......... .......... .......... .......... 15,0M
  2400K .......... .......... .......... .......... .......... 34,2M
  2450K .......... .......... .......... .......... .......... 23,0M
  2500K .......... .......... .......... .......... .......... 37,1M
  2550K .......... .......... .......... .......... .......... 30,9M
  2600K .......... .......... .......... .......... .......... 32,6M
  2650K .......... .......... .......... .......... .......... 41,2M
  2700K .......... .......... .......... .......... .......... 39,2M
  2750K .......... .......... .......... .......... .......... 19,3M
  2800K .......... .......... .......... .......... .......... 11,2M
  2850K .......... .......... .......... .......... ..........  928K
  2900K .......... .......... .......... .......... .......... 23,7M
  2950K .......... .......... .......... .......... .......... 8,21M
  3000K .......... .......... .......... .......... .......... 22,2M
  3050K .......... .......... .......... .......... .......... 17,6M
  3100K .......... .......... .......... .......... .......... 81,1M
  3150K .......... .......... .......... .......... .......... 42,3M
  3200K .......... .......... .......... .......... .......... 30,6M
  3250K .......... .......... .......... .......... .......... 43,5M
  3300K .......... .......... .......... .......... .......... 31,9M
  3350K .......... .......... .......... .......... .......... 20,7M
  3400K .......... .......... .......... .......... .......... 39,7M
  3450K .......... .......... .......... .......... .......... 42,5M
  3500K .......... .......... .......... .......... .......... 15,1M
  3550K .......... .......... .......... .......... .......... 20,4M
  3600K .......... .......... .......... .......... .......... 38,2M
  3650K .......... .......... .......... .......... .......... 21,7M
  3700K .......... .......... .......... .......... .......... 38,2M
  3750K .......... .......... .......... .......... .......... 60,6M
  3800K .......... .......... .......... .......... .......... 62,2M
  3850K .......... .......... .......... .                     76,8M=1,3s

2023-11-25 22:56:21 (2,83 MB/s) - &#39;adult.data.1&#39; saved [3974305]

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"age"</span><span class="p">,</span>
    <span class="s2">"workclass"</span><span class="p">,</span>
    <span class="s2">"fnlwgt"</span><span class="p">,</span>
    <span class="s2">"education"</span><span class="p">,</span>
    <span class="s2">"education-num"</span><span class="p">,</span>
    <span class="s2">"marital-status"</span><span class="p">,</span>
    <span class="s2">"occupation"</span><span class="p">,</span>
    <span class="s2">"relationship"</span><span class="p">,</span>
    <span class="s2">"race"</span><span class="p">,</span>
    <span class="s2">"sex"</span><span class="p">,</span>
    <span class="s2">"capital-gain"</span><span class="p">,</span>
    <span class="s2">"capital-loss"</span><span class="p">,</span>
    <span class="s2">"hours-per-week"</span><span class="p">,</span>
    <span class="s2">"native-country"</span><span class="p">,</span>
    <span class="s2">"wage"</span>
<span class="p">]</span>

<span class="sd">"""</span>
<span class="sd">age: continuous.</span>
<span class="sd">workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.</span>
<span class="sd">fnlwgt: continuous.</span>
<span class="sd">education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.</span>
<span class="sd">education-num: continuous.</span>
<span class="sd">marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.</span>
<span class="sd">occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.</span>
<span class="sd">relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.</span>
<span class="sd">race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.</span>
<span class="sd">sex: Female, Male.</span>
<span class="sd">capital-gain: continuous.</span>
<span class="sd">capital-loss: continuous.</span>
<span class="sd">hours-per-week: continuous.</span>
<span class="sd">native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&amp;Tobago, Peru, Hong, Holand-Netherlands.</span>
<span class="sd">"""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"adult.data"</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">wage</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>array([&#39; &lt;=50K&#39;, &#39; &gt;50K&#39;], dtype=object)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># attribution: https://www.kaggle.com/code/royshih23/topic7-classification-in-python</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Preschool'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'10th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'11th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'12th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'1st-4th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'5th-6th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'7th-8th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'9th'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'HS-Grad'</span><span class="p">,</span> <span class="s1">'HighGrad'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'HS-grad'</span><span class="p">,</span> <span class="s1">'HighGrad'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Some-college'</span><span class="p">,</span> <span class="s1">'CommunityCollege'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Assoc-acdm'</span><span class="p">,</span> <span class="s1">'CommunityCollege'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Assoc-voc'</span><span class="p">,</span> <span class="s1">'CommunityCollege'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Bachelors'</span><span class="p">,</span> <span class="s1">'Bachelors'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Masters'</span><span class="p">,</span> <span class="s1">'Masters'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Prof-school'</span><span class="p">,</span> <span class="s1">'Masters'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'education'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Doctorate'</span><span class="p">,</span> <span class="s1">'Doctorate'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'Never-married'</span><span class="p">,</span> <span class="s1">'NotMarried'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">'Married-AF-spouse'</span><span class="p">],</span> <span class="s1">'Married'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">'Married-civ-spouse'</span><span class="p">],</span> <span class="s1">'Married'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">'Married-spouse-absent'</span><span class="p">],</span> <span class="s1">'NotMarried'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">'Separated'</span><span class="p">],</span> <span class="s1">'Separated'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">'Divorced'</span><span class="p">],</span> <span class="s1">'Separated'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'marital-status'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">'Widowed'</span><span class="p">],</span> <span class="s1">'Widowed'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>


<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"wage"</span><span class="p">)</span> <span class="o">==</span> <span class="s1">' &gt;50K'</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="n">train_valid_size</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
    <span class="n">test_size</span><span class="o">=</span><span class="n">train_valid_size</span><span class="p">,</span> 
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
    <span class="n">test_size</span><span class="o">=</span><span class="n">train_valid_size</span><span class="p">,</span> 
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
    <span class="n">stratify</span><span class="o">=</span><span class="n">y_train</span>
<span class="p">)</span>

<span class="n">continuous_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'age'</span><span class="p">,</span> <span class="s1">'fnlwgt'</span><span class="p">,</span> <span class="s1">'education-num'</span><span class="p">,</span> <span class="s1">'capital-gain'</span><span class="p">,</span> <span class="s1">'capital-loss'</span><span class="p">,</span> <span class="s1">'hours-per-week'</span><span class="p">]</span>
<span class="n">continuous_X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">continuous_cols</span><span class="p">]</span>
<span class="n">categorical_X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="o">~</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">continuous_cols</span><span class="p">)]</span>

<span class="n">continuous_X_valid</span> <span class="o">=</span> <span class="n">X_valid</span><span class="p">[</span><span class="n">continuous_cols</span><span class="p">]</span>
<span class="n">categorical_X_valid</span> <span class="o">=</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="o">~</span><span class="n">X_valid</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">continuous_cols</span><span class="p">)]</span>

<span class="n">continuous_X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">continuous_cols</span><span class="p">]</span>
<span class="n">categorical_X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="o">~</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">continuous_cols</span><span class="p">)]</span>

<span class="n">categorical_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">'ignore'</span><span class="p">)</span>
<span class="n">continuous_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span> <span class="c1">#MinMaxScaler(feature_range=(-1, 1))</span>

<span class="n">categorical_encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">categorical_X_train</span><span class="p">)</span>
<span class="n">continuous_scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">continuous_X_train</span><span class="p">)</span>

<span class="n">continuous_X_train</span> <span class="o">=</span> <span class="n">continuous_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">continuous_X_train</span><span class="p">)</span>
<span class="n">continuous_X_valid</span> <span class="o">=</span> <span class="n">continuous_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">continuous_X_valid</span><span class="p">)</span>
<span class="n">continuous_X_test</span> <span class="o">=</span> <span class="n">continuous_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">continuous_X_test</span><span class="p">)</span>

<span class="n">categorical_X_train</span> <span class="o">=</span> <span class="n">categorical_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">categorical_X_train</span><span class="p">)</span>
<span class="n">categorical_X_valid</span> <span class="o">=</span> <span class="n">categorical_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">categorical_X_valid</span><span class="p">)</span>
<span class="n">categorical_X_test</span> <span class="o">=</span> <span class="n">categorical_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">categorical_X_test</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">continuous_X_train</span><span class="p">,</span> <span class="n">categorical_X_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">continuous_X_valid</span><span class="p">,</span> <span class="n">categorical_X_valid</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">continuous_X_test</span><span class="p">,</span> <span class="n">categorical_X_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[171]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[171]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(torch.Size([20838, 108]), torch.Size([20838, 1]))</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Uwaga co do typów - PyTorchu wszystko w sieci neuronowej musi być typu <code>float32</code>. W szczególności trzeba uważać na konwersje z Numpy'a, który używa domyślnie typu <code>float64</code>. Może ci się przydać metoda <code>.float()</code>.</p>
<p>Uwaga co do kształtów wyjścia - wejścia do <code>nn.BCELoss</code> muszą być tego samego kształtu. Może ci się przydać metoda <code>.squeeze()</code> lub <code>.unsqueeze()</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_valid</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Podobnie jak w laboratorium 2, mamy tu do czynienia z klasyfikacją niezbalansowaną:</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">y_pos_perc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_neg_perc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">y_pos_perc</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Class percentages"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s2">"&lt;50k"</span><span class="p">,</span> <span class="s2">"&gt;=50k"</span><span class="p">],</span> <span class="p">[</span><span class="n">y_neg_perc</span><span class="p">,</span> <span class="n">y_pos_perc</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtw0lEQVR4nO3de1iUZeL/8Q+IDCjMIMgxUZQsT2mJqeQxw1xXy77iqcNqZlobaUpHdrc8dFDrWjVLs8xDbvq12NJ+rqWbaJqGZpRlmqamqyuBZjGYBajcvz+6nG8TWg2ON0Hv13U91zr3c88z99DivH3mGQgwxhgBAABYEljVCwAAAL8vxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAdQBZKSknTrrbdW9TIAoEoQH4Af7du3T3fccYeaNGmikJAQOZ1OderUSU8//bS+//77ql7e797OnTs1YcIEHThwoKqXAvyuBVX1AoCaYuXKlRo4cKAcDoeGDh2qVq1aqaysTBs3btT999+vHTt26IUXXqjqZf6u7dy5UxMnTlT37t2VlJRU1csBfreID8AP9u/fryFDhqhRo0Zau3at4uPjPfsyMjK0d+9erVy5sgpX+Nvx3XffqU6dOlW9DABViLddAD948skn9e2332revHle4XHGxRdfrHvuueec9//6669133336bLLLlNYWJicTqd69+6tjz/+uMLcZ555Ri1btlSdOnVUr149tWvXTkuWLPHsP378uMaOHaukpCQ5HA7FxMSoZ8+e+vDDD3/2OUyYMEEBAQHatWuXBg0aJKfTqaioKN1zzz0qKSmpMP/ll19WSkqKQkNDFRkZqSFDhujQoUNec7p3765WrVopLy9PXbt2VZ06dfSXv/xFklRSUqIJEybokksuUUhIiOLj49W/f3/t27fPc//y8nLNmDFDLVu2VEhIiGJjY3XHHXfom2++8XqcpKQk9e3bVxs3blT79u0VEhKiJk2aaNGiRZ45Cxcu1MCBAyVJV199tQICAhQQEKB33nlHkvTGG2+oT58+SkhIkMPhUHJysh599FGdPn26wnOfNWuWmjRpotDQULVv317vvvuuunfvru7du3vNKy0t1fjx43XxxRfL4XAoMTFRDzzwgEpLS73mvf322+rcubMiIiIUFhamSy+91PN1AmoiznwAfrBixQo1adJEV111VaXu/8UXX2j58uUaOHCgGjdurMLCQj3//PPq1q2bdu7cqYSEBEnS3LlzNWbMGA0YMMATBZ988om2bNmim266SZJ055136p///KfuvvtutWjRQseOHdPGjRv12WefqW3btr+4lkGDBikpKUmTJ0/W5s2bNXPmTH3zzTdeL+SPP/64Hn74YQ0aNEi33367jh49qmeeeUZdu3bVRx99pIiICM/cY8eOqXfv3hoyZIhuueUWxcbG6vTp0+rbt69ycnI0ZMgQ3XPPPTp+/Ljefvttffrpp0pOTpYk3XHHHVq4cKGGDx+uMWPGaP/+/Xr22Wf10UcfadOmTapdu7bncfbu3asBAwZoxIgRGjZsmObPn69bb71VKSkpatmypbp27aoxY8Zo5syZ+stf/qLmzZtLkud/Fy5cqLCwMGVmZiosLExr167VI488ouLiYj311FOex3nuued09913q0uXLho3bpwOHDigG264QfXq1VODBg0888rLy3X99ddr48aNGjVqlJo3b67t27dr+vTp+vzzz7V8+XJJ0o4dO9S3b1+1bt1akyZNksPh0N69e7Vp0yZf/i8EVC8GwHlxu91GkunXr9+vvk+jRo3MsGHDPLdLSkrM6dOnvebs37/fOBwOM2nSJM9Yv379TMuWLX/22C6Xy2RkZPzqtZwxfvx4I8lcf/31XuN33XWXkWQ+/vhjY4wxBw4cMLVq1TKPP/6417zt27eboKAgr/Fu3boZSWbOnDlec+fPn28kmWnTplVYR3l5uTHGmHfffddIMosXL/bav2rVqgrjjRo1MpLMhg0bPGNHjhwxDofD3HvvvZ6x7OxsI8msW7euwuN+9913FcbuuOMOU6dOHVNSUmKMMaa0tNRERUWZK6+80pw8edIzb+HChUaS6datm2fsH//4hwkMDDTvvvuu1zHnzJljJJlNmzYZY4yZPn26kWSOHj1a4fGBmoq3XYDzVFxcLEkKDw+v9DEcDocCA3/4djx9+rSOHTvmOf3+47dLIiIi9N///ldbt24957EiIiK0ZcsW5efnV2otGRkZXrdHjx4tSXrzzTclSa+//rrKy8s1aNAgffXVV54tLi5OTZs21bp16yo8t+HDh3uNvfbaa6pfv77n2D8WEBAgScrOzpbL5VLPnj29HiclJUVhYWEVHqdFixbq0qWL53Z0dLQuvfRSffHFF7/qeYeGhnr+fPz4cX311Vfq0qWLvvvuO+3atUuS9MEHH+jYsWMaOXKkgoL+78TxzTffrHr16nkdLzs7W82bN1ezZs281t+jRw9J8qz/zFmiN954Q+Xl5b9qrUB1R3wA58npdEr64QWrssrLyzV9+nQ1bdpUDodD9evXV3R0tD755BO53W7PvAcffFBhYWFq3769mjZtqoyMjAqn55988kl9+umnSkxMVPv27TVhwoRf/QIsSU2bNvW6nZycrMDAQM/HU/fs2SNjjJo2baro6Giv7bPPPtORI0e87n/RRRcpODjYa2zfvn269NJLvV7Af2rPnj1yu92KiYmp8Djffvtthcdp2LBhhWPUq1evwvUh57Jjxw79z//8j1wul5xOp6Kjo3XLLbdIkue/wX/+8x9JP1zD82NBQUEVPj2zZ88e7dixo8LaL7nkEknyrH/w4MHq1KmTbr/9dsXGxmrIkCF69dVXCRHUaFzzAZwnp9OphIQEffrpp5U+xhNPPKGHH35Yt912mx599FFFRkYqMDBQY8eO9XoRat68uXbv3q1//etfWrVqlV577TXNnj1bjzzyiCZOnCjph2s2unTpomXLlunf//63nnrqKU2dOlWvv/66evfu7fPazpyJOKO8vFwBAQF66623VKtWrQrzw8LCvG7/+IyCL8rLyxUTE6PFixefdX90dLTX7bOtRZKMMb/4WEVFRerWrZucTqcmTZqk5ORkhYSE6MMPP9SDDz5YqRAoLy/XZZddpmnTpp11f2JioqQfvj4bNmzQunXrtHLlSq1atUqvvPKKevTooX//+9/nfF5AdUZ8AH7Qt29fvfDCC8rNzVVqaqrP9//nP/+pq6++WvPmzfMaLyoqUv369b3G6tatq8GDB2vw4MEqKytT//799fjjjysrK0shISGSpPj4eN1111266667dOTIEbVt21aPP/74r4qPPXv2qHHjxp7be/fuVXl5uedf9snJyTLGqHHjxp5/xfsqOTlZW7Zs0cmTJ70uGv3pnDVr1qhTp06VDpif+mlInfHOO+/o2LFjev3119W1a1fP+P79+73mNWrUSNIPX5Orr77aM37q1CkdOHBArVu39lr/xx9/rGuuueacj3tGYGCgrrnmGl1zzTWaNm2annjiCf31r3/VunXrlJaW5vPzBH7reNsF8IMHHnhAdevW1e23367CwsIK+/ft26enn376nPevVatWhX+hZ2dn6/Dhw15jx44d87odHBysFi1ayBijkydP6vTp015v00hSTEyMEhISKny881xmzZrldfuZZ56RJE+49O/fX7Vq1dLEiRMrrNkYU2GNZ5Oenq6vvvpKzz77bIV9Z445aNAgnT59Wo8++miFOadOnVJRUdGvej4/VrduXUmqcN8zZxd+/HzKyso0e/Zsr3nt2rVTVFSU5s6dq1OnTnnGFy9eXOHtnUGDBunw4cOaO3duhXV8//33OnHihKQfPmb9U5dffrkk/er/ZkB1w5kPwA+Sk5O1ZMkSDR48WM2bN/f6CafvvfeesrOzf/Z3ufTt21eTJk3S8OHDddVVV2n79u1avHixmjRp4jXv2muvVVxcnDp16qTY2Fh99tlnevbZZ9WnTx+Fh4erqKhIDRo00IABA9SmTRuFhYVpzZo12rp1q/7+97//queyf/9+XX/99frDH/6g3Nxcvfzyy7rpppvUpk0bz3N97LHHlJWV5fmYaXh4uPbv369ly5Zp1KhRuu+++372MYYOHapFixYpMzNT77//vrp06aITJ05ozZo1uuuuu9SvXz9169ZNd9xxhyZPnqxt27bp2muvVe3atbVnzx5lZ2fr6aef1oABA37Vczrj8ssvV61atTR16lS53W45HA716NFDV111lerVq6dhw4ZpzJgxCggI0D/+8Y8KcRUcHKwJEyZo9OjR6tGjhwYNGqQDBw5o4cKFSk5O9jrD8ac//Umvvvqq7rzzTq1bt06dOnXS6dOntWvXLr366qtavXq12rVrp0mTJmnDhg3q06ePGjVqpCNHjmj27Nlq0KCBOnfu7NPzA6qNqvqYDVATff7552bkyJEmKSnJBAcHm/DwcNOpUyfzzDPPeD6uaczZP2p77733mvj4eBMaGmo6depkcnNzTbdu3bw+vvn888+brl27mqioKONwOExycrK5//77jdvtNsb88FHQ+++/37Rp08aEh4ebunXrmjZt2pjZs2f/4trPfNR2586dZsCAASY8PNzUq1fP3H333eb777+vMP+1114znTt3NnXr1jV169Y1zZo1MxkZGWb37t2eOd26dTvnR4O/++4789e//tU0btzY1K5d28TFxZkBAwaYffv2ec174YUXTEpKigkNDTXh4eHmsssuMw888IDJz8/3+nr26dOnwmP89OtnjDFz5841TZo0MbVq1fL62O2mTZtMx44dTWhoqElISDAPPPCAWb169Vk/mjtz5kzTqFEj43A4TPv27c2mTZtMSkqK+cMf/uA1r6yszEydOtW0bNnSOBwOU69ePZOSkmImTpzo+W+Wk5Nj+vXrZxISEkxwcLBJSEgwN954o/n888/P+nUDaoIAY37F1VgAarwJEyZo4sSJOnr0aIXrTPDzysvLFR0drf79+5/1bRYA3rjmAwB8UFJSUuHtmEWLFunrr7+u8OPVAZwd13wAgA82b96scePGaeDAgYqKitKHH36oefPmqVWrVp7fHQPg5xEfAOCDpKQkJSYmaubMmfr6668VGRmpoUOHasqUKRV+mBqAs+OaDwAAYBXXfAAAAKuIDwAAYNVv7pqP8vJy5efnKzw8/Bd/JDEAAPhtMMbo+PHjSkhI8PyW7nP5zcVHfn6+5xcuAQCA6uXQoUNq0KDBz875zcVHeHi4pB8Wf+ZXlQMAgN+24uJiJSYmel7Hf85vLj7OvNXidDqJDwAAqplfc8kEF5wCAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVgVV9QJsS3poZVUvAfjNOjClT1UvAcDvAGc+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYJVP8ZGUlKSAgIAKW0ZGhiSppKREGRkZioqKUlhYmNLT01VYWHhBFg4AAKonn+Jj69at+vLLLz3b22+/LUkaOHCgJGncuHFasWKFsrOztX79euXn56t///7+XzUAAKi2gnyZHB0d7XV7ypQpSk5OVrdu3eR2uzVv3jwtWbJEPXr0kCQtWLBAzZs31+bNm9WxY0f/rRoAAFRblb7mo6ysTC+//LJuu+02BQQEKC8vTydPnlRaWppnTrNmzdSwYUPl5uae8zilpaUqLi722gAAQM1V6fhYvny5ioqKdOutt0qSCgoKFBwcrIiICK95sbGxKigoOOdxJk+eLJfL5dkSExMruyQAAFANVDo+5s2bp969eyshIeG8FpCVlSW32+3ZDh06dF7HAwAAv20+XfNxxn/+8x+tWbNGr7/+umcsLi5OZWVlKioq8jr7UVhYqLi4uHMey+FwyOFwVGYZAACgGqrUmY8FCxYoJiZGffr08YylpKSodu3aysnJ8Yzt3r1bBw8eVGpq6vmvFAAA1Ag+n/koLy/XggULNGzYMAUF/d/dXS6XRowYoczMTEVGRsrpdGr06NFKTU3lky4AAMDD5/hYs2aNDh48qNtuu63CvunTpyswMFDp6ekqLS1Vr169NHv2bL8sFAAA1AwBxhhT1Yv4seLiYrlcLrndbjmdTr8fP+mhlX4/JlBTHJjS55cnAcBZ+PL6ze92AQAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABY5XN8HD58WLfccouioqIUGhqqyy67TB988IFnvzFGjzzyiOLj4xUaGqq0tDTt2bPHr4sGAADVl0/x8c0336hTp06qXbu23nrrLe3cuVN///vfVa9ePc+cJ598UjNnztScOXO0ZcsW1a1bV7169VJJSYnfFw8AAKqfIF8mT506VYmJiVqwYIFnrHHjxp4/G2M0Y8YM/e1vf1O/fv0kSYsWLVJsbKyWL1+uIUOG+GnZAACguvLpzMf/+3//T+3atdPAgQMVExOjK664QnPnzvXs379/vwoKCpSWluYZc7lc6tChg3Jzc896zNLSUhUXF3ttAACg5vIpPr744gs999xzatq0qVavXq0///nPGjNmjF566SVJUkFBgSQpNjbW636xsbGefT81efJkuVwuz5aYmFiZ5wEAAKoJn+KjvLxcbdu21RNPPKErrrhCo0aN0siRIzVnzpxKLyArK0tut9uzHTp0qNLHAgAAv30+xUd8fLxatGjhNda8eXMdPHhQkhQXFydJKiws9JpTWFjo2fdTDodDTqfTawMAADWXT/HRqVMn7d6922vs888/V6NGjST9cPFpXFyccnJyPPuLi4u1ZcsWpaam+mG5AACguvPp0y7jxo3TVVddpSeeeEKDBg3S+++/rxdeeEEvvPCCJCkgIEBjx47VY489pqZNm6px48Z6+OGHlZCQoBtuuOFCrB8AAFQzPsXHlVdeqWXLlikrK0uTJk1S48aNNWPGDN18882eOQ888IBOnDihUaNGqaioSJ07d9aqVasUEhLi98UDAIDqJ8AYY6p6ET9WXFwsl8slt9t9Qa7/SHpopd+PCdQUB6b0qeolAKimfHn95ne7AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVPsXHhAkTFBAQ4LU1a9bMs7+kpEQZGRmKiopSWFiY0tPTVVhY6PdFAwCA6svnMx8tW7bUl19+6dk2btzo2Tdu3DitWLFC2dnZWr9+vfLz89W/f3+/LhgAAFRvQT7fIShIcXFxFcbdbrfmzZunJUuWqEePHpKkBQsWqHnz5tq8ebM6dux41uOVlpaqtLTUc7u4uNjXJQEAgGrE5zMfe/bsUUJCgpo0aaKbb75ZBw8elCTl5eXp5MmTSktL88xt1qyZGjZsqNzc3HMeb/LkyXK5XJ4tMTGxEk8DAABUFz7FR4cOHbRw4UKtWrVKzz33nPbv368uXbro+PHjKigoUHBwsCIiIrzuExsbq4KCgnMeMysrS26327MdOnSoUk8EAABUDz697dK7d2/Pn1u3bq0OHTqoUaNGevXVVxUaGlqpBTgcDjkcjkrdFwAAVD/n9VHbiIgIXXLJJdq7d6/i4uJUVlamoqIirzmFhYVnvUYEAAD8Pp1XfHz77bfat2+f4uPjlZKSotq1aysnJ8ezf/fu3Tp48KBSU1PPe6EAAKBm8Oltl/vuu0/XXXedGjVqpPz8fI0fP161atXSjTfeKJfLpREjRigzM1ORkZFyOp0aPXq0UlNTz/lJFwAA8PvjU3z897//1Y033qhjx44pOjpanTt31ubNmxUdHS1Jmj59ugIDA5Wenq7S0lL16tVLs2fPviALBwAA1VOAMcZU9SJ+rLi4WC6XS263W06n0+/HT3popd+PCdQUB6b0qeolAKimfHn95ne7AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsOq/4mDJligICAjR27FjPWElJiTIyMhQVFaWwsDClp6ersLDwfNcJAABqiErHx9atW/X888+rdevWXuPjxo3TihUrlJ2drfXr1ys/P1/9+/c/74UCAICaoVLx8e233+rmm2/W3LlzVa9ePc+42+3WvHnzNG3aNPXo0UMpKSlasGCB3nvvPW3evNlviwYAANVXpeIjIyNDffr0UVpamtd4Xl6eTp486TXerFkzNWzYULm5uWc9VmlpqYqLi702AABQcwX5eoelS5fqww8/1NatWyvsKygoUHBwsCIiIrzGY2NjVVBQcNbjTZ48WRMnTvR1GQAAoJry6czHoUOHdM8992jx4sUKCQnxywKysrLkdrs926FDh/xyXAAA8NvkU3zk5eXpyJEjatu2rYKCghQUFKT169dr5syZCgoKUmxsrMrKylRUVOR1v8LCQsXFxZ31mA6HQ06n02sDAAA1l09vu1xzzTXavn2719jw4cPVrFkzPfjgg0pMTFTt2rWVk5Oj9PR0SdLu3bt18OBBpaam+m/VAACg2vIpPsLDw9WqVSuvsbp16yoqKsozPmLECGVmZioyMlJOp1OjR49WamqqOnbs6L9VAwCAasvnC05/yfTp0xUYGKj09HSVlpaqV69emj17tr8fBgAAVFMBxhhT1Yv4seLiYrlcLrnd7gty/UfSQyv9fkygpjgwpU9VLwFANeXL6ze/2wUAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYJVP8fHcc8+pdevWcjqdcjqdSk1N1VtvveXZX1JSooyMDEVFRSksLEzp6ekqLCz0+6IBAED15VN8NGjQQFOmTFFeXp4++OAD9ejRQ/369dOOHTskSePGjdOKFSuUnZ2t9evXKz8/X/37978gCwcAANVTgDHGnM8BIiMj9dRTT2nAgAGKjo7WkiVLNGDAAEnSrl271Lx5c+Xm5qpjx46/6njFxcVyuVxyu91yOp3ns7SzSnpopd+PCdQUB6b0qeolAKimfHn9rvQ1H6dPn9bSpUt14sQJpaamKi8vTydPnlRaWppnTrNmzdSwYUPl5uae8zilpaUqLi722gAAQM3lc3xs375dYWFhcjgcuvPOO7Vs2TK1aNFCBQUFCg4OVkREhNf82NhYFRQUnPN4kydPlsvl8myJiYk+PwkAAFB9+Bwfl156qbZt26YtW7boz3/+s4YNG6adO3dWegFZWVlyu92e7dChQ5U+FgAA+O0L8vUOwcHBuvjiiyVJKSkp2rp1q55++mkNHjxYZWVlKioq8jr7UVhYqLi4uHMez+FwyOFw+L5yAABQLZ33z/koLy9XaWmpUlJSVLt2beXk5Hj27d69WwcPHlRqaur5PgwAAKghfDrzkZWVpd69e6thw4Y6fvy4lixZonfeeUerV6+Wy+XSiBEjlJmZqcjISDmdTo0ePVqpqam/+pMuAACg5vMpPo4cOaKhQ4fqyy+/lMvlUuvWrbV69Wr17NlTkjR9+nQFBgYqPT1dpaWl6tWrl2bPnn1BFg4AAKqn8/45H/7Gz/kAqg4/5wNAZVn5OR8AAACVQXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVBVb0AAPC3pIdWVvUSgN+0A1P6VOnjc+YDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsMqn+Jg8ebKuvPJKhYeHKyYmRjfccIN2797tNaekpEQZGRmKiopSWFiY0tPTVVhY6NdFAwCA6sun+Fi/fr0yMjK0efNmvf322zp58qSuvfZanThxwjNn3LhxWrFihbKzs7V+/Xrl5+erf//+fl84AAConoJ8mbxq1Sqv2wsXLlRMTIzy8vLUtWtXud1uzZs3T0uWLFGPHj0kSQsWLFDz5s21efNmdezY0X8rBwAA1dJ5XfPhdrslSZGRkZKkvLw8nTx5UmlpaZ45zZo1U8OGDZWbm3vWY5SWlqq4uNhrAwAANVel46O8vFxjx45Vp06d1KpVK0lSQUGBgoODFRER4TU3NjZWBQUFZz3O5MmT5XK5PFtiYmJllwQAAKqBSsdHRkaGPv30Uy1duvS8FpCVlSW32+3ZDh06dF7HAwAAv20+XfNxxt13361//etf2rBhgxo0aOAZj4uLU1lZmYqKirzOfhQWFiouLu6sx3I4HHI4HJVZBgAAqIZ8OvNhjNHdd9+tZcuWae3atWrcuLHX/pSUFNWuXVs5OTmesd27d+vgwYNKTU31z4oBAEC15tOZj4yMDC1ZskRvvPGGwsPDPddxuFwuhYaGyuVyacSIEcrMzFRkZKScTqdGjx6t1NRUPukCAAAk+Rgfzz33nCSpe/fuXuMLFizQrbfeKkmaPn26AgMDlZ6ertLSUvXq1UuzZ8/2y2IBAED151N8GGN+cU5ISIhmzZqlWbNmVXpRAACg5uJ3uwAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArPI5PjZs2KDrrrtOCQkJCggI0PLly732G2P0yCOPKD4+XqGhoUpLS9OePXv8tV4AAFDN+RwfJ06cUJs2bTRr1qyz7n/yySc1c+ZMzZkzR1u2bFHdunXVq1cvlZSUnPdiAQBA9Rfk6x169+6t3r17n3WfMUYzZszQ3/72N/Xr10+StGjRIsXGxmr58uUaMmTI+a0WAABUe3695mP//v0qKChQWlqaZ8zlcqlDhw7Kzc09631KS0tVXFzstQEAgJrLr/FRUFAgSYqNjfUaj42N9ez7qcmTJ8vlcnm2xMREfy4JAAD8xlT5p12ysrLkdrs926FDh6p6SQAA4ALya3zExcVJkgoLC73GCwsLPft+yuFwyOl0em0AAKDm8mt8NG7cWHFxccrJyfGMFRcXa8uWLUpNTfXnQwEAgGrK50+7fPvtt9q7d6/n9v79+7Vt2zZFRkaqYcOGGjt2rB577DE1bdpUjRs31sMPP6yEhATdcMMN/lw3AACopnyOjw8++EBXX32153ZmZqYkadiwYVq4cKEeeOABnThxQqNGjVJRUZE6d+6sVatWKSQkxH+rBgAA1ZbP8dG9e3cZY865PyAgQJMmTdKkSZPOa2EAAKBmqvJPuwAAgN8X4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKsuWHzMmjVLSUlJCgkJUYcOHfT+++9fqIcCAADVyAWJj1deeUWZmZkaP368PvzwQ7Vp00a9evXSkSNHLsTDAQCAauSCxMe0adM0cuRIDR8+XC1atNCcOXNUp04dzZ8//0I8HAAAqEaC/H3AsrIy5eXlKSsryzMWGBiotLQ05ebmVphfWlqq0tJSz2232y1JKi4u9vfSJEnlpd9dkOMCNcGF+r6zje9z4OddiO/1M8c0xvziXL/Hx1dffaXTp08rNjbWazw2Nla7du2qMH/y5MmaOHFihfHExER/Lw3AL3DNqOoVALDhQn6vHz9+XC6X62fn+D0+fJWVlaXMzEzP7fLycn399deKiopSQEBAFa4MF1pxcbESExN16NAhOZ3Oql4OgAuE7/XfB2OMjh8/roSEhF+c6/f4qF+/vmrVqqXCwkKv8cLCQsXFxVWY73A45HA4vMYiIiL8vSz8hjmdTv5CAn4H+F6v+X7pjMcZfr/gNDg4WCkpKcrJyfGMlZeXKycnR6mpqf5+OAAAUM1ckLddMjMzNWzYMLVr107t27fXjBkzdOLECQ0fPvxCPBwAAKhGLkh8DB48WEePHtUjjzyigoICXX755Vq1alWFi1Dx++ZwODR+/PgKb7sBqFn4XsdPBZhf85kYAAAAP+F3uwAAAKuIDwAAYBXxAQAArCI+AACAVcQHqo1bb71VN9xwQ1UvA0AVCQgI0PLly6t6GfAD4gNWJCUlKSAgwGubMmWK15xPPvlEXbp0UUhIiBITE/Xkk09W0WoB+NM777xT4fs/ICBABQUFXvNmzZqlpKQkhYSEqEOHDnr//feraMW40Kr8d7ug5vrmm29Uu3ZthYWFSZImTZqkkSNHevaHh4d7/lxcXKxrr71WaWlpmjNnjrZv367bbrtNERERGjVqlPW1A79H+fn5iomJUVDQhXlp2L17t9ePV4+JifH8+ZVXXlFmZqbmzJmjDh06aMaMGerVq5d2797tNQ81A2c+4FenTp3SypUrNXDgQMXHx2vfvn2efeHh4YqLi/NsdevW9exbvHixysrKNH/+fLVs2VJDhgzRmDFjNG3atHM+1tatWxUdHa2pU6de0OcE/F7MnTtXDRo00H333aft27f7/fgxMTFefwcEBv7fS9C0adM0cuRIDR8+XC1atNCcOXNUp04dzZ8//5zHGz9+vOLj4/XJJ5/4fa24sIgP+MX27dt17733qkGDBho6dKiio6O1bt06tWnTxjNnypQpioqK0hVXXKGnnnpKp06d8uzLzc1V165dFRwc7Bk786+eb775psLjrV27Vj179tTjjz+uBx988MI+OeB34sEHH9TTTz+tzz77TG3btlXbtm01c+ZMHT16tMLcli1bKiws7Jxb7969K9zn8ssvV3x8vHr27KlNmzZ5xsvKypSXl6e0tDTPWGBgoNLS0pSbm1vhOMYYjR49WosWLdK7776r1q1b++krAFt42wWVduzYMb388st66aWXtGPHDv3xj3/U7Nmz1bdvX6+IkKQxY8aobdu2ioyM1HvvvaesrCx9+eWXnjMbBQUFaty4sdd9zvw4/oKCAtWrV88zvmzZMg0dOlQvvviiBg8efIGfJfD7ERISosGDB2vw4ME6cuSIlixZooULF+q+++7TH//4Rw0bNkzXXXedgoKC9Oabb+rkyZPnPFZoaKjnz/Hx8ZozZ47atWun0tJSvfjii+revbu2bNmitm3b6quvvtLp06cr/AqO2NhY7dq1y2vs1KlTuuWWW/TRRx9p48aNuuiii/z7RYAdBqik8ePHG0mmS5cu5uDBgz7dd968eSYoKMiUlJQYY4zp2bOnGTVqlNecHTt2GElm586dxhhjhg0bZuLi4kytWrXMsmXL/PIcAPyyN99808TExBhJ5qOPPvLLMbt27WpuueUWY4wxhw8fNpLMe++95zXn/vvvN+3bt/fclmQaNGhgkpOTzdGjR/2yDlQN3nZBpY0aNUqPPvqoCgoK1LJlSw0fPlxr165VeXn5L963Q4cOOnXqlA4cOCBJiouLU2FhodecM7fj4uI8Y8nJyWrWrJnmz5//s//qAnB+jh8/rgULFqhHjx667rrr1KpVK7300ktq0aKFpMq97fJj7du31969eyVJ9evXV61atc76d8CPv/8lqWfPnjp8+LBWr17tx2cL24gPVFpCQoL+9re/6fPPP9eqVasUHBys/v37q1GjRnrooYe0Y8eOc95327ZtCgwM9FzFnpqaqg0bNngFxdtvv61LL73U6y2X+vXra+3atdq7d68GDRpEgAB+dPr0ab311lu66aabFBsbqylTpuiaa67RF198oZycHA0dOtTzluqbb76pbdu2nXN78cUXf/axtm3bpvj4eElScHCwUlJSlJOT49lfXl6unJwcpaamet3v+uuv15IlS3T77bdr6dKlfv4KwJqqPvWCmuX77783//u//2t69eplatWqZT755BPz3nvvmenTp5tt27aZffv2mZdfftlER0eboUOHeu5XVFRkYmNjzZ/+9Cfz6aefmqVLl5o6deqY559/3jNn2LBhpl+/fsYYY7788kvTrFkzk56ebk6ePGn7aQI10qRJk4zL5TKjRo0ymzZt8ttxp0+fbpYvX2727Nljtm/fbu655x4TGBho1qxZ45mzdOlS43A4zMKFC83OnTvNqFGjTEREhCkoKPDMkeR5yzU7O9uEhISY7Oxsv60T9hAfuGAOHz5s3G63ycvLMx06dDAul8uEhISY5s2bmyeeeMJzvccZH3/8sencubNxOBzmoosuMlOmTPHa/+P4MMaY/Px8c8kll5hBgwaZU6dO2XhKQI22f/9+8/333/v9uFOnTjXJyckmJCTEREZGmu7du5u1a9dWmPfMM8+Yhg0bmuDgYNO+fXuzefNmr/0/jg9jjHnllVdMSEiIee211/y+ZlxYAcYYU9VnXwAAwO8H13wAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKz6/8ZZsRD+YNnCAAAAAElFTkSuQmCC"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>W związku z powyższym będziemy używać odpowiednich metryk, czyli AUROC, precyzji i czułości.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-3-(1.0-punkt)">Zadanie 3 (1.0 punkt)<a class="anchor-link" href="#Zadanie-3-(1.0-punkt)">&#182;</a></h4><p>Zaimplementuj regresję logistyczną dla tego zbioru danych, używając PyTorcha. Dane wejściowe zostały dla ciebie przygotowane w komórkach poniżej.</p>
<p>Sama sieć składa się z 2 elementów:</p>
<ul>
<li>warstwa liniowa <code>nn.Linear</code>, przekształcająca wektor wejściowy na 1 wyjście - logit</li>
<li>aktywacja sigmoidalna <code>nn.Sigmoid</code>, przekształcająca logit na prawdopodobieństwo klasy pozytywnej</li>
</ul>
<p>Użyj binarnej entropii krzyżowej <code>nn.BCELoss</code> jako funkcji kosztu. Użyj optymalizatora SGD ze stałą uczącą <code>1e-3</code>. Trenuj przez 3000 epok. Pamiętaj, aby przekazać do optymalizatora <code>torch.optim.SGD</code> parametry sieci (metoda <code>.parameters()</code>). Dopisz logowanie kosztu raz na 100 epok.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[174]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">3000</span>

<span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">best_loss</span> <span class="o">&gt;</span> <span class="n">loss</span><span class="p">:</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="se">\t</span><span class="s2">Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Best loss: </span><span class="si">{</span><span class="n">best_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch: 100/3000	Loss: 0.6276997923851013
Epoch: 200/3000	Loss: 0.6031697392463684
Epoch: 300/3000	Loss: 0.5826571583747864
Epoch: 400/3000	Loss: 0.5653572082519531
Epoch: 500/3000	Loss: 0.5506343245506287
Epoch: 600/3000	Loss: 0.5379889011383057
Epoch: 700/3000	Loss: 0.5270274877548218
Epoch: 800/3000	Loss: 0.5174400806427002
Epoch: 900/3000	Loss: 0.508981466293335
Epoch: 1000/3000	Loss: 0.5014569759368896
Epoch: 1100/3000	Loss: 0.4947112500667572
Epoch: 1200/3000	Loss: 0.48861974477767944
Epoch: 1300/3000	Loss: 0.483082115650177
Epoch: 1400/3000	Loss: 0.47801676392555237
Epoch: 1500/3000	Loss: 0.4733572006225586
Epoch: 1600/3000	Loss: 0.4690491259098053
Epoch: 1700/3000	Loss: 0.46504727005958557
Epoch: 1800/3000	Loss: 0.46131429076194763
Epoch: 1900/3000	Loss: 0.4578188955783844
Epoch: 2000/3000	Loss: 0.4545348584651947
Epoch: 2100/3000	Loss: 0.45143988728523254
Epoch: 2200/3000	Loss: 0.4485150873661041
Epoch: 2300/3000	Loss: 0.44574421644210815
Epoch: 2400/3000	Loss: 0.4431132972240448
Epoch: 2500/3000	Loss: 0.44061020016670227
Epoch: 2600/3000	Loss: 0.4382243752479553
Epoch: 2700/3000	Loss: 0.43594664335250854
Epoch: 2800/3000	Loss: 0.43376874923706055
Epoch: 2900/3000	Loss: 0.4316834509372711
Epoch: 3000/3000	Loss: 0.4296844005584717
Best loss: 0.4296844005584717
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Teraz trzeba sprawdzić, jak poszło naszej sieci. W PyTorchu sieć pracuje zawsze w jednym z dwóch trybów: treningowym lub ewaluacyjnym (predykcyjnym). Ten drugi wyłącza niektóre mechanizmy, które są używane tylko podczas treningu, w szczególności regularyzację dropout. Do przełączania służą metody modelu <code>.train()</code> i <code>.eval()</code>.</p>
<p>Dodatkowo podczas liczenia predykcji dobrze jest wyłączyć liczenie gradientów, bo nie będą potrzebne, a oszczędza to czas i pamięć. Używa się do tego menadżera kontekstu <code>with torch.no_grad():</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[175]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">precision_recall_fscore_support</span><span class="p">,</span> <span class="n">roc_auc_score</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

<span class="n">auroc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">auroc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>AUROC: 86.04%
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Jest to całkiem dobry wynik, a może być jeszcze lepszy. Sprawdźmy dla pewności jeszcze inne metryki: precyzję, recall oraz F1-score. Dodatkowo narysujemy krzywą precision-recall, czyli jak zmieniają się te metryki w zależności od przyjętego progu (threshold) prawdopodobieństwa, powyżej którego przyjmujemy klasę pozytywną. Taką krzywą należy rysować na zbiorze walidacyjnym, bo później chcemy wykorzystać tę informację do doboru progu, a nie chcemy mieć wycieku danych testowych (data leakage).</p>
<p>Poniżej zaimplementowano także funkcję <code>get_optimal_threshold()</code>, która sprawdza, dla którego progu uzyskujemy maksymalny F1-score, i zwraca indeks oraz wartość optymalnego progu. Przyda ci się ona w dalszej części laboratorium.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">PrecisionRecallDisplay</span>


<span class="k">def</span> <span class="nf">get_optimal_threshold</span><span class="p">(</span>
    <span class="n">precisions</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> 
    <span class="n">recalls</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> 
    <span class="n">thresholds</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    
    <span class="n">numerator</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">precisions</span> <span class="o">*</span> <span class="n">recalls</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">precisions</span> <span class="o">+</span> <span class="n">recalls</span>
    <span class="n">f1_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">denominator</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">numerator</span><span class="p">),</span> <span class="n">where</span><span class="o">=</span><span class="n">denominator</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="n">optimal_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">f1_scores</span><span class="p">)</span>
    <span class="n">optimal_threshold</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">optimal_idx</span><span class="p">,</span> <span class="n">optimal_threshold</span>


<span class="k">def</span> <span class="nf">plot_precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_score</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_score</span><span class="p">)</span>
    <span class="n">optimal_idx</span><span class="p">,</span> <span class="n">optimal_threshold</span> <span class="o">=</span> <span class="n">get_optimal_threshold</span><span class="p">(</span><span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">)</span>

    <span class="n">disp</span> <span class="o">=</span> <span class="n">PrecisionRecallDisplay</span><span class="p">(</span><span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span><span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision-recall curve (opt. thresh.: </span><span class="si">{</span><span class="n">optimal_threshold</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">recalls</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">"green"</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">"-."</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">precisions</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">"green"</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">"-."</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_pred_valid_score</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X_valid</span><span class="p">))</span>

<span class="n">plot_precision_recall_curve</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred_valid_score</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoNElEQVR4nO3deVhU1f8H8PfMwAw7qCxuKLgr7rikpqCiKGRppZamROZu35JvmaiJS4mlmVbilltquX1NywVTck3LXDA30BQEFxA0QbYZZub+/uDn6MiwzAhzYXi/nmee595zz73zmTsD85lzzz1HIgiCACIiIiILIRU7ACIiIqKyxOSGiIiILAqTGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii8Lkhiqkt99+G15eXkbtc/jwYUgkEhw+fLhcYqpMEhMTIZFIsG7dOl3ZrFmzIJFIxAtKRFqtFi1btsRnn30mdigmW7duHSQSCU6fPi12KAAqXjyWYPny5ahXrx6USqXYoVR6TG4IwJN/VI8fNjY2aNKkCSZNmoTU1FSxwyN6Lj/++COSk5MxadKkcn2eqKgovYRSrGNYoocPH2LMmDFwc3ODvb09evbsibNnz5Zq31WrVsHPzw8eHh5QKBTw9vZGaGgoEhMT9eolJydj9uzZ6NSpE6pVqwZXV1f4+/vj4MGDhY4ZExODd955B02aNIGdnR0aNGiAd999F3fv3jUYw4kTJ/Diiy/Czs4ONWvWxH/+8x9kZWXp1Xn77behUqmwYsWK0p0UKpKV2AFQxTJnzhx4e3sjLy8Px48fx7Jly7B3715cvHgRdnZ2Zotj1apV0Gq1Ru3To0cP5ObmQi6Xl1NUVFktWLAAb7zxBpydncv1eaKiouDq6oq3335b1GNYGq1Wi+DgYJw/fx4fffQRXF1dERUVBX9/f5w5cwaNGzcudv9z587B29sbL7/8MqpVq4aEhASsWrUKu3fvxvnz51G7dm0AwK5du/D5559j4MCBCAkJgVqtxvfff48+ffpgzZo1CA0N1R3z448/xoMHDzB48GA0btwYN27cwLfffovdu3cjNjYWNWvW1NWNjY1F79690bx5cyxatAi3bt3CwoULce3aNezbt09Xz8bGBiEhIVi0aBHee++9KtvSWiYEIkEQ1q5dKwAQ/vrrL73ysLAwAYDwww8/FLlvVlZWeYdXKeXm5goajUaU505ISBAACGvXrtWVRURECBXhTz4/P19QKpVme76zZ88KAISDBw+W+3P5+PgIfn5+5XKMov5GS0Or1Qo5OTnPFVdZxmOsLVu2CACEbdu26cru3bsnuLi4CG+++aZJxzx9+rQAQIiMjNSVXbx4UUhLS9Orl5eXJzRr1kyoW7euXvmRI0cK/X0fOXJEACBMnz5dr7x///5CrVq1hIyMDF3ZqlWrBADC/v37DcYVExNj0uuiArwsRcXq1asXACAhIQFAQbOpg4MDrl+/jqCgIDg6OmL48OEACn5dLV68GD4+PrCxsYGHhwfGjh2Lf//9t9Bx9+3bBz8/Pzg6OsLJyQkdO3bEDz/8oNtuqM/N5s2b4evrq9unVatWWLJkiW57UX1utm3bBl9fX9ja2sLV1RVvvfUWbt++rVfn8eu6ffs2Bg4cCAcHB7i5ueHDDz+ERqMp8Tw9fu7NmzdjxowZqFOnDuzs7JCZmQkA+PPPP9GvXz84OzvDzs4Ofn5++P333wsd5/bt2xg1ahRq166taz4fP348VCoVAODBgwf48MMP0apVKzg4OMDJyQn9+/fH+fPnS4zRGH/++SeCgoJQrVo12Nvbo3Xr1nrn2t/fH/7+/oX2e/Z9e9z3Z+HChVi8eDEaNmwIhUKBc+fOwcrKCrNnzy50jPj4eEgkEnz77be6socPH+KDDz6Ap6cnFAoFGjVqhM8//7xUrXs7d+6EXC5Hjx49Cm07d+4c+vfvDycnJzg4OKB37974448/9Oo8vmR79OhRjB07FjVq1ICTkxNGjhyp99n28vLCpUuXcOTIEd3lXUPnqDilOYZSqURYWJju8sygQYOQlpZW6DgvvfQS9u/fjw4dOsDW1lZ3qaO057Kkvzdj4jEkPz8fcXFxRV7Gedr27dvh4eGBV199VVfm5uaGIUOGYNeuXSb1UXn8OX348KGuzMfHB66urnr1FAoFgoKCcOvWLTx69EhX3qNHD0il+l+hPXr0QPXq1XHlyhVdWWZmJg4cOIC33noLTk5OuvKRI0fCwcEBW7du1TuGr68vqlevjl27dhn9mugJXpaiYl2/fh0AUKNGDV2ZWq1GYGAgXnzxRSxcuFB3uWrs2LFYt24dQkND8Z///AcJCQn49ttvce7cOfz++++wtrYGUPBl8c4778DHxwfh4eFwcXHBuXPnEB0djWHDhhmM48CBA3jzzTfRu3dvfP755wCAK1eu4Pfff8f7779fZPyP4+nYsSMiIyORmpqKJUuW4Pfff8e5c+fg4uKiq6vRaBAYGIjOnTtj4cKFOHjwIL788ks0bNgQ48ePL9X5mjt3LuRyOT788EMolUrI5XL89ttv6N+/P3x9fREREQGpVIq1a9eiV69eOHbsGDp16gQAuHPnDjp16qTrW9CsWTPcvn0b27dvR05ODuRyOW7cuIGdO3di8ODB8Pb2RmpqKlasWAE/Pz9cvnxZ17z+PA4cOICXXnoJtWrVwvvvv4+aNWviypUr2L17d7Hnujhr165FXl4exowZA4VCgVq1asHPzw9bt25FRESEXt0tW7ZAJpNh8ODBAICcnBz4+fnh9u3bGDt2LOrVq4cTJ04gPDwcd+/exeLFi4t97hMnTqBly5a6z99jly5dQvfu3eHk5IQpU6bA2toaK1asgL+/P44cOYLOnTvr1Z80aRJcXFwwa9YsxMfHY9myZbh586YusV28eDHee+89ODg4YPr06QAADw8Po85TaY7x3nvvoVq1aoiIiEBiYiIWL16MSZMmYcuWLXr14uPj8eabb2Ls2LEYPXo0mjZtWupzaczfW2njedbt27fRvHlzhISElNjH6Ny5c2jfvn2hZKJTp05YuXIlrl69ilatWhV7DAC4f/8+NBoNkpKSMGfOHABA7969S9wvJSUFdnZ2JV6az8rKQlZWll6CdOHCBajVanTo0EGvrlwuR9u2bXHu3LlCx2nfvr3BHz9kBLGbjqhieNzEfPDgQSEtLU1ITk4WNm/eLNSoUUOwtbUVbt26JQiCIISEhAgAhKlTp+rtf+zYMQGAsGnTJr3y6OhovfKHDx8Kjo6OQufOnYXc3Fy9ulqtVrccEhIi1K9fX7f+/vvvC05OToJarS7yNRw6dEgAIBw6dEgQBEFQqVSCu7u70LJlS73n2r17twBAmDlzpt7zARDmzJmjd8x27doJvr6+RT7ns8/doEEDveZ/rVYrNG7cWAgMDNR7fTk5OYK3t7fQp08fXdnIkSMFqVRqsJn/8b55eXmFmsITEhIEhUKhF7upl6XUarXg7e0t1K9fX/j3338NxiAIguDn52fw0smz79vjOJycnIR79+7p1V2xYoUAQLhw4YJeeYsWLYRevXrp1ufOnSvY29sLV69e1as3depUQSaTCUlJScW+prp16wqvvfZaofKBAwcKcrlcuH79uq7szp07gqOjo9CjRw9d2eO/DV9fX0GlUunKv/jiCwGAsGvXLl2ZOS5LBQQE6L0XkydPFmQymfDw4UNdWf369QUAQnR0tN4xSnsuS/P3Zkw8hjz+bISEhBRbTxAEwd7eXnjnnXcKle/Zs8fg6yyKQqEQAAgAhBo1aghff/11iftcu3ZNsLGxEUaMGFFi3blz5xa6pLRt2zYBgHD06NFC9QcPHizUrFmzUPmYMWMEW1vbEp+PisbLUqQnICAAbm5u8PT0xBtvvAEHBwf89NNPqFOnjl69Z1sytm3bBmdnZ/Tp0wfp6em6h6+vLxwcHHDo0CEABb8IHz16hKlTp8LGxkbvGMV1nnNxcUF2djYOHDhQ6tdy+vRp3Lt3DxMmTNB7ruDgYDRr1gx79uwptM+4ceP01rt3744bN26U+jlDQkJga2urW4+NjcW1a9cwbNgw3L9/X3desrOz0bt3bxw9ehRarRZarRY7d+7EgAEDCv3CA56cG4VCofv1qtFocP/+fTg4OKBp06alvnOkOOfOnUNCQgI++OADvVatp2MwxWuvvQY3Nze9sldffRVWVlZ6v/AvXryIy5cvY+jQobqybdu2oXv37qhWrZreZysgIAAajQZHjx4t9rnv37+PatWq6ZVpNBr8+uuvGDhwIBo0aKArr1WrFoYNG4bjx4/rLik+NmbMGL3Wn/Hjx8PKygp79+4t/YkoA2PGjNF7L7p37w6NRoObN2/q1fP29kZgYKBeWWnPpTF/b6WN51leXl4QBKFUd4bl5uZCoVAUKn/8d52bm1viMYCCy+F79+7Fl19+iXr16iE7O7vY+jk5ORg8eDBsbW0xf/78YusePXoUs2fPxpAhQ3SX85+Oraj4DcVerVo15ObmIicnpzQviwzgZSnSs3TpUjRp0gRWVlbw8PBA06ZNCzUFW1lZoW7dunpl165dQ0ZGBtzd3Q0e9969ewCeXOZq2bKlUXFNmDABW7duRf/+/VGnTh307dsXQ4YMQb9+/Yrc5/E/16ZNmxba1qxZMxw/flyvzMbGptAXcLVq1fT6VaSlpen1wXFwcICDg4Nu3dvbW2//a9euAShIeoqSkZEBlUqFzMzMEs+LVqvFkiVLEBUVhYSEBL1Ynr50aCpT35+SPHteAMDV1RW9e/fG1q1bMXfuXAAFl6SsrKz0+lZcu3YNf//9d6H35rHHn63iCIKgt56WloacnByDn43mzZtDq9UiOTkZPj4+uvJn78hxcHBArVq1Ct1OXN7q1aunt/44cXu2b5uhc17ac2nM31tp43ketra2BvvV5OXl6baXRs+ePQEA/fv3xyuvvIKWLVvCwcHB4BABGo0Gb7zxBi5fvox9+/YVe8k3Li4OgwYNQsuWLfHdd98Vih1AkfEbiv3x55V3S5mOyQ3p6dSpk8GWg6c93XrwmFarhbu7OzZt2mRwn6L+mZaWu7s7YmNjsX//fuzbtw/79u3D2rVrMXLkSKxfv/65jv2YTCYrsU7Hjh31fpFGRERg1qxZuvVn/1E97qS5YMECtG3b1uAxHRwc8ODBg1LFOG/ePHzyySd45513MHfuXFSvXh1SqRQffPCB0bfOPw+JRFIoYQBQZOfror583njjDYSGhiI2NhZt27bF1q1b0bt3b70+C1qtFn369MGUKVMMHqNJkybFxlqjRo0y/aIVW1Gf02ffD0PnvLTn0pi/t9LG8zxq1aplsOPx4zJT+po1bNgQ7dq1w6ZNmwwmN6NHj8bu3buxadMmvZaYZyUnJ6Nv375wdnbG3r174ejoWCj2p2N9Nn5Dsf/777+ws7MrddJGhTG5oTLRsGFDHDx4EN26dSv2D7Jhw4YACi4/NGrUyKjnkMvlGDBgAAYMGACtVosJEyZgxYoV+OSTTwweq379+gAKOlY++88pPj5et90YmzZt0mtGfvqShiGPX6+TkxMCAgKKrOfm5gYnJydcvHix2ONt374dPXv2xOrVq/XKHz58WOguD1M8/f4UF2+1atUMXq4r6VLEswYOHIixY8fqLk1dvXoV4eHhhWLKysoqNp7iNGvWTHe332Nubm6ws7NDfHx8ofpxcXGQSqXw9PTUK7927Zrulz9Q0Hn07t27CAoK0pWVxS/t8vy1bsy5NPbvrTy1bdsWx44dg1ar1fth9eeff8LOzq7EBLcoubm5BltUPvroI6xduxaLFy/Gm2++WeT+9+/fR9++faFUKhETE6NLZJ7WsmVLWFlZ4fTp0xgyZIiuXKVSITY2Vq/ssYSEBDRv3tyk10QF2OeGysSQIUOg0Wh0lxeeplardbdb9u3bF46OjoiMjNQ1KT9W3C+9+/fv661LpVK0bt0agOHmXgDo0KED3N3dsXz5cr06+/btw5UrVxAcHFyq1/a0bt26ISAgQPcoKbnx9fVFw4YNsXDhwkKjkQLQ3TIrlUoxcOBA/PLLLwaHs398bmQyWaHztG3btkK3tpuqffv28Pb2xuLFi/VukX06BqDgSzIuLk7vlt/z588bfYeHi4sLAgMDsXXrVmzevBlyuRwDBw7UqzNkyBCcPHkS+/fvL7T/w4cPoVari32OLl264OLFi3qfAZlMhr59+2LXrl16l5VSU1Pxww8/4MUXX9S7bRcAVq5cifz8fN36smXLoFar0b9/f12Zvb19ofMGGHfbc1HHKAulPZem/L0V5+7du4iLi9M7f8ack9dffx2pqanYsWOHriw9PR3btm3DgAED9PqzXL9+XXd5FSj4/2Oo5e7UqVO4cOFCoZbqBQsWYOHChZg2bVqxdwdmZ2cjKCgIt2/fxt69e4scSNDZ2RkBAQHYuHGj3q3kGzZsQFZWlu6uwKedPXsWXbt2LfK5qWRsuaEy4efnh7FjxyIyMhKxsbHo27cvrK2tce3aNWzbtg1LlizB66+/DicnJ3z11Vd499130bFjRwwbNgzVqlXD+fPnkZOTU+QlpnfffRcPHjxAr169ULduXdy8eRPffPMN2rZtW+QvHGtra3z++ecIDQ2Fn58f3nzzTd2t4F5eXpg8eXJ5nhIABV8K3333Hfr37w8fHx+EhoaiTp06uH37Ng4dOgQnJyf88ssvAAouOf3666/w8/PDmDFj0Lx5c9y9exfbtm3D8ePH4eLigpdeeglz5sxBaGgounbtigsXLmDTpk0lJlnGxLts2TIMGDAAbdu2RWhoKGrVqoW4uDhcunRJ96X4zjvvYNGiRQgMDMSoUaNw7949LF++HD4+PoU64pZk6NCheOuttxAVFYXAwMBCHZk/+ugj/Pzzz3jppZfw9ttvw9fXF9nZ2bhw4QK2b9+OxMTEYlutXnnlFcydOxdHjhxB3759deWffvopDhw4gBdffBETJkyAlZUVVqxYAaVSiS+++KLQcVQqFXr37o0hQ4YgPj4eUVFRePHFF/Hyyy/r6vj6+mLZsmX49NNP0ahRI7i7u6NXr15G3fZc1DHKQmnPpSl/b8UJDw/H+vXrkZCQoBtfxphz8vrrr+OFF15AaGgoLl++rBuhWKPRFBor6fGt3Y+T1qysLHh6emLo0KHw8fGBvb09Lly4gLVr18LZ2RmffPKJbt+ffvoJU6ZMQePGjdG8eXNs3LhR79h9+vTR3Zo/fPhwnDp1Cu+88w6uXLmiN7aNg4ODXpL+2WefoWvXrrq/7Vu3buHLL79E3759C/VjOnPmDB48eIBXXnmlxPNKxRDrNi2qWEo72mhISIhgb29f5PaVK1cKvr6+gq2treDo6Ci0atVKmDJlinDnzh29ej///LPQtWtXwdbWVnBychI6deok/Pjjj3rP8/Qtxdu3bxf69u0ruLu7C3K5XKhXr54wduxY4e7du7o6z94K/tiWLVuEdu3aCQqFQqhevbowfPhw3a3tJb2u0o7q+/i5nx5B9Wnnzp0TXn31VaFGjRqCQqEQ6tevLwwZMqTQKKQ3b94URo4cKbi5uQkKhUJo0KCBMHHiRN2Ivnl5ecJ///tfoVatWoKtra3QrVs34eTJk4VuzX7eEYqPHz8u9OnTR3B0dBTs7e2F1q1bC998841enY0bNwoNGjQQ5HK50LZtW2H//v1F3gq+YMGCIp8rMzNTsLW1FQAIGzduNFjn0aNHQnh4uNCoUSNBLpcLrq6uQteuXYWFCxfq3Z5dlNatWwujRo0qVH727FkhMDBQcHBwEOzs7ISePXsKJ06c0Kvz+G/jyJEjwpgxY4Rq1aoJDg4OwvDhw4X79+/r1U1JSRGCg4MFR0dHAYDuPTHmtueijlHU36ihz339+vWF4OBgg8cvzbkszd+bMfE8HmohISFBV2bMOREEQXjw4IEwatQooUaNGoKdnZ3g5+dn8P9V/fr19T6DSqVSeP/994XWrVsLTk5OgrW1tVC/fn1h1KhRevEIwpO/kaIez57jouo9/fyPHTt2TOjatatgY2MjuLm5CRMnThQyMzML1fv444+FevXq6d1eT8aTCEIZ9voiIqqANmzYgIkTJyIpKalQy1BJHg8E+ddff5XY2Z7oeSiVSnh5eWHq1KkmD5hJBdjnhogs3vDhw1GvXj0sXbpU7FCIirR27VpYW1sXGm+LjMc+N0Rk8aRSaYl3ohGJbdy4cUxsyghbboiIiMiisM8NERERWRS23BAREZFFYXJDREREFqXKdSjWarW4c+cOHB0dOSkZERFRJSEIAh49eoTatWsXmt/wWVUuublz506hOWOIiIiockhOTkbdunWLrVPlkpvHM7YmJycXmjuGiIiIKqbMzEx4enoWmnndkCqX3Dy+FOXk5MTkhoiIqJIpTZcSdigmIiKT5anzMHjbYAzeNhh56jyxwyECwOSGiIieg0arwfbL27H98nZotBqxwyECwOSGiIiILAyTGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIiiyJqcnP06FEMGDAAtWvXhkQiwc6dO0vc5/Dhw2jfvj0UCgUaNWqEdevWlXucREREVHmImtxkZ2ejTZs2WLp0aanqJyQkIDg4GD179kRsbCw++OADvPvuu9i/f385R0pERESVhagTZ/bv3x/9+/cvdf3ly5fD29sbX375JQCgefPmOH78OL766isEBgaWV5ilolRrkPZIWeT2Ws62kElLnuyLiIiInk+lmhX85MmTCAgI0CsLDAzEBx98UOQ+SqUSSuWTpCMzM7NcYrt0JxOvRp0ocntHr2rYNq5ruTw3EZFYZFIZXm/xum6ZqCKoVMlNSkoKPDw89Mo8PDyQmZmJ3Nxc2NraFtonMjISs2fPLvfYJAAUVoWv8gkAVGotzidnlHsMRETmZmNlg22Dt4kdBpGeSpXcmCI8PBxhYWG69czMTHh6epb587SrVw3xnxa+xHY3IxddIn8r8+cjIiIiwypVclOzZk2kpqbqlaWmpsLJyclgqw0AKBQKKBQKc4RHREREFUClGuemS5cuiImJ0Ss7cOAAunTpIlJERERVW7YqG5LZEkhmS5CtyhY7HCIAIic3WVlZiI2NRWxsLICCW71jY2ORlJQEoOCS0siRI3X1x40bhxs3bmDKlCmIi4tDVFQUtm7dismTJ4sRPhEREVVAol6WOn36NHr27Klbf9w3JiQkBOvWrcPdu3d1iQ4AeHt7Y8+ePZg8eTKWLFmCunXr4rvvvhP9NnAioqrKztoO9z68p1smqghETW78/f0hCEKR2w2NPuzv749z586VY1RERFRaEokEbvZuYodBpKdS9bkhIiIiKgmTGyIiMplSrcTEPRMxcc9EKNVFj9JOZE5MboiIyGRqrRpRp6MQdToKaq1a7HCIADC5ISIiIgvD5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii8LkhoiIiCwKkxsiIiKyKExuiIiIyKIwuSEiIiKLwuSGiIiILAqTGyIiIrIoVmIHQERElZdUIoVffT/dMlFFwOSGiIhMZmtti8NvHxY7DCI9TLOJiIjIojC5ISIiIovC5IaIiEyWrcqG2wI3uC1wQ7YqW+xwiACwzw0RET2n9Jx0sUMg0sPkhoiITGZrbYuL4y/qlokqAiY3RERkMqlECh93H7HDINLDPjdERERkUdhyQ0REJlNpVJh3bB4AYFr3aZDL5CJHRMTkhoiInkO+Jh+zj8wGAHzU9SMmN1Qh8LIUERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFGY3BAREZFFYXJDREREFkX05Gbp0qXw8vKCjY0NOnfujFOnThVZNz8/H3PmzEHDhg1hY2ODNm3aIDo62ozREhERUUUnanKzZcsWhIWFISIiAmfPnkWbNm0QGBiIe/fuGaw/Y8YMrFixAt988w0uX76McePGYdCgQTh37pyZIzeeSqPF1tPJYodBRERk8URNbhYtWoTRo0cjNDQULVq0wPLly2FnZ4c1a9YYrL9hwwZMmzYNQUFBaNCgAcaPH4+goCB8+eWXZo7cNHN+uSx2CERERBZPtLmlVCoVzpw5g/DwcF2ZVCpFQEAATp48aXAfpVIJGxsbvTJbW1scP368yOdRKpVQKpW69czMzOeM3DiC8GQ5S6k263MTEZU3iUSCFm4tdMtEFYFoLTfp6enQaDTw8PDQK/fw8EBKSorBfQIDA7Fo0SJcu3YNWq0WBw4cwI4dO3D37t0inycyMhLOzs66h6enZ5m+jpKkZubplms52xRTk4io8rGztsOlCZdwacIl2FnbiR0OEYAK0KHYGEuWLEHjxo3RrFkzyOVyTJo0CaGhoZBKi34Z4eHhyMjI0D2Sk83b7+Wphhv41HY263MTERFVRaIlN66urpDJZEhNTdUrT01NRc2aNQ3u4+bmhp07dyI7Oxs3b95EXFwcHBwc0KBBgyKfR6FQwMnJSe9hTtXs5GZ9PiIioqpOtORGLpfD19cXMTExujKtVouYmBh06dKl2H1tbGxQp04dqNVq/O9//8Mrr7xS3uGazNvVXuwQiIjKTU5+DnyifOAT5YOc/ByxwyECIPJlqbCwMKxatQrr16/HlStXMH78eGRnZyM0NBQAMHLkSL0Ox3/++Sd27NiBGzdu4NixY+jXrx+0Wi2mTJki1ksolfmvthI7BCKiciEIAi6nXcbltMsQnr6DgkhEot0tBQBDhw5FWloaZs6ciZSUFLRt2xbR0dG6TsZJSUl6/Wny8vIwY8YM3LhxAw4ODggKCsKGDRvg4uIi0iswjkarhVYrQCrlHQVEZBlsrGxwKOSQbpmoIpAIVSzVzszMhLOzMzIyMszW/2bzqSRM3XEBANDQzR773u8BuVWl6stNREQkKmO+v/kNa2bX07L1bg8nIiKisiXqZSkiIqrc8jX5WHlmJQBgjO8YWMusRY6IiMkNERE9B5VGhUn7JgEA3m77NpMbqhB4WYqIiIgsCpMbM1BptGKHQEREVGUwuTEDtaZK3ZBGREQkKiY3ZnDkaprYIRAREVUZTG7MICM3X+wQiIiIqgwmN0RERGRRmNyYQVtPF7318ZvOYNbPl7Dj7C1xAiIiIrJgHOfGDGa+1AIN3ezxya5LAICLtzNx8XYmAGBQuzqQSDjXFBERUVlhy40ZSKUSjOjiJXYYREREVQKTGyIiIrIoTG6IiIjIorDPDRERPRdXO1exQyDSw+TGjLo1qoHf/7kvdhhERGXGXm6PtI84UClVLLwsZUYfBDQROwQiIiKLx+SGiIiILAqTGyIiMllufi781/nDf50/cvNzxQ6HCAD73JgVZwcnIkujFbQ4cvOIbpmoImByY0YXb2eIHQIRUZlSWCmw9fWtumWiioDJjRnla/mrhogsi5XUCoN9BosdBpEe9rkxIxsrmdghEBERWTwmN2Y0rHM9AMALDaqLHAkRUdlQa9XYdmkbtl3aBrVWLXY4RAB4WcqsbKxlSJwfjPtZSvh+elDscIiInptSrcSQ7UMAAFnhWbCS82uFxMeWGyIiIrIoTG6IiIjIojC5EdkjpRoJ6dnY9OdNZOTkix0OERFRpceLoyLIzHvS6e5wfBq+/DUeN+/n4NKdTMwb1ErEyIiIiCo/ttyIQK15Mt5NjlKNm/dzAACnEh6IFRIREZHFYHIjAmc7a91yXMoj3XJtF1sxwiEiIrIoTG5E4O5oo1vec+GubrmOiw1u3s+GIHAOKiIiIlMxuRFJ98auAIC0R0pd2Y+nkuG34DBm7LwoVlhERESVnujJzdKlS+Hl5QUbGxt07twZp06dKrb+4sWL0bRpU9ja2sLT0xOTJ09GXl6emaI1j01/JhW7/d9sFTb+cRNJ/99Xh4iIiJ4Q9W6pLVu2ICwsDMuXL0fnzp2xePFiBAYGIj4+Hu7u7oXq//DDD5g6dSrWrFmDrl274urVq3j77bchkUiwaNEiEV6BOIK+Poa7GXlo6uGI/ZN7iB0OERFRhSJqy82iRYswevRohIaGokWLFli+fDns7OywZs0ag/VPnDiBbt26YdiwYfDy8kLfvn3x5ptvltjaU9m0qetc5DalWoO7GQUtVfGpj4qsR0REVFWJltyoVCqcOXMGAQEBT4KRShEQEICTJ08a3Kdr1644c+aMLpm5ceMG9u7di6CgoCKfR6lUIjMzU+9R0dlYy/AwR4UvouOw/1KK3rbvjiWIFBUREVHlINplqfT0dGg0Gnh4eOiVe3h4IC4uzuA+w4YNQ3p6Ol588UUIggC1Wo1x48Zh2rRpRT5PZGQkZs+eXaaxm8OKozew7PB1AMDu915EyzoFrTkL9sfr1Xtn3V9YOcIXVjLRu08RURVkL7eHEME7PKliqVTfiIcPH8a8efMQFRWFs2fPYseOHdizZw/mzp1b5D7h4eHIyMjQPZKTk80Ycem82Mi1UNnjxAYAXvrmOJRqDe5lFu44/VvcPZy/9dCk501+kIM/btyHVst/TEREZDlEa7lxdXWFTCZDamqqXnlqaipq1qxpcJ9PPvkEI0aMwLvvvgsAaNWqFbKzszFmzBhMnz4dUmnhXE2hUEChUJT9CyhD9gqZ3vqfBkYqzlNpsSTmmsH9x288i1PTAwxuK0p6lhLdvzgEAIga3h5BrWoZtT8REVFFJVrLjVwuh6+vL2JiYnRlWq0WMTEx6NKli8F9cnJyCiUwMllBYlDZBr7Lf2oKhkAfw8nc06btvKC7RdxOrp8M3XtqrJzS6vDpQd3ynYe5uHg7A3/euF/pziMRiStPnYfB2wZj8LbByFNb1rAcVHmJelkqLCwMq1atwvr163HlyhWMHz8e2dnZCA0NBQCMHDkS4eHhuvoDBgzAsmXLsHnzZiQkJODAgQP45JNPMGDAAF2SU1n8ceNJ60xAC49iahbY8/eTkYxnvexTaLvGiEtL0Rfv6q3/mfAAL31zHENX/oFLdyp+h2siqjg0Wg22X96O7Ze3Q6PViB0OEQCRx7kZOnQo0tLSMHPmTKSkpKBt27aIjo7WdTJOSkrSa6mZMWMGJBIJZsyYgdu3b8PNzQ0DBgzAZ599JtZLKBNONtZInB+MH/5MwrSfLpRYf1C7OhjQujaaz4zWlZ28fh8vNi7cd+dZgiBg3MazemUHLj+5NPhq1AkcndITNZ1tnt2ViKgQuUyOb/t/q1smqggkQhW7DpGZmQlnZ2dkZGTAyclJtDi8pu7RLSfODwYAvPfjOfxy/o6u3E4uQ45K/5eQs601zkf0BQAkpGej58LDAErfb2b6TxdKHAEZAH6a0BVtPV0gkUhKrEtERFTejPn+rlR3S1U1hz/yh5ONfuPa5IDGumVvV3vd8oRNZ3G1hEH9lGpNqRIbABgUdQKb/6p4d5YRERGVhMmNyLo/dSnpP70a6W1zd7TBe70a65UN6ehZ5LHGbzxT5LZpP11A0xlPLmP9NKEr3uxUT7fe0ataoX3+Six81xYR0dM0Wg0OJx7G4cTD7HNDFQaTG5G93Ka2brmxhyP+nlVwycmviRsAYNSL3nr17eRFd5O6npZtsHzH2Vv44ZkWm3b1quGD/28F6t3MHVvGdEF4/2bP7Hdb7zIZEdGz8tR56Lm+J3qu78m7pajCELVDcVWWOD8YD7JVqG6v3wHvcefix6RSCWytZcjN16C1gTmnWtd1xt+3MgAATT0cdeX/3MvChpOJeLltHYRtPa+3z7EpPQEAHk42es811q8hujd2Q9DXx3Rl7/14DgOeSsCIiIgqOiY3Ino2sSnKmU8C8MOfSRjZxavQtm6NXHXJTXzqI0TsuojZr7REwKIjAID1J28W2sezul2Rz9WitnidrImIiMoCL0tVAnZyK7zbvQHkVoXfro/7NcNbLzzpO7P+5E1cupNR5LGOfORf4vN9/04nk+IkIiKqCJjcWABnW2u99eCvjxeqM/OlFkicH4z6NewLbXtWjyZuOP5xwaUrG2t+RIiIqHLhN5cFeJCdr1u2lxseqTm0m5eZoiEiIhIXkxsL8N++TXTL2U8N+tfAraCVpmvDGhyMj4iIqgx2KLYArg4KRA1vjwmbnkyrUMNejt/+64/7WUrUcDB9VvS8fC3iUx6haU3HkisTERFVAGy5sRAJ6fpj3GwZ+wIAmJzY5GuezMrRb8lR0wMjIiIyMyY3FuLp0YYBoJH787W0qDVa3bIgAF8duPpcxyMiIjIXJjcWorq9XDfC8LPTOJiisYd+crQk5hp+5mjFRERUCbDPjQUZ69cQY/0altnx4ub2Q7NPnpqP6uwtJD/IwWvt66Kms02ZPQ8REVFZYssNFcnGWqbXCnQoPg0L9sdj9i+XRIyKiIioeExuqFhhfZsWKsvIzTdQk4iqIjtrO9z78B7ufXgPdtZFT+1CZE68LEVGq+nES1JEVEAikcDN3k3sMIj0sOWGSrR5zAtih0BERFRqTG6oRC80qIEdE7qWyV1YRGRZlGolJu6ZiIl7JkKpVoodDhEAJjdUSu3rVcP9bBUAYMe52yJHQ0QVhVqrRtTpKESdjoJaqxY7HCIA7HNDRviF49wQ0TOsZdaI8IvQLRNVBGy5oVL7bFAr3fJ3x24gS8lfaURVnVwmxyz/WZjlPwtymVzscIgAMLkhI7zQoIZu+dM9V9AyYj/y8jXF7EFERGR+TG6o1AQIhcqWHb4uQiREVFFoBS0u3buES/cuQStoS96ByAyY3FCpZSsLt9KsOZ4gQiREVFHk5uei5bKWaLmsJXLzc8UOhwgAkxsygrerfaGyR0o1EtKzRYiGiIjIMCY3ZJTE+cFInB+sV/Ygm2NbEBFRxcHkhkzy7bB2uuU3Vv6BjBzON0VERBUDkxsyyUuta+uW8zUC/kp8IGI0RERETzC5oTJx/tZDsUMgIiICwOSGnkNbTxfd8je//SNeIERERE9hckMm2zmxm956yJpTOHE9XaRoiIiICjC5oecSMaCFbvnI1TQMW/Un8jUcyIuIiMRTIZKbpUuXwsvLCzY2NujcuTNOnTpVZF1/f39IJJJCj+Dg4CL3ofLzs4HJNBtP34f1JxLNHwwREREqQHKzZcsWhIWFISIiAmfPnkWbNm0QGBiIe/fuGay/Y8cO3L17V/e4ePEiZDIZBg8ebObICQCauDsaLI/4+ZKZIyEiIiogenKzaNEijB49GqGhoWjRogWWL18OOzs7rFmzxmD96tWro2bNmrrHgQMHYGdnx+RGJPNfa4WvhrbB5TmBhbb5LziEm/c5ejEREZmXqMmNSqXCmTNnEBAQoCuTSqUICAjAyZMnS3WM1atX44033oC9feGpAaj8SSQSDGpXF3ZyKwS3rqW3LfF+DvwWHIYgFEy4qdEWnniTiIiorFmJ+eTp6enQaDTw8PDQK/fw8EBcXFyJ+586dQoXL17E6tWri6yjVCqhVD6ZHiAzM9P0gKlYS4e1xwT/DAR/fVyv/LVlJ5Cj0iAu5RFmBDfHu90blPqYgiAg4udL+P7kTQDA8rfaw9vVAQ3d7GElE73hkajKs7W2xcXxF3XLRBWBqMnN81q9ejVatWqFTp06FVknMjISs2fPNmNUVVuzmk6Fys4mPdQtL/w13qjkpuNnMUjPepKcjtt4Vrd8Y14QpFKJaYESUZmQSqTwcfcROwwiPaL+9HV1dYVMJkNqaqpeeWpqKmrWrFnsvtnZ2di8eTNGjRpVbL3w8HBkZGToHsnJyc8dNxVNJpUYnFzzsTZ1XaBS698qnq1U448b95GRqz8/1cg1p/QSm2fdfJDz/AETEZHFETW5kcvl8PX1RUxMjK5Mq9UiJiYGXbp0KXbfbdu2QalU4q233iq2nkKhgJOTk96DzKOxu0Ohsj8THqDJjH2Yu/syTiU8wN2MXPhE7McbK/9Am9m/4vd/0nEt9RG8pu7B0atpuv28XQv3qYq5klqojIjMS6VRYdbhWZh1eBZUGpXY4RABACTC496eItmyZQtCQkKwYsUKdOrUCYsXL8bWrVsRFxcHDw8PjBw5EnXq1EFkZKTeft27d0edOnWwefNmo54vMzMTzs7OyMjIYKJjBkn3c7D97C1cTXmE6EspJh3jzIwA1HBQ6Na9pu4BALzWvi6+HNKmTOIkItNkq7LhEFnwQyYrPAv2ct7cQeXDmO9v0fvcDB06FGlpaZg5cyZSUlLQtm1bREdH6zoZJyUlQSrVb2CKj4/H8ePH8euvv4oRMhmhXg07hPVpgtm/mDbuzcEwP73E5mn/O3sLvZu7o3/LmhAEsP8NkQispFaY0GGCbpmoIhC95cbc2HIjjsi9V7Di6I0it5+P6Is2s/WT1V0Tu6HNU5NzPva45eZZHwU2xbvdvaGwkj1XrEREVPEY8/3N5IbMQqMV8OWv8Rja0RMeTja48zAXOSoNFh24im+HtYOd3Arnkv7FoKgTCPTxwIoRHYo81qH4ewhd+5fBbe6OChz+yB92cv6CJCKyJExuisHkxjJk5OSjzRzDlyW/eL01hnTwNHNERFWTIAhIz0kHALjauUIi4eVhKh/lntxoNBqsW7cOMTExuHfvHrRa/Vt7f/vtN2MPaTZMbizHzfvZ8FtwuFC5i501Ymf21a1fvJ2BXy+nYrBvXXhWtzNjhESWjx2KyVzKvUPx+++/j3Xr1iE4OBgtW7Zkpk6iqF/DHonzg6FSazHtpwvYfuYWAOBhTj68pu7BhlGdMGL1kxnmv465hvD+zTDWr6FYIRMRkRmY1HLj6uqK77//HkFBQeURU7liy43lajhtr1HzV43u7o3pwS3KMSIiy8eWGzIXY76/TRrETy6Xo1GjRiYFR1ReTkztZVT9VccSkMxRjomILI5Jyc1///tfLFmyBFWsLzJVcB5ONoib2w+9m7nryib1bITE+cGYO7ClwX3eXnsK/2ZzVFUiIktiUp+b48eP49ChQ9i3bx98fHxgbW2tt33Hjh1lEhyRsWysZVj9dkccvJwKK5kE/k0LEp0RL9RH+iMllsRcw3/7NMGXB64CAK6nZaPd3APY/d6LaFnHWczQiYiojJiU3Li4uGDQoEFlHQtRmQlo4VGobHKfJpjcpwkAYNWxG8jMU+u27f77LpMbIiILYVJys3bt2rKOg8isjnzUE+3mHtCtLz9yHU62Vgjp4gV7BQcAJCKqzJ5rVvC0tDQcP34cx48fR1paWsk7EFUQ1ezlSJwfrFf2RXQ8pu64gKupj4y664qIiCoWk36iZmdn47333sP333+vG8BPJpNh5MiR+Oabb2Bnx4HSqHL65fwd/HL+Dga1q4NB7epApdbCy9UOK47cwJmkf/H1G+14+YqIqIIzqeUmLCwMR44cwS+//IKHDx/i4cOH2LVrF44cOYL//ve/ZR0jUbk5Na03mng4FCr/6dxtjFxzCu9+fxoBi45i25lbuJGWjZe+OS5ClEREZAyTWm7+97//Yfv27fD399eVBQUFwdbWFkOGDMGyZcvKKj6icuXuZINfJ/sh+UEOun9xqFT7qNRarPk9AfP3xQEAVo7wRV+fmuUZJhERGcGklpucnBx4eBS+G8Xd3R05ORwUjSofz+p2SIgMwnu9Sh6cssmMfbrEBgDGbDiD5Ueul2d4RERkBJOmX+jduzdq1KiB77//HjY2NgCA3NxchISE4MGDBzh48GCZB1pWOP0ClWTfhbvo2tAVznZPxm/KUanRYub+Yvc7MbUXarvYlnd4RBWKRqvBsaRjAIDu9bpDJpWJHBFZqnKfFfzixYsIDAyEUqlEmzZtAADnz5+HjY0N9u/fDx8fH9MiNwMmN2SqZxOcE1N7oev83/TqJM4Pxr/ZKtzJyMW9TCV86jjB3dHG3KESEVmcck9ugIJLU5s2bUJcXEHzfPPmzTF8+HDY2lbsX65MbqgsnU9+iFeW/l5snSMf+WPnuTvwb+qGNp4u5gmMiMjCmCW5qayY3FBZ23vhLiZsOluqukc+8kf9Gpw1mSxHviYfK8+sBACM8R0Da5l1CXsQmcaY7+9S3y31888/o3///rC2tsbPP/9cbN2XX365tIclqvT6GpjqoSjTf7qIje92LsdoiMxLpVFh0r5JAIC3277N5IYqhFInNwMHDkRKSgrc3d0xcODAIutJJBJoNJqyiI2oUrCSSbFhVCeMWH0KHwQ0xgcBBfNXHYq7h9B1f+nVPZ/8EEn3c1CvBge6JMsgk8rweovXdctEFQEvSxGZwYoj1xH51O3jCispRnapj2v3stC0piM+DmwGqVQiYoRERBWbMd/fzzW31NMePnxYVocisjgxcff01pVqLVYdS8Dh+DSsOHIDDabtxY+nkkSKjojIspiU3Hz++efYsmWLbn3w4MGoXr066tSpg/Pnz5dZcESWIqxPkxLrhO+4gPUnEuE1dQ+8pu7BiiPXcTX1ER7l5ZshQiIiy2HSZSlvb29s2rQJXbt2xYEDBzBkyBBs2bIFW7duRVJSEn799dfyiLVM8LIUiSk9S4lFB66iracLpmz/Gz61nXDpTmaJ+w3t4InAlh7o5F0DDgqTZk0hKhfZqmw4RBbMz5YVngV7Oe8GpPJRLndLPS0lJQWenp4AgN27d2PIkCHo27cvvLy80Lkz7wQhKoqrgwLzBrUCAAzpUPA3JAgCvMP3FrvfltPJ2HI6GQBwY14Q++cQERXDpMtS1apVQ3JywT/a6OhoBAQEACj4J807pYiMI5FIsGtiN936pdmBxdafvvNCeYdERFSpmdRy8+qrr2LYsGFo3Lgx7t+/j/79+wMAzp07h0aNSp54kIj0tfF0QeL8YN263nJ6NvwXHtat/3gqGQNa10bXRq7mDJGIqNIwqeXmq6++wqRJk9CiRQscOHAADg4F11vv3r2LCRMmlGmARFWdl6s9EucHw9b6yRgiw777U8SIiIgqNo5zQ1SJeE3do1uOm9sPNtYcNI3ExQ7FZC6cfoHIQv0R3hsvRMYAAJp9Eq13+YqIiApw+gWiSqSms43eutfUPejTwgOrRnYQKSIiooqn1H1utFot3N3ddctFPZjYEJWvH0brD7dw4HIqvjt2Q6RoiIgqnjKbfoGIzKNLgxqFyj7dcwUj15yCWqMVISIioorFpOTmP//5D77++utC5d9++y0++OADo461dOlSeHl5wcbGBp07d8apU6eKrf/w4UNMnDgRtWrVgkKhQJMmTbB3b/EDoBFZEolEgri5/XDxmfFwjl5NQ6Pp+0SKioio4jApufnf//6Hbt26FSrv2rUrtm/fXurjbNmyBWFhYYiIiMDZs2fRpk0bBAYG4t69ewbrq1Qq9OnTB4mJidi+fTvi4+OxatUq1KlTx5SXQVRp2VjL4KCwwpkZAYW29fjiEGKTH5o/KCKiCsKk5Ob+/ftwdnYuVO7k5IT09PRSH2fRokUYPXo0QkND0aJFCyxfvhx2dnZYs2aNwfpr1qzBgwcPsHPnTnTr1g1eXl7w8/NDmzZtTHkZRJVeDQcFEucHY0Zwc11Z0oMc/PgnZxgnoqrLpOSmUaNGiI6OLlS+b98+NGjQoFTHUKlUOHPmjG7qBgCQSqUICAjAyZMnDe7z888/o0uXLpg4cSI8PDzQsmVLzJs3r9hOzEqlEpmZmXoPIkvzbnf9v7tslVqkSKiqUVgpsPX1rdj6+lYorBRih0MEwMTpF8LCwjBp0iSkpaWhV69eAICYmBh8+eWXWLx4camOkZ6eDo1GAw8PD71yDw8PxMXFGdznxo0b+O233zB8+HDs3bsX//zzDyZMmID8/HxEREQY3CcyMhKzZ88u/YsjqqQuzOqLVrN+BQDs/vsufGpfx3j/hiJHRZbOSmqFwT6DxQ6DSI9Jyc0777wDpVKJzz77DHPnzgUAeHl5YdmyZRg5cmSZBvi0x7ejr1y5EjKZDL6+vrh9+zYWLFhQZHITHh6OsLAw3XpmZqZuRnMiS+JoY41O3tVxKuEBAODz6DjEpWRickATeLly1FgiqjpMSm4AYPz48Rg/fjzS0tJga2urm1+qtFxdXSGTyZCamqpXnpqaipo1axrcp1atWrC2toZM9mTI+ebNmyMlJQUqlQpyubzQPgqFAgoFm0qpatg6toveFA27Yu9gV+wdAMDkgCaY2LMhrGRS5Ko0GLX+L5y4fl9X18NJgajh7dG6rgusZRwlgkpHrVXjpys/AQAGNR8EK6nJXytEZcbk/2BqtRoHDx7Ejh078Hh6qjt37iArK6tU+8vlcvj6+iImJkZXptVqERMTgy5duhjcp1u3bvjnn3+g1T4Zy+Pq1auoVauWwcSGqCqKndnHYPlXB6+i0fR98Jq6B81nRuslNgCQmqnEa8tOovH0fejxxSFzhEoWQKlWYsj2IRiyfQiUaqXY4RABMDG5uXnzJlq1aoVXXnkFEydORFpaGgDg888/x4cffljq44SFhWHVqlVYv349rly5gvHjxyM7OxuhoaEAgJEjRyI8PFxXf/z48Xjw4AHef/99XL16FXv27MG8efMwceJEU14GkUVysZPj2JSeGOfXEFKJacdIepADr6l7sP9SCvLyNXiQrQIAfH8yEQv2xyElI68MI6bKTCqRwq++H/zq+0EqYYsfVQwmzQo+cOBAODo6YvXq1ahRowbOnz+PBg0a4PDhwxg9ejSuXbtW6mN9++23WLBgAVJSUtC2bVt8/fXX6Ny5YHh5f39/eHl5Yd26dbr6J0+exOTJkxEbG4s6depg1KhR+Pjjj/UuVRWHs4JTVTP7l0vIyMnHjnO39coXDm6D133rAgB2xd7GkphruJGWXerjctJOIjInY76/TUpuatSogRMnTqBp06ZwdHTUJTeJiYlo0aIFcnJyTA6+vDG5oaouV6WBrbzoHwNP99kpjquDHGN7NMTJG/chAbDkzXZwULC/BRGVD2O+v01qQyxqgsxbt27B0dHRlEMSkZkUl9gABS0yifODMbxzvULb5E91NE7PUuGzvVfwW9w9xMTdQ8uI/biW+qjM4yUiMpZJP7P69u2LxYsXY+XKlQAK5rrJyspCREQEgoKCyjRAIhLHZ4Na4bNBrfTK1BptsfNX/ZnwAI09+AOnKslWZcNriRcAIPH9RNjLOewAic+ky1LJycno168fBEHAtWvX0KFDB1y7dg2urq44evQo3N3dyyPWMsHLUkTPLz1LCVtrGT7cdh7v9WqMoK+P6bZdmdOvxNYhshzZqmw4RBYMBZIVnsXkhsqNMd/fJrXceHp64vz589iyZQvOnz+PrKwsjBo1CsOHD4etra1JQRNR5eHqUDB21LK3fAttaz4zGq3qOOPbYe1Qv8aTL7pclQaxyQ/xT1oWfjl/B3Ne8UGzmvyBQURlz+iWm/z8fDRr1gy7d+9G8+bNS96hgmHLDVHZ+zdbhXZzDxjcdmpabwQsOoLMvMLzXZ2f2RfOdtblHR6VI7bckLmUa4dia2tr5OVxjAsieqKafcHYOoZ0mhdjMLEBgDZzfkXLiP2IvphSnuERURVj0t1SEydOxOeffw61mjMPE1EBz+p2SJwfjBNTexVb79V2dfTWs5RqjNt4Bl5T98Br6h58tucyAOD4tXT8dO4WTOgWSERVnEkdigcNGoSYmBg4ODigVatWsLfXb4bcsWNHmQVY1nhZisg8Zuy8gI1/JAEAto/rgg5e1XXbQtacwpGraUYdb8kbbfFK2zolVySz4mUpMpdy71Ds4uKC1157zaTgiKhq+HRgK3w6sJXBbevf6YSM3Hw4KKzQcNreUh3v/c2xiE95hCn9mpVlmERkgYxKbrRaLRYsWICrV69CpVKhV69emDVrFu+QIiKjOdsWdCROiAxCbr4GdnIrzNx1Ed+fvAkA6NnUDYfi9Vt3og5fx7mkh7j1MAfdG7thWlBzjopMRIUYdVlq7ty5mDVrFgICAmBra4v9+/fjzTffxJo1a8ozxjLFy1JElc+Ln/+GW//mGtx2fV4QZKbOEErPjZelyFzK7W6p77//HlFRUdi/fz927tyJX375BZs2bYJWq32ugImIinP846I7KTecthc7n5kUlIiqNqPac5OSkvSmVwgICIBEIsGdO3dQt27dMg+OiOixhMggnLh+Hx5OCiisZOj+xSHdtg+2xOLlNrUhZQsOEcHIlhu1Wg0bGxu9Mmtra+Tn55dpUEREz5JIJOjWyBWN3B3hWd0Ohz/019veYNpexFxJFSc4IqpQjGq5EQQBb7/9NhQKha4sLy8P48aN07sdvCLfCk5ElsHL1R4JkUHwDn9yt9Wo9afRp4UHVo3sIGJkVYtcJse3/b/VLRNVBEZ1KA4NDS1VvbVr15ocUHljh2Iiy/Jq1O84m/SwUPmxKT2hsJJizu7L2P33XQCAXCbFsY97wsPJplB9IqrYjPn+NmkQv8qMyQ2RZZr4w1ns+f8kpiTr3+kEvyZu5RwREZWlcp1bioioIvpycJtS1w1ZcwoZOewrWBY0Wg0OJx7G4cTD0Gg1YodDBIAtN2KHQ0TloMOnB5GepUT3xq6YHtwczWo64UG2Cu2fmbnc29Uee/7zIuzkHAjQVBznhsyFl6WKweSGqOpSa7RoNH1fofL3ezfG5D5NRIio8svJz0HHVR0BAH+N/gt21nYiR0SWislNMZjcEFVt2Uo1fCL2Fyr/dlg7vNS6tggREVFpsM8NEVER7BVWSJwfXKh80g/n8CiP/XCILAFbboioyhIEQW+cHKCgH05evgafvNQCQa1qiRQZET2LLTdERKUgkUgKjXSckJ6Nuxl5mLDpLO+oKoWc/Bz4RPnAJ8oHOfk5YodDBIDJDRFVcV6u9lj+VnuD23LzeWtzSQRBwOW0y7icdhlV7EIAVWC8/5GIqrx+LWshcX4wUjPzYK+wQpvZv0Kj5Rc1UWXFlhsiov/n4WQDB4WVLrF5ITIG/9x7JHJURGQsJjdERMUIWHQUb678Q+wwiMgITG6IiJ5xZkaA3vrJG/fRePpeJD9gh1miyoDJDRHRM2o4KJA4PxhDO3jqyvI1Arp/cQi+cw/gzsNcEaMjopIwuSEiKsLnr7fGwLb6oxbfz1ah6/zfoFJrRYqKiErCQfyIiErBa+qeIrd1bVgDJ67f161fnB0IB0XVuBmVE2eSuXAQPyKiMpY4P9jgtA0A9BIbAGgZsR9jvj+NLKXaHKER0TMqRHKzdOlSeHl5wcbGBp07d8apU6eKrLtu3TpIJBK9h42NjRmjJaKqLOa/fqWq9+vlVLSM2A+vqXt0j79vPcTGP27i71sPyzdIoipO9HbTLVu2ICwsDMuXL0fnzp2xePFiBAYGIj4+Hu7u7gb3cXJyQnx8vG5dIpGYK1wiquIaujnoteAkpGejXnU7yKQF/4dazIxGjsrwyMYvf/u73vq1z/rDWlYhfmMSWRTR/6oWLVqE0aNHIzQ0FC1atMDy5cthZ2eHNWvWFLmPRCJBzZo1dQ8PDw8zRkxE9IS3q70usQGAy3P64WBY6Vp3Gk/fV15hEVVporbcqFQqnDlzBuHh4boyqVSKgIAAnDx5ssj9srKyUL9+fWi1WrRv3x7z5s2Dj4+PwbpKpRJKpVK3npmZWXYvgIjIgEbuDoX656Q9UmLfxbvo2dQd3b84pCv3mroHreo44+dJ3SplK7S1zBoRfhG6ZaKKQNSWm/T0dGg0mkItLx4eHkhJSTG4T9OmTbFmzRrs2rULGzduhFarRdeuXXHr1i2D9SMjI+Hs7Kx7eHp6GqxHRFSe3BwVGNnFC57V7RA1XH+izgu3M+AdvhdeU/dg1Lq/KlVHZLlMjln+szDLfxbkMrnY4RABqACXpYzVpUsXjBw5Em3btoWfnx927NgBNzc3rFixwmD98PBwZGRk6B7JyclmjpiISF9Qq1qoW83W4LaYuHu6jsjfn0w0b2BEFkLUy1Kurq6QyWRITU3VK09NTUXNmjVLdQxra2u0a9cO//zzj8HtCoUCCoXiuWMlIipLxz/uBaD48XNm7roEd0cF+rWsZa6wjKYVtLiSdgUA0NytOaSSSvebmSyQqJ9CuVwOX19fxMTE6Mq0Wi1iYmLQpUuXUh1Do9HgwoULqFWr4v7xExEVJSEyCIc+9Efi/GBsG1f4/964jWfhNXUPOnx6EKmZeSJEWLzc/Fy0XNYSLZe1RG4+p6WgikH0W8HDwsIQEhKCDh06oFOnTli8eDGys7MRGhoKABg5ciTq1KmDyMhIAMCcOXPwwgsvoFGjRnj48CEWLFiAmzdv4t133xXzZRARmUQikcDbtWBU345e1XUdkZ9t0UnPUqLzvIIfgr/91w+1nG0ht5JCJpUgW6nGrX9zMWf3Jbg6KDBvUCvYm3GEZFc7V7M9F1FpiJ7cDB06FGlpaZg5cyZSUlLQtm1bREdH6zoZJyUlQSp90sD077//YvTo0UhJSUG1atXg6+uLEydOoEWLFmK9BCKiMte9sSuOXUs3uK3Xl0eK3XdX7B24OshxYLIfqtmXbydfe7k90j5KK9fnIDIW55YiIqqgfjp3C7WcbfFCgxrov+QYrtw1fSiLV9vXweSAJvCsbleGERKZjzHf30xuiIgqict3MhH09bFC5T2auGFA61p4qXVtdP/iN6RnqYo8hq21DL+81w2N3B3LM1SiMsfkphhMbojI0qVk5OGFyJiSKz4lvH8zjHrRG1ZGTgeRm5+L/pv6AwD2Dd8HW2vDt7gTPS8mN8VgckNEVdHYDaex/1JqifU2juqMFxuXvoNwtiobDpEOAICs8CzYy+1NjpGoOMZ8f4veoZiIiMrfihEdkJmXj82nkjBvb1yR9d5a/SecbKywdVwXNKvJH4BUOTG5ISKqIpxsrDGmR0OM6dFQrzxLqUbLiP269cw8NfotPoa/pgfAzZGDoFLlw+SGiKiKc1BYIXF+MMZvPIN9F5/M69fxs4NF7tPZuzp+HP2COcIjMlqV7XNzJ+2OUX1uFFYKWEkLckG1Vg2lWgmpRKrXeS5blW10PHKZXDeTrkarQZ46DxKJBHbWT27XzMnPgbFvk7XMWjeJnVbQ6kYOffp6eG5+LrSC1qjjWkmtoLAq+CUnCAJy8nMKHTdPnQeNVmPUcWVSGWysbHTrj8+lnbWdbqZkpVoJtda4CQWLeo9srW11w8SrNCrka/KNOm5R75GNlQ1kUhkAIF+TD5Wm6LtWimLoPTL0+Xue4z5+jwx9/oxl6D0q6vNnDEPvUVGfP2MYeo+K+vwZw1L+R8SnqPBq1ImCcigBFH/cbo0csPl2PwBA6n9T4WzjzP8R4P+Ip5XV/4jMzEzUdqvNDsWGPE5uMBWATYnVdba+vhWDfQYDALZd2oYh24fAr74fDr99WFfHbYEb0nMMD7pVlG/7f4uJnSYCAA4nHkbP9T3Rwq0FLk24pKvjE+WDy2mXjTpuhF8EZvnPAgBcuncJLZe1hKudq95gW/7r/HHkZvGDgT1rQocJWBq8FACQlp0G94XuAAAh4snHaPC2wdh+ebtRx329xevYNnibbl0yu+AP4d6H9+Bm7wYAmLhnIqJORxl13KLeo4vjL8LH3QcAMOvwLMw+Mtuo4xb1Hh0KOQR/L38AwNJTSzFp3ySjjlvUe2To82csQ++Roc+fsQy9R4Y+f8Yy9B4V9fkzhqH3qKjPnzEs6X+EIAj4/Z/7CNjQE0rZRaOOy/8RBfg/4oky+x+RB2A+SpXccIYzIiLSI5FI8GJjV7zQoIbR+/6RcB/JD4xvUSMqS1W25YaXpXhZik3OFavJ+Vm8LFWgov+PuP3wXzRd5gkAqJO7ETLYo46zI06E9+b/CP6PAMDLUmbBcW6IiMrO0+PceOZuh/T/r/d/82Y7DGhTW8zQyMIY8/3Ny1JERFQmdozvqlt+78dzmPq/v5GvMa51mKgs8FZwIiIqE81rOaGphyPiUx8BADb/lYzNfyUDAPq08EDU8PawNnJ6ByJT8FNGRERlZv/kHgbLD1xORePp+4zuG0RkCrbcEBGRyaykVpjQYYJuGQAS5wcjV6VB85nRhep7h+9F4vxgs8ZIVQ87FBMRUbmKS8lEv8XH9Mr2/qc7pFKgqYej7k4aouJwVvBiMLkhIjK/mCupGLX+tMFts1/2QUhXL/MGRJUO75YiIiKzEAQBadlpSMtOK7Y/Te/mHjg1rbfBbRE/X4LX1D048Y9xozcTFYXJDRERmSwnPwfuC93hvtC9xEEV3Z1skDg/GCtH+KJnU7dC24d99yd+Pn+nvEKlKoSXpYiIyGRPD+KXFZ6lN8ptSQRBgHf43iK3t6vngp8mdHvuGMkysM9NMZjcEBFVPD4zo5GtMjwlw9dvtkObus6oX6P0iRNZHiY3xWByQ0RU8ZTUivPYxlGdUdNZgUbujmaIiioSJjfFYHJDRFTxPchWof3cAyXW++SlFhj1orcZIiKxMbkpBpMbIqKyk6fOw4ifRgAANgzaoDdzd1nIUqqx4eRNfB4dV2SdGvZynPmkT5k+L1U8TG6KweSGiKjsPE+HYmMkP8hBamYeEtKz8dH2vw3WuTKnH2zlsnJ5fhKfMd/fnH6BiIgqPM/qdvCsbocOXtUxuIMnACAhPRs9Fx7W1Wk+MxqrRnZAz6ZusOIEnVUa330iIqqUvF3tkRAZpFc2+vvTaDR9H/LyDd95RVUDkxsiIqq0JBIJzs/sC0eF/oWIZp9E4/VlJ5CYni1SZCQmJjdERFSpOdtZ48LsQPw0oate+emb/8J/4WH0+OIQ4lMeiRQdiYHJDRERWYR29arhn8/6Y0Cb2nrlSQ9yELj4KNafSETaI6VI0ZE58W4pIiIymbnuljLFwcupePd7wzORA8Dyt3zRr2VNM0ZEz4OzghMRUZUX0MIDuyYWPTfVuI1ncD0ty4wRkbnwVnAiIrJYbTxdkDg/GACw5++7mPjDWb3tvb88giEd6uJRnhrdGrmifg07dG9ceMZyqlwqRMvN0qVL4eXlBRsbG3Tu3BmnTp0q1X6bN2+GRCLBwIEDyzdAIiKq9IJb10Li/GAkzg+GX5MnCczW07ew72IKZuy8iBGrT+GX83dEjJLKgujJzZYtWxAWFoaIiAicPXsWbdq0QWBgIO7du1fsfomJifjwww/RvXt3M0VKRESWYtGQNkVue+/Hc7hwK8OM0VBZE71DcefOndGxY0d8++23AACtVgtPT0+89957mDp1qsF9NBoNevTogXfeeQfHjh3Dw4cPsXPnzlI9HzsUExGVnYrcobg0BEGARCIBAGw9nYwpT03tsOc/L8KntrNYodEzKk2HYpVKhTNnziAgIEBXJpVKERAQgJMnTxa535w5c+Du7o5Ro0aV+BxKpRKZmZl6DyIiKhsyqQyvt3gdr7d4HTJp5ZvX6XFiAwBDOniiea0nX5rBXx/H1r+SxQiLnpOoyU16ejo0Gg08PDz0yj08PJCSkmJwn+PHj2P16tVYtWpVqZ4jMjISzs7Ouoenp+dzx01ERAVsrGywbfA2bBu8rcxnBBfD3v+8iMbuDrr1Kf/7Gx9uO48zN/8VMSoyluh9bozx6NEjjBgxAqtWrYKrq2up9gkPD0dGRobukZzMLJyIiAyTSCQ4EOandwv59jO38NqyE7h0h/1wKgtRbwV3dXWFTCZDamqqXnlqaipq1iw8sNL169eRmJiIAQMG6Mq0Wi0AwMrKCvHx8WjYsKHePgqFAgqFohyiJyIiS9XG0wVfDW2DxQev4eb9HAAFl6keWzWyA3o3c4dUKinqECQiUVtu5HI5fH19ERMToyvTarWIiYlBly5dCtVv1qwZLly4gNjYWN3j5ZdfRs+ePREbG8tLTkREZpatyoZktgSS2RJkqyxrkspB7eriyEc9C03nABTMPt5g2l5k5uWLEBmVRPRB/MLCwhASEoIOHTqgU6dOWLx4MbKzsxEaGgoAGDlyJOrUqYPIyEjY2NigZcuWevu7uLgAQKFyIiKisvDNm+3wUd+mGPbdH7j1b67ettazfgUArH27I3o2cxcjPDJA9ORm6NChSEtLw8yZM5GSkoK2bdsiOjpa18k4KSkJUmml6hpERFRl2Fnb4d6H93TLlqpeDTsc/7gXAECjFdBw2l697aHr/sKy4e3Rv1UtMcKjZ4g+zo25cZwbIiIqC3n5GkzbcQE7zt3WlUklwB/TesPdsfLfOVbRVJpxboiIiCorG2sZFg1ti7F+DXRlWgHo9FkMOnx6AEn/3xGZzI/JDRERmUypVmLinomYuGcilGql2OGIIrx/c2x6t7NeWXqWCltPc+gRsTC5ISIik6m1akSdjkLU6SiotWqxwxFNt0auuDEvCGF9mujK8jVaESOq2pjcEBERlQGpVIL/9G6M0d29AQArjt7A5Tuc8kcMTG6IiIjK0NO36QR9fQyrjyeIF0wVxeSGiIioDI3u0QDNajrq1ufuvozP9lwWMaKqh8kNERFRGfJwskH0Bz2wNrSjrmzVsQR4Td2DHFXV7ZdkTkxuiIiIykHPpu7o28JDr6zFzP34/mQivj+ZiDsPc4vYk54XB/EjIiKTZauy4RDpAADICs+Cvdxe5Igqnrx8DZp9Em1w2/mZfeFsZ23miConDuJHRERUQdhYy3B6RoDBbW3m/IoPt53nbeNlTPS5pYiIiCydq4MCifODIQgCJBIJvKbu0W3bfuYWtp+5helBzTG6R4NijkKlxZYbIiIiM5FIJACAs5/0KbTts71XcC7pX+Tla8wdlsVhyw0REZGZVbeXI3F+MADg10spGLPhDABgUNQJXZ2gVjXxWvu66N3cw+AxqGhsuSEiIhJRX5+amBHcvFD53gspGLX+NPZeuCtCVJUbW26IiMhkUokUfvX9dMtkmne7N0D/VrWwK/Y2voiO19v2eXQcmng4wLO6HRRWMpEirFx4KzgREVEFFL7jAn48laRXFje3H2ysq2aCw1vBiYiIKrnHE3A+rdkn0bifpRQhmsqFyQ0REVEF1MDNATfmBRUaI8f304NIe8QEpzhMboiIyGTZqmy4LXCD2wI3ZKuyxQ7H4kilErg6KBD9QXe98o6fHcT1tCyRoqr4mNwQEdFzSc9JR3pOuthhWLRmNZ3wz2f94eqg0JX1/vIIvKbuwYY/booYWcXE5IaIiExma22Li+Mv4uL4i7C1thU7HItmJZPi1LTe6N7YVa/8k50XkfwgR6SoKibeLUVERFQJ7btwF+M3ndWtd/Sqhm3juooYUfni3VJEREQWrn+rWnrr8SmPRIqk4mFyQ0REJlNpVJh1eBZmHZ4FlUYldjhVTuL8YByY3AMAkJmnFjmaioPJDRERmSxfk4/ZR2Zj9pHZyNfkix1OlZT71ESb4zeewaM8vg9MboiIiCqxJh6OuuV9F1PQatav+PPGfREjEh+TGyIiokrMxlqGqOHt9cqGrvwDm08lYcMfN6FUa4rY03IxuSEiIqrkglrVQuL8YAS3ftLJeOqOC/hk50U0nRGN7WduiRid+TG5ISIishDzBrUyWP7htvPIVVWdFhwrsQMgIiKisuFsa43E+cG69fPJD/HK0t8BAM1nRmNtaEf4N3GDRCIRK0SzYMsNERGRhWrj6aK3Hrr2L8z+5bI4wZgRkxsiIiILduhDf7g6yHXr604kot/ioyJGVP6Y3BAREVkwb1d7nJ7RBz+OfkFXFpfyCHce5ooYVfmqEMnN0qVL4eXlBRsbG3Tu3BmnTp0qsu6OHTvQoUMHuLi4wN7eHm3btsWGDRvMGC0REVHl06VhDZyP6Ktb/2BzrHjBlDPRk5stW7YgLCwMEREROHv2LNq0aYPAwEDcu3fPYP3q1atj+vTpOHnyJP7++2+EhoYiNDQU+/fvN3PkRERElYuzrbVu+VTiA4zbcMYiZxQXPblZtGgRRo8ejdDQULRo0QLLly+HnZ0d1qxZY7C+v78/Bg0ahObNm6Nhw4Z4//330bp1axw/ftzMkRMREVU+p6b11i1HX0rB+hOJ4gVTTkRNblQqFc6cOYOAgABdmVQqRUBAAE6ePFni/oIgICYmBvHx8ejRo0d5hkpERAZIJBK0cGuBFm4tLP72Ykvh7mSDDwIa69a/O54Ar6l7sOGPmyJGVbZEHecmPT0dGo0GHh4eeuUeHh6Ii4srcr+MjAzUqVMHSqUSMpkMUVFR6NOnj8G6SqUSSqVSt56ZmVk2wRMREeys7XBpwiWxwyAjfRDQBG3quiB03V+6sk92XsSIF+qLGFXZEf2ylCkcHR0RGxuLv/76C5999hnCwsJw+PBhg3UjIyPh7Oyse3h6epo3WCIiogqoZzN3rA3tqFf25a/xIkVTtiSCIAhiPblKpYKdnR22b9+OgQMH6spDQkLw8OFD7Nq1q1THeffdd5GcnGywU7GhlhtPT09kZGTAycnpuV8DERFRZabVCmgwba9u3U4uw9lP+sDGWiZiVIVlZmbC2dm5VN/forbcyOVy+Pr6IiYmRlem1WoRExODLl26lPo4Wq1WL4F5mkKhgJOTk96DiIjKRk5+DnyifOAT5YOcfMu766YqkEol+Py1J3NS5ag0CPr6GOJTHokY1fMR/bJUWFgYVq1ahfXr1+PKlSsYP348srOzERoaCgAYOXIkwsPDdfUjIyNx4MAB3LhxA1euXMGXX36JDRs24K233hLrJRARVVmCIOBy2mVcTrsMES8E0HMa2rEeEiKDdOs30rIRuPgo/kp8IGJUphN94syhQ4ciLS0NM2fOREpKCtq2bYvo6GhdJ+OkpCRIpU9ysOzsbEyYMAG3bt2Cra0tmjVrho0bN2Lo0KFivQQioirLxsoGh0IO6Zap8pJIJFg0pA3Ctp7XlQ1efhKBPh74dlh7WMtEbw8pNVH73IjBmGt2REREVdEX0XGIOnxdr2zr2C7o5F1dpIgqUZ8bIiIiqnim9GuGXRO76ZUNWXESy55JeCoqJjdERGSyfE0+lp5aiqWnliJfky92OFSG2ni6IHF+sF7Z59FFj0FXkTC5ISIik6k0KkzaNwmT9k2CSqMSOxwqB4nzgxHWp4luffT3p6HVVuweLUxuiIiIqFjj/Rvqlg9cTsXNCj7ZJpMbIiIiKpa1TIq/pj+ZB1Jbwe9FYnJDREREJXJzVMDJpmAEmfAdFyr0uEZMboiIiKhUMvPUAIBTCQ/Qfu6BCpvgMLkhIiKiUvl9ai/d8r85+Ziy/W8RoykakxsiIiIqlTouttgy5gXd+rYzt5CQni1iRIYxuSEiIqJS69ygBraNezK59V8JFW/+KSY3REREZJSOXtXR0asaAOCXv+9UuL43TG6IiIjIaNfuZQEAjl1Lx+QtseIG8wwmN0RERGS0GcEtdMs7Y+/gqwNXK8zIxUxuiIiIyGiv+9bFkY/8detLYq5h2ZGKMbEmkxsiInournaucLVzFTsMEkH9GvZYOcJXt7700D8iRvMEkxsiIjKZvdweaR+lIe2jNNjL7cUOh0TQ16cmZgQ3BwDkqDQiR1OAyQ0RERE9l74tagIArGUSkSMpwOSGiIiInovcqiCdyNcIFeK2cCY3RERkstz8XPiv84f/On/k5ueKHQ6JRPpUNuEdvhc374s7ajGTGyIiMplW0OLIzSM4cvMItIJW7HBIJO6ONnrrI1afEimSAlaiPjsREVVqCisFtr6+VbdMVdf1eUHoNv83pGTmoZazTck7lCOJUBEujplRZmYmnJ2dkZGRAScnJ7HDISIiolIw5vubl6WIiIjIovCyFBERmUytVeOnKz8BAAY1HwQrKb9WSHz8FBIRkcmUaiWGbB8CAMgKz4KVnF8rJD5eliIiIiKLwuSGiIiILAqTGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii8LkhoiIiCwKkxsiIiKyKFVuEhBBEAAUTJ1ORETPJ1uVDeQVLGdmZkIj14gbEFmsx9/bj7/HiyMRSlPLgty6dQuenp5ih0FEREQmSE5ORt26dYutU+WSG61Wizt37sDR0RESiaRMj52ZmQlPT08kJyfDycmpTI9NT/A8mwfPs3nwPJsPz7V5lNd5FgQBjx49Qu3atSGVFt+rpspdlpJKpSVmfM/LycmJfzhmwPNsHjzP5sHzbD481+ZRHufZ2dm5VPXYoZiIiIgsCpMbIiIisihMbsqQQqFAREQEFAqF2KFYNJ5n8+B5Ng+eZ/PhuTaPinCeq1yHYiIiIrJsbLkhIiIii8LkhoiIiCwKkxsiIiKyKExuiIiIyKIwuTHS0qVL4eXlBRsbG3Tu3BmnTp0qtv62bdvQrFkz2NjYoFWrVti7d6+ZIq3cjDnPq1atQvfu3VGtWjVUq1YNAQEBJb4vVMDYz/NjmzdvhkQiwcCBA8s3QAth7Hl++PAhJk6ciFq1akGhUKBJkyb831EKxp7nxYsXo2nTprC1tYWnpycmT56MvLw8M0VbOR09ehQDBgxA7dq1IZFIsHPnzhL3OXz4MNq3bw+FQoFGjRph3bp15R4nBCq1zZs3C3K5XFizZo1w6dIlYfTo0YKLi4uQmppqsP7vv/8uyGQy4YsvvhAuX74szJgxQ7C2thYuXLhg5sgrF2PP87Bhw4SlS5cK586dE65cuSK8/fbbgrOzs3Dr1i0zR165GHueH0tISBDq1KkjdO/eXXjllVfME2wlZux5ViqVQocOHYSgoCDh+PHjQkJCgnD48GEhNjbWzJFXLsae502bNgkKhULYtGmTkJCQIOzfv1+oVauWMHnyZDNHXrns3btXmD59urBjxw4BgPDTTz8VW//GjRuCnZ2dEBYWJly+fFn45ptvBJlMJkRHR5drnExujNCpUydh4sSJunWNRiPUrl1biIyMNFh/yJAhQnBwsF5Z586dhbFjx5ZrnJWdsef5WWq1WnB0dBTWr19fXiFaBFPOs1qtFrp27Sp89913QkhICJObUjD2PC9btkxo0KCBoFKpzBWiRTD2PE+cOFHo1auXXllYWJjQrVu3co3TkpQmuZkyZYrg4+OjVzZ06FAhMDCwHCMTBF6WKiWVSoUzZ84gICBAVyaVShEQEICTJ08a3OfkyZN69QEgMDCwyPpk2nl+Vk5ODvLz81G9evXyCrPSM/U8z5kzB+7u7hg1apQ5wqz0TDnPP//8M7p06YKJEyfCw8MDLVu2xLx586DRaMwVdqVjynnu2rUrzpw5o7t0dePGDezduxdBQUFmibmqEOt7sMpNnGmq9PR0aDQaeHh46JV7eHggLi7O4D4pKSkG66ekpJRbnJWdKef5WR9//DFq165d6A+KnjDlPB8/fhyrV69GbGysGSK0DKac5xs3buC3337D8OHDsXfvXvzzzz+YMGEC8vPzERERYY6wKx1TzvOwYcOQnp6OF198EYIgQK1WY9y4cZg2bZo5Qq4yivoezMzMRG5uLmxtbcvledlyQxZl/vz52Lx5M3766SfY2NiIHY7FePToEUaMGIFVq1bB1dVV7HAsmlarhbu7O1auXAlfX18MHToU06dPx/Lly8UOzaIcPnwY8+bNQ1RUFM6ePYsdO3Zgz549mDt3rtihURlgy00pubq6QiaTITU1Va88NTUVNWvWNLhPzZo1japPpp3nxxYuXIj58+fj4MGDaN26dXmGWekZe56vX7+OxMREDBgwQFem1WoBAFZWVoiPj0fDhg3LN+hKyJTPc61atWBtbQ2ZTKYra968OVJSUqBSqSCXy8s15srIlPP8ySefYMSIEXj33XcBAK1atUJ2djbGjBmD6dOnQyrlb/+yUNT3oJOTU7m12gBsuSk1uVwOX19fxMTE6Mq0Wi1iYmLQpUsXg/t06dJFrz4AHDhwoMj6ZNp5BoAvvvgCc+fORXR0NDp06GCOUCs1Y89zs2bNcOHCBcTGxuoeL7/8Mnr27InY2Fh4enqaM/xKw5TPc7du3fDPP//okkcAuHr1KmrVqsXEpgimnOecnJxCCczjhFLglItlRrTvwXLtrmxhNm/eLCgUCmHdunXC5cuXhTFjxgguLi5CSkqKIAiCMGLECGHq1Km6+r///rtgZWUlLFy4ULhy5YoQERHBW8FLwdjzPH/+fEEulwvbt28X7t69q3s8evRIrJdQKRh7np/Fu6VKx9jznJSUJDg6OgqTJk0S4uPjhd27dwvu7u7Cp59+KtZLqBSMPc8RERGCo6Oj8OOPPwo3btwQfv31V6Fhw4bCkCFDxHoJlcKjR4+Ec+fOCefOnRMACIsWLRLOnTsn3Lx5UxAEQZg6daowYsQIXf3Ht4J/9NFHwpUrV4SlS5fyVvCK6JtvvhHq1asnyOVyoVOnTsIff/yh2+bn5yeEhITo1d+6davQpEkTQS6XCz4+PsKePXvMHHHlZMx5rl+/vgCg0CMiIsL8gVcyxn6en8bkpvSMPc8nTpwQOnfuLCgUCqFBgwbCZ599JqjVajNHXfkYc57z8/OFWbNmCQ0bNhRsbGwET09PYcKECcK///5r/sArkUOHDhn8f/v43IaEhAh+fn6F9mnbtq0gl8uFBg0aCGvXri33OCWCwPY3IiIishzsc0NEREQWhckNERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFGY3BARAZBIJNi5cycAIDExERKJhDOgE1VSTG6ISHRvv/02JBIJJBIJrK2t4e3tjSlTpiAvL0/s0IioEuKs4ERUIfTr1w9r165Ffn4+zpw5g5CQEEgkEnz++edih0ZElQxbboioQlAoFKhZsyY8PT0xcOBABAQE4MCBAwAKZniOjIyEt7c3bG1t0aZNG2zfvl1v/0uXLuGll16Ck5MTHB0d0b17d1y/fh0A8Ndff6FPnz5wdXWFs7Mz/Pz8cPbsWbO/RiIyDyY3RFThXLx4ESdOnIBcLgcAREZG4vvvv8fy5ctx6dIlTJ48GW+99RaOHDkCALh9+zZ69OgBhUKB3377DWfOnME777wDtVoNAHj06BFCQkJw/Phx/PHHH2jcuDGCgoLw6NEj0V4jEZUfXpYiogph9+7dcHBwgFqthlKphFQqxbfffgulUol58+bh4MGD6NKlCwCgQYMGOH78OFasWAE/Pz8sXboUzs7O2Lx5M6ytrQEATZo00R27V69ees+1cuVKuLi44MiRI3jppZfM9yKJyCyY3BBRhdCzZ08sW7YM2dnZ+Oqrr2BlZYXXXnsNly5dQk5ODvr06aNXX6VSoV27dgCA2NhYdO/eXZfYPCs1NRUzZszA4cOHce/ePWg0GuTk5CApKancXxcRmR+TGyKqEOzt7dGoUSMAwJo1a9CmTRusXr0aLVu2BADs2bMHderU0dtHoVAAAGxtbYs9dkhICO7fv48lS5agfv36UCgU6NKlC1QqVTm8EiISG5MbIqpwpFIppk2bhrCwMFy9ehUKhQJJSUnw8/MzWL9169ZYv3498vPzDbbe/P7774iKikJQUBAAIDk5Genp6eX6GohIPOxQTEQV0uDBgyGTybBixQp8+OGHmDx5MtavX4/r16/j7Nmz+Oabb7B+/XoAwKRJk5CZmYk33ngDp0+fxrVr17BhwwbEx8cDABo3bowNGzbgypUr+PPPPzF8+PASW3uIqPJiyw0RVUhWVlaYNGkSvvjiCyQkJMDNzQ2RkZG4ceMGXFxc0L59e0ybNg0AUKNGDfz222/46KOP4OfnB5lMhrZt26Jbt24AgNWrV2PMmDFo3749PD09MW/ePHz44YdivjwiKkcSQRAEsYMgIiIiKiu8LEVEREQWhckNERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFGY3BAREZFFYXJDREREFoXJDREREVkUJjdERERkUZjcEBERkUX5P8aO5XD0zKRCAAAAAElFTkSuQmCC"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Jak widać, chociaż AUROC jest wysokie, to dla optymalnego F1-score recall nie jest zbyt wysoki, a precyzja jest już dość niska. Być może wynik uda się poprawić, używając modelu o większej pojemności - pełnej, głębokiej sieci neuronowej.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Sieci-neuronowe">Sieci neuronowe<a class="anchor-link" href="#Sieci-neuronowe">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Wszystko zaczęło się od inspirowanych biologią <a href="https://en.wikipedia.org/wiki/Artificial_neuron">sztucznych neuronów</a>, których próbowano użyć do symulacji mózgu. Naukowcy szybko odeszli od tego podejścia (sam problem modelowania okazał się też znacznie trudniejszy, niż sądzono), zamiast tego używając neuronów jako jednostek reprezentującą dowolną funkcję parametryczną $f(x, \Theta)$. Każdy neuron jest zatem bardzo elastyczny, bo jedyne wymagania to funkcja różniczkowalna, a mamy do tego wektor parametrów $\Theta$.</p>
<p>W praktyce najczęściej można spotkać się z kilkoma rodzinami sieci neuronowych:</p>
<ol>
<li>Perceptrony wielowarstwowe (<em>MultiLayer Perceptron</em>, MLP) - najbardziej podobne do powyższego opisu, niezbędne do klasyfikacji i regresji</li>
<li>Konwolucyjne (<em>Convolutional Neural Networks</em>, CNNs) - do przetwarzania danych z zależnościami przestrzennymi, np. obrazów czy dźwięku</li>
<li>Rekurencyjne (<em>Recurrent Neural Networks</em>, RNNs) - do przetwarzania danych z zależnościami sekwencyjnymi, np. szeregi czasowe, oraz kiedyś do języka naturalnego</li>
<li>Transformacyjne (<em>Transformers</em>), oparte o mechanizm atencji (<em>attention</em>) - do przetwarzania języka naturalnego (NLP), z którego wyparły RNNs, a coraz częściej także do wszelkich innych danych, np. obrazów, dźwięku</li>
<li>Grafowe (<em>Graph Neural Networks</em>, GNNS) - do przetwarzania grafów</li>
</ol>
<p>Na tym laboratorium skupimy się na najprostszej architekturze, czyli MLP. Jest ona powszechnie łączona z wszelkimi innymi architekturami, bo pozwala dokonywać klasyfikacji i regresji. Przykładowo, klasyfikacja obrazów to zwykle CNN + MLP, klasyfikacja tekstów to transformer + MLP, a regresja na grafach to GNN + MLP.</p>
<p>Dodatkowo, pomimo prostoty MLP są bardzo potężne - udowodniono, że perceptrony (ich powszechna nazwa) są <a href="https://www.sciencedirect.com/science/article/abs/pii/0893608089900208">uniwersalnym aproksymatorem</a>, będącym w stanie przybliżyć dowolną funkcję z odpowiednio małym błędem, zakładając wystarczającą wielkość warstw sieci. Szczególne ich wersje potrafią nawet <a href="https://www.youtube.com/watch?v=_okxGdHM5b8">reprezentować drzewa decyzyjne</a>.</p>
<p>Dla zainteresowanych polecamy <a href="https://d2l.ai/chapter_multilayer-perceptrons/index.html">doskonałą książkę "Dive into Deep Learning", z implementacjami w PyTorchu</a>, <a href="https://www.deeplearningbook.org/contents/mlp.html">klasyczną książkę "Deep Learning Book"</a>, oraz <a href="https://www.youtube.com/watch?v=BFHrIxKcLjA">ten filmik</a>, jeśli zastanawiałeś/-aś się, czemu używamy deep learning, a nie naprzykład (wide?) learning. (aka. czemu staramy się budować głębokie sieci, a nie płytkie za to szerokie)</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Sieci-MLP">Sieci MLP<a class="anchor-link" href="#Sieci-MLP">&#182;</a></h3><p>Dla przypomnienia, na wejściu mamy punkty ze zbioru treningowego, czyli $d$-wymiarowe wektory. W klasyfikacji chcemy znaleźć granicę decyzyjną, czyli krzywą, która oddzieli od siebie klasy. W wejściowej przestrzeni może być to trudne, bo chmury punktów z poszczególnych klas mogą być ze sobą dość pomieszane. Pamiętajmy też, że regresja logistyczna jest klasyfikatorem liniowym, czyli w danej przestrzeni potrafi oddzielić punkty tylko linią prostą.</p>
<p>Sieć MLP składa się z warstw. Każda z nich dokonuje nieliniowego przekształcenia przestrzeni (można o tym myśleć jak o składaniu przestrzeni jakąś prostą/łamaną), tak, aby w finalnej przestrzeni nasze punkty były możliwie liniowo separowalne. Wtedy ostatnia warstwa z sigmoidą będzie potrafiła je rozdzielić od siebie.</p>
<p><img src="data:image/png;base64,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" alt="1_x-3NGQv0pRIab8xDT-f_Hg.png"></p>
<p>Poszczególne neurony składają się z iloczynu skalarnego wejść z wagami neuronu, oraz nieliniowej funkcji aktywacji. W PyTorchu są to osobne obiekty - <code>nn.Linear</code> oraz np. <code>nn.Sigmoid</code>. Funkcja aktywacji przyjmuje wynik iloczynu skalarnego i przekształca go, aby sprawdzić, jak mocno reaguje neuron na dane wejście. Musi być nieliniowa z dwóch powodów. Po pierwsze, tylko nieliniowe przekształcenia są na tyle potężne, żeby umożliwić liniową separację danych w ostatniej warstwie. Po drugie, liniowe przekształcenia zwyczajnie nie działają. Aby zrozumieć czemu, trzeba zobaczyć, co matematycznie oznacza sieć MLP.</p>
<p><img src="https://www.saedsayad.com/images/Perceptron_bkp_1.png" alt="perceptron"></p>
<p>Zapisane matematycznie MLP to:</p>
<p>$\large
h_1 = f_1(x) \\
h_2 = f_2(h_1) \\
h_3 = f_3(h_2) \\
... \\
h_n = f_n(h_{n-1})
$</p>
<p>gdzie $x$ to wejście $f_i$ to funkcja aktywacji $i$-tej warstwy, a $h_i$ to wyjście $i$-tej warstwy, nazywane <strong>ukrytą reprezentacją (hidden representation)</strong>, lub <em>latent representation</em>. Nazwa bierze się z tego, że w środku sieci wyciągamy cechy i wzorce w danych, które nie są widoczne na pierwszy rzut oka na wejściu.</p>
<p>Załóżmy, że uczymy się na danych $x$ o jednym wymiarze (dla uproszczenia wzorów) oraz nie mamy funkcji aktywacji, czyli wykorzystujemy tak naprawdę aktywację liniową $f(x) = x$. Zobaczmy jak będą wyglądać dane przechodząc przez kolejne warstwy:</p>
<p>$\large
h_1 = f_1(xw_1) = xw_1 \\
h_2 = f_2(h_1w_2) = xw_1w_2 \\
... \\
h_n = f_n(h_{n-1}w_n) = xw_1w_2...w_n
$</p>
<p>gdzie $w_i$ to jest parametr $i$-tej warstwy sieci, $x$ to są dane (w naszym przypadku jedna liczba) wejściowa, a $h_i$ to wyjście $i$-tej warstwy.</p>
<p>Jak widać, taka sieć o $n$ warstwach jest równoważna sieci o jednej warstwie z parametrem $w = w_1w_2...w_n$. Wynika to z tego, że złożenie funkcji liniowych jest także funkcją liniową - patrz notatki z algebry :)</p>
<p>Jeżeli natomiast użyjemy nieliniowej funkcji aktywacji, często oznaczanej jako $\sigma$, to wszystko będzie działać. Co ważne, ostatnia warstwa, dająca wyjście sieci, ma zwykle inną aktywację od warstw wewnątrz sieci, bo też ma inne zadanie - zwrócić wartość dla klasyfikacji lub regresji. Na wyjściu korzysta się z funkcji liniowej (regresja), sigmoidalnej (klasyfikacja binarna) lub softmax (klasyfikacja wieloklasowa).</p>
<p>Wewnątrz sieci używano kiedyś sigmoidy oraz tangensa hiperbolicznego <code>tanh</code>, ale okazało się to nieefektywne przy uczeniu głębokich sieci o wielu warstwach. Nowoczesne sieci korzystają zwykle z funkcji ReLU (<em>rectified linear unit</em>), która jest zaskakująco prosta: $ReLU(x) = \max(0, x)$. Okazało się, że bardzo dobrze nadaje się do treningu nawet bardzo głębokich sieci neuronowych. Nowsze funkcje aktywacji są głównie modyfikacjami ReLU.</p>
<p><img src="https://www.nomidl.com/wp-content/uploads/2022/04/image-10.png" alt="relu"></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="MLP-w-PyTorchu">MLP w PyTorchu<a class="anchor-link" href="#MLP-w-PyTorchu">&#182;</a></h3><p>Warstwę neuronów w MLP nazywa się warstwą gęstą (<em>dense layer</em>) lub warstwą w pełni połączoną (<em>fully-connected layer</em>), i taki opis oznacza zwykle same neurony oraz funkcję aktywacji. PyTorch, jak już widzieliśmy, definiuje osobno transformację liniową oraz aktywację, a więc jedna warstwa składa się de facto z 2 obiektów, wywoływanych jeden po drugim. Inne frameworki, szczególnie wysokopoziomowe (np. Keras) łączą to często w jeden obiekt.</p>
<p>MLP składa się zatem z sekwencji obiektów, które potem wywołuje się jeden po drugim, gdzie wyjście poprzedniego to wejście kolejnego. Ale nie można tutaj używać Pythonowych list! Z perspektywy PyTorcha to wtedy niezależne obiekty i nie zostanie wtedy przekazany między nimi gradient. Trzeba tutaj skorzystać z <code>nn.Sequential</code>, aby tworzyć taki pipeline.</p>
<p>Rozmiary wejścia i wyjścia dla każdej warstwy trzeba w PyTorchu podawać explicite. Jest to po pierwsze edukacyjne, a po drugie często ułatwia wnioskowanie o działaniu sieci oraz jej debugowanie - mamy jasno podane, czego oczekujemy. Niektóre frameworki (np. Keras) obliczają to automatycznie.</p>
<p>Co ważne, ostatnia warstwa zwykle nie ma funkcji aktywacji. Wynika to z tego, że obliczanie wielu funkcji kosztu (np. entropii krzyżowej) na aktywacjach jest często niestabilne numerycznie. Z tego powodu PyTorch oferuje funkcje kosztu zawierające w środku aktywację dla ostatniej warstwy, a ich implementacje są stabilne numerycznie. Przykładowo, <code>nn.BCELoss</code> przyjmuje wejście z zaaplikowanymi już aktywacjami, ale może skutkować under/overflow, natomiast <code>nn.BCEWithLogitsLoss</code> przyjmuje wejście bez aktywacji, a w środku ma specjalną implementację łączącą binarną entropię krzyżową z aktywacją sigmoidalną. Oczywiście w związku z tym aby dokonać potem predykcji w praktyce, trzeba pamiętać o użyciu funkcji aktywacji. Często korzysta się przy tym z funkcji z modułu <code>torch.nn.functional</code>, które są w tym wypadku nieco wygodniejsze od klas wywoływalnych z <code>torch.nn</code>.</p>
<p>Całe sieci w PyTorchu tworzy się jako klasy dziedziczące po <code>nn.Module</code>. Co ważne, obiekty, z których tworzymy sieć, np. <code>nn.Linear</code>, także dziedziczą po tej klasie. Pozwala to na bardzo modułową budowę kodu, zgodną z zasadami OOP. W konstruktorze najpierw trzeba zawsze wywołać konstruktor rodzica - <code>super().__init__()</code>, a później tworzy się potrzebne obiekty i zapisuje jako atrybuty. Każdy atrybut dziedziczący po <code>nn.Module</code> lub <code>nn.Parameter</code> jest uważany za taki, który zawiera parametry sieci, a więc przy wywołaniu metody <code>parameters()</code> - parametry z tych atrybutów pojawią się w liście wszystkich parametrów. Musimy też zdefiniować metodę <code>forward()</code>, która przyjmuje tensor <code>x</code> i zwraca wynik. Typowo ta metoda po prostu używa obiektów zdefiniowanych w konstruktorze.</p>
<p><strong>UWAGA: nigdy w normalnych warunkach się nie woła metody <code>forward</code> ręcznie</strong></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-4-(0.5-punktu)">Zadanie 4 (0.5 punktu)<a class="anchor-link" href="#Zadanie-4-(0.5-punktu)">&#182;</a></h4><p>Uzupełnij implementację 3-warstwowej sieci MLP. Użyj rozmiarów:</p>
<ul>
<li>pierwsza warstwa: input_size x 256</li>
<li>druga warstwa: 256 x 128</li>
<li>trzecia warstwa: 128 x 1</li>
</ul>
<p>Użyj funkcji aktywacji ReLU.</p>
<p>Przydatne klasy:</p>
<ul>
<li><code>nn.Sequential</code></li>
<li><code>nn.Linear</code></li>
<li><code>nn.ReLU</code></li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">sigmoid</span>


<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>            
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">y_pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y_pred_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># note that we are using loss function with sigmoid built in</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">evaluation_steps</span> <span class="o">=</span> <span class="mi">200</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">evaluation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> train loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"final loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7079
Epoch 200 train loss: 0.6790
Epoch 400 train loss: 0.6542
Epoch 600 train loss: 0.6325
Epoch 800 train loss: 0.6134
Epoch 1000 train loss: 0.5965
Epoch 1200 train loss: 0.5816
Epoch 1400 train loss: 0.5684
Epoch 1600 train loss: 0.5569
Epoch 1800 train loss: 0.5467
final loss: 0.5378
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># positive class probabilities</span>
    <span class="n">y_pred_valid_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
    <span class="n">y_pred_test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">auroc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test_score</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">auroc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>

<span class="n">plot_precision_recall_curve</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred_valid_score</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>AUROC: 81.59%
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>AUROC jest podobne, a precision i recall spadły - wypadamy wręcz gorzej od regresji liniowej! Skoro dodaliśmy więcej warstw, to może pojemność modelu jest teraz za duża i trzeba by go zregularyzować?</p>
<p>Sieci neuronowe bardzo łatwo przeuczają, bo są bardzo elastycznymi i pojemnymi modelami. Dlatego mają wiele różnych rodzajów regularyzacji, których używa się razem. Co ciekawe, udowodniono eksperymentalnie, że zbyt duże sieci z mocną regularyzacją działają lepiej niż mniejsze sieci, odpowiedniego rozmiaru, za to ze słabszą regularyzacją.</p>
<p>Pierwszy rodzaj regularyzacji to znana nam już <strong>regularyzacja L2</strong>, czyli penalizacja zbyt dużych wag. W kontekście sieci neuronowych nazywa się też ją czasem <em>weight decay</em>. W PyTorchu dodaje się ją jako argument do optymalizatora.</p>
<p>Regularyzacja specyficzna dla sieci neuronowych to <strong>dropout</strong>. Polega on na losowym wyłączaniu zadanego procenta neuronów podczas treningu. Pomimo prostoty okazała się niesamowicie skuteczna, szczególnie w treningu bardzo głębokich sieci. Co ważne, jest to mechanizm używany tylko podczas treningu - w trakcie predykcji za pomocą sieci wyłącza się ten mechanizm i dokonuje normalnie predykcji całą siecią. Podejście to można potraktować jak ensemble learning, podobny do lasów losowych - wyłączając losowe części sieci, w każdej iteracji trenujemy nieco inną sieć, co odpowiada uśrednianiu predykcji różnych algorytmów. Typowo stosuje się dość mocny dropout, rzędu 25-50%. W PyTorchu implementuje go warstwa <code>nn.Dropout</code>, aplikowana zazwyczaj po funkcji aktywacji.</p>
<p>Ostatni, a być może najważniejszy rodzaj regularyzacji to <strong>wczesny stop (early stopping)</strong>. W każdym kroku mocniej dostosowujemy terenową sieć do zbioru treningowego, a więc zbyt długi trening będzie skutkował przeuczeniem. W metodzie wczesnego stopu używamy wydzielonego zbioru walidacyjnego (pojedynczego, metoda holdout), sprawdzając co określoną liczbę epok wynik na tym zbiorze. Jeżeli nie uzyskamy wyniku lepszego od najlepszego dotychczas uzyskanego przez określoną liczbę epok, to przerywamy trening. Okres, przez który czekamy na uzyskanie lepszego wyniku, to cierpliwość (<em>patience</em>). Im mniejsze, tym mocniejszy jest ten rodzaj regularyzacji, ale trzeba z tym uważać, bo łatwo jest przesadzić i zbyt szybko przerywać trening. Niektóre implementacje uwzględniają tzw. <em>grace period</em>, czyli gwarantowaną minimalną liczbę epok, przez którą będziemy trenować sieć, niezależnie od wybranej cierpliwości.</p>
<p>Dodatkowo ryzyko przeuczenia można zmniejszyć, używając mniejszej stałej uczącej.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-5-(1.5-punktu)">Zadanie 5 (1.5 punktu)<a class="anchor-link" href="#Zadanie-5-(1.5-punktu)">&#182;</a></h4><p>Zaimplementuj funkcję <code>evaluate_model()</code>, obliczającą metryki na zbiorze testowym:</p>
<ul>
<li>wartość funkcji kosztu (loss)</li>
<li>AUROC</li>
<li>optymalny próg</li>
<li>F1-score przy optymalnym progu</li>
<li>precyzję oraz recall dla optymalnego progu</li>
</ul>
<p>Jeżeli podana jest wartość argumentu <code>threshold</code>, to użyj jej do zamiany prawdopodobieństw na twarde predykcje. W przeciwnym razie użyj funkcji <code>get_optimal_threshold</code> i oblicz optymalną wartość progu.</p>
<p>Pamiętaj o przełączeniu modelu w tryb ewaluacji oraz o wyłączeniu obliczania gradientów.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">sigmoid</span>

<span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> 
    <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="c1"># implement me!</span>


    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1">### LOSS ###</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span> <span class="p">)</span>
    
    <span class="c1">### AUROC ###</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">'AUROC'</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1">### OPTIMAL VALUES ###</span>
    <span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">optimal_idx</span><span class="p">,</span> <span class="n">optimal_threshold</span> <span class="o">=</span> <span class="n">get_optimal_threshold</span><span class="p">(</span><span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">)</span>

    <span class="n">optimal_precision</span> <span class="o">=</span> <span class="n">precisions</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">]</span>
    <span class="n">optimal_recall</span> <span class="o">=</span> <span class="n">recalls</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">]</span>
    <span class="n">optimal_f1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">optimal_precision</span> <span class="o">*</span> <span class="n">optimal_recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">optimal_precision</span> <span class="o">+</span> <span class="n">optimal_recall</span><span class="p">)</span>
    
    <span class="n">results</span><span class="p">[</span><span class="s1">'threshold'</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimal_threshold</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimal_f1</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">'precision'</span><span class="p">]</span> <span class="o">=</span> <span class="n">precisions</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">'recall'</span><span class="p">]</span> <span class="o">=</span> <span class="n">recalls</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">]</span>

    <span class="c1">### PASSED THRESHOLD ####    </span>
    <span class="k">if</span> <span class="n">threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

        <span class="n">results</span><span class="p">[</span><span class="s1">'threshold'</span><span class="p">]</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">'precision'</span><span class="p">]</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">'recall'</span><span class="p">]</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">results</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-6-(0.5-punktu)">Zadanie 6 (0.5 punktu)<a class="anchor-link" href="#Zadanie-6-(0.5-punktu)">&#182;</a></h4><p>Zaimplementuj 3-warstwową sieć MLP z dropout (50%). Rozmiary warstw ukrytych mają wynosić 256 i 128.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RegularizedMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>            
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">y_pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y_pred_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Opisaliśmy wcześniej podstawowy optymalizator w sieciach neuronowych - spadek wzdłuż gradientu. Jednak wymaga on użycia całego zbioru danych, aby obliczyć gradient, co jest często niewykonalne przez rozmiar zbioru. Dlatego wymyślono <strong>stochastyczny spadek wzdłuż gradientu (stochastic gradient descent, SGD)</strong>, w którym używamy 1 przykładu naraz, liczymy gradient tylko po nim i aktualizujemy parametry. Jest to oczywiście dość grube przybliżenie gradientu, ale pozwala robić szybko dużo małych kroków. Kompromisem, którego używa się w praktyce, jest <strong>minibatch gradient descent</strong>, czyli używanie batchy np. 32, 64 czy 128 przykładów.</p>
<p>Rzadko wspominanym, a ważnym faktem jest także to, że stochastyczność metody optymalizacji jest sama w sobie też <a href="https://arxiv.org/abs/2101.12176">metodą regularyzacji</a>, a więc <code>batch_size</code> to także hiperparametr.</p>
<p>Obecnie najpopularniejszą odmianą SGD jest <a href="https://arxiv.org/abs/1412.6980">Adam</a>, gdyż uczy on szybko sieć oraz daje bardzo dobre wyniki nawet przy niekoniecznie idealnie dobranych hiperparametrach. W PyTorchu najlepiej korzystać z jego implementacji <code>AdamW</code>, która jest nieco lepsza niż implementacja <code>Adam</code>. Jest to zasadniczo zawsze wybór domyślny przy treningu współczesnych sieci neuronowych.</p>
<p>Na razie użyjemy jednak minibatch SGD.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Poniżej znajduje się implementacja prostej klasy dziedziczącej po <code>Dataset</code> - tak w PyTorchu implementuje się własne zbiory danych. Użycie takich klas umożliwia użycie klas ładujących dane (<code>DataLoader</code>), które z kolei pozwalają łatwo ładować batche danych. Trzeba w takiej klasie zaimplementować metody:</p>
<ul>
<li><code>__len__</code> - zwraca ilość punktów w zbiorze</li>
<li><code>__getitem__</code> - zwraca przykład ze zbioru pod danym indeksem oraz jego klasę</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>


<span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-7-(1.5-punktu)">Zadanie 7 (1.5 punktu)<a class="anchor-link" href="#Zadanie-7-(1.5-punktu)">&#182;</a></h4><p>Zaimplementuj pętlę treningowo-walidacyjną dla sieci neuronowej. Wykorzystaj podane wartości hiperparametrów do treningu (stała ucząca, prawdopodobieństwo dropoutu, regularyzacja L2, rozmiar batcha, maksymalna liczba epok). Użyj optymalizatora SGD.</p>
<p>Dodatkowo zaimplementuj regularyzację przez early stopping. Sprawdzaj co epokę wynik na zbiorze walidacyjnym. Użyj podanej wartości patience, a jako metryki po prostu wartości funkcji kosztu. Może się tutaj przydać zaimplementowana funkcja <code>evaluate_model()</code>.</p>
<p>Pamiętaj o tym, aby przechowywać najlepszy dotychczasowy wynik walidacyjny oraz najlepszy dotychczasowy model. Zapamiętaj też optymalny próg do klasyfikacji dla najlepszego modelu.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>


<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">dropout_p</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">l2_reg</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">early_stopping_patience</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[105]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RegularizedMLP</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
    <span class="n">dropout_p</span><span class="o">=</span><span class="n">dropout_p</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
    <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> 
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">l2_reg</span>
<span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">steps_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_threshold</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">epoch_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># note that we are using DataLoader to get batches</span>
    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
        <span class="c1"># model training</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># model evaluation, early stopping</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">valid_metrics</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">best_val_loss</span> <span class="o">&gt;</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]:</span>
        <span class="n">steps_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">best_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>
        <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'threshold'</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">steps_without_improvement</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">steps_without_improvement</span> <span class="o">==</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
            <span class="k">break</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="s2"> train loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, eval loss </span><span class="si">{</span><span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.6561, eval loss 0.8409299850463867
Epoch 1 train loss: 0.6428, eval loss 0.8347378969192505
Epoch 2 train loss: 0.6273, eval loss 0.8289541602134705
Epoch 3 train loss: 0.6176, eval loss 0.8235336542129517
Epoch 4 train loss: 0.6047, eval loss 0.8184210658073425
Epoch 5 train loss: 0.5915, eval loss 0.8135877251625061
Epoch 6 train loss: 0.5868, eval loss 0.8090202808380127
Epoch 7 train loss: 0.5759, eval loss 0.8047022223472595
Epoch 8 train loss: 0.5633, eval loss 0.800606369972229
Epoch 9 train loss: 0.5559, eval loss 0.7967148423194885
Epoch 10 train loss: 0.5538, eval loss 0.7930673360824585
Epoch 11 train loss: 0.5467, eval loss 0.7895961403846741
Epoch 12 train loss: 0.5477, eval loss 0.7863551378250122
Epoch 13 train loss: 0.5487, eval loss 0.7832545638084412
Epoch 14 train loss: 0.5344, eval loss 0.7803651094436646
Epoch 15 train loss: 0.5408, eval loss 0.7776179909706116
Epoch 16 train loss: 0.5271, eval loss 0.775051474571228
Epoch 17 train loss: 0.5202, eval loss 0.7726078629493713
Epoch 18 train loss: 0.5216, eval loss 0.7702898979187012
Epoch 19 train loss: 0.5180, eval loss 0.7681267857551575
Epoch 20 train loss: 0.5199, eval loss 0.7660524845123291
Epoch 21 train loss: 0.5221, eval loss 0.7641136050224304
Epoch 22 train loss: 0.5123, eval loss 0.762246310710907
Epoch 23 train loss: 0.5158, eval loss 0.7605046629905701
Epoch 24 train loss: 0.5142, eval loss 0.7588704824447632
Epoch 25 train loss: 0.5098, eval loss 0.7572818398475647
Epoch 26 train loss: 0.4946, eval loss 0.7557525038719177
Epoch 27 train loss: 0.4909, eval loss 0.7542656660079956
Epoch 28 train loss: 0.4980, eval loss 0.7527868747711182
Epoch 29 train loss: 0.4870, eval loss 0.7513915300369263
Epoch 30 train loss: 0.4985, eval loss 0.7501153349876404
Epoch 31 train loss: 0.4844, eval loss 0.748813807964325
Epoch 32 train loss: 0.4875, eval loss 0.7475222945213318
Epoch 33 train loss: 0.4839, eval loss 0.7462928295135498
Epoch 34 train loss: 0.4799, eval loss 0.745082437992096
Epoch 35 train loss: 0.4729, eval loss 0.743872344493866
Epoch 36 train loss: 0.4772, eval loss 0.7427512407302856
Epoch 37 train loss: 0.4587, eval loss 0.741654634475708
Epoch 38 train loss: 0.4683, eval loss 0.740588903427124
Epoch 39 train loss: 0.4546, eval loss 0.7394770979881287
Epoch 40 train loss: 0.4707, eval loss 0.7384206056594849
Epoch 41 train loss: 0.4547, eval loss 0.7374183535575867
Epoch 42 train loss: 0.4643, eval loss 0.7364249229431152
Epoch 43 train loss: 0.4492, eval loss 0.7354336380958557
Epoch 44 train loss: 0.4486, eval loss 0.7344078421592712
Epoch 45 train loss: 0.4715, eval loss 0.733426034450531
Epoch 46 train loss: 0.4487, eval loss 0.732463002204895
Epoch 47 train loss: 0.4550, eval loss 0.7315363883972168
Epoch 48 train loss: 0.4443, eval loss 0.7307389974594116
Epoch 49 train loss: 0.4264, eval loss 0.7298889756202698
Epoch 50 train loss: 0.4430, eval loss 0.7290868163108826
Epoch 51 train loss: 0.4401, eval loss 0.7282419800758362
Epoch 52 train loss: 0.4479, eval loss 0.7274570465087891
Epoch 53 train loss: 0.4382, eval loss 0.7266631722450256
Epoch 54 train loss: 0.4411, eval loss 0.725945770740509
Epoch 55 train loss: 0.4404, eval loss 0.725200355052948
Epoch 56 train loss: 0.4370, eval loss 0.7244736552238464
Epoch 57 train loss: 0.4198, eval loss 0.7238161563873291
Epoch 58 train loss: 0.4274, eval loss 0.723158061504364
Epoch 59 train loss: 0.4232, eval loss 0.7224931120872498
Epoch 60 train loss: 0.4127, eval loss 0.7218281030654907
Epoch 61 train loss: 0.4388, eval loss 0.7212294936180115
Epoch 62 train loss: 0.4194, eval loss 0.7206520438194275
Epoch 63 train loss: 0.4268, eval loss 0.7200978994369507
Epoch 64 train loss: 0.4219, eval loss 0.7194838523864746
Epoch 65 train loss: 0.4114, eval loss 0.7189707159996033
Epoch 66 train loss: 0.4288, eval loss 0.7184216380119324
Epoch 67 train loss: 0.4360, eval loss 0.7179437875747681
Epoch 68 train loss: 0.4130, eval loss 0.7173982262611389
Epoch 69 train loss: 0.4309, eval loss 0.7169532179832458
Epoch 70 train loss: 0.4191, eval loss 0.716463565826416
Epoch 71 train loss: 0.4135, eval loss 0.7159793972969055
Epoch 72 train loss: 0.4146, eval loss 0.7154910564422607
Epoch 73 train loss: 0.4013, eval loss 0.7150589227676392
Epoch 74 train loss: 0.4334, eval loss 0.7146172523498535
Epoch 75 train loss: 0.4073, eval loss 0.7141782641410828
Epoch 76 train loss: 0.4077, eval loss 0.7137504816055298
Epoch 77 train loss: 0.4089, eval loss 0.7133535146713257
Epoch 78 train loss: 0.4117, eval loss 0.7129895687103271
Epoch 79 train loss: 0.4110, eval loss 0.7126367092132568
Epoch 80 train loss: 0.3972, eval loss 0.7122700810432434
Epoch 81 train loss: 0.3827, eval loss 0.7118843793869019
Epoch 82 train loss: 0.4118, eval loss 0.7115022540092468
Epoch 83 train loss: 0.4104, eval loss 0.7111331820487976
Epoch 84 train loss: 0.4483, eval loss 0.7107885479927063
Epoch 85 train loss: 0.3891, eval loss 0.7104740738868713
Epoch 86 train loss: 0.3773, eval loss 0.7101176381111145
Epoch 87 train loss: 0.4279, eval loss 0.7098321318626404
Epoch 88 train loss: 0.4035, eval loss 0.7095593214035034
Epoch 89 train loss: 0.4172, eval loss 0.7092218995094299
Epoch 90 train loss: 0.4035, eval loss 0.7089887857437134
Epoch 91 train loss: 0.4103, eval loss 0.7087026238441467
Epoch 92 train loss: 0.4172, eval loss 0.7082858085632324
Epoch 93 train loss: 0.4131, eval loss 0.7081155776977539
Epoch 94 train loss: 0.4055, eval loss 0.7078969478607178
Epoch 95 train loss: 0.3892, eval loss 0.7076750993728638
Epoch 96 train loss: 0.4234, eval loss 0.7073931694030762
Epoch 97 train loss: 0.4054, eval loss 0.7071532607078552
Epoch 98 train loss: 0.3909, eval loss 0.7069347500801086
Epoch 99 train loss: 0.3986, eval loss 0.706795334815979
Epoch 100 train loss: 0.3852, eval loss 0.7065563201904297
Epoch 101 train loss: 0.4149, eval loss 0.7063311338424683
Epoch 102 train loss: 0.3924, eval loss 0.7060286998748779
Epoch 103 train loss: 0.4049, eval loss 0.7058963179588318
Epoch 104 train loss: 0.3815, eval loss 0.7057217955589294
Epoch 105 train loss: 0.3709, eval loss 0.7055555582046509
Epoch 106 train loss: 0.3919, eval loss 0.7053222060203552
Epoch 107 train loss: 0.3907, eval loss 0.7052744626998901
Epoch 108 train loss: 0.3980, eval loss 0.705079197883606
Epoch 109 train loss: 0.3888, eval loss 0.7048582434654236
Epoch 110 train loss: 0.3937, eval loss 0.7046995162963867
Epoch 111 train loss: 0.4140, eval loss 0.7045410871505737
Epoch 112 train loss: 0.4010, eval loss 0.7042675614356995
Epoch 113 train loss: 0.3945, eval loss 0.7040615677833557
Epoch 114 train loss: 0.3924, eval loss 0.7038549184799194
Epoch 115 train loss: 0.3781, eval loss 0.7038099765777588
Epoch 116 train loss: 0.4092, eval loss 0.7035799622535706
Epoch 117 train loss: 0.3958, eval loss 0.7034440040588379
Epoch 118 train loss: 0.3943, eval loss 0.703405499458313
Epoch 119 train loss: 0.3858, eval loss 0.703220784664154
Epoch 120 train loss: 0.3864, eval loss 0.703070878982544
Epoch 121 train loss: 0.3814, eval loss 0.7028730511665344
Epoch 122 train loss: 0.4085, eval loss 0.7028163075447083
Epoch 123 train loss: 0.4213, eval loss 0.7027440667152405
Epoch 124 train loss: 0.3959, eval loss 0.7026003003120422
Epoch 125 train loss: 0.3735, eval loss 0.7024908065795898
Epoch 126 train loss: 0.4050, eval loss 0.7023977041244507
Epoch 127 train loss: 0.4365, eval loss 0.7023091316223145
Epoch 128 train loss: 0.3616, eval loss 0.7022541165351868
Epoch 129 train loss: 0.4093, eval loss 0.7021613121032715
Epoch 130 train loss: 0.3911, eval loss 0.7020716071128845
Epoch 131 train loss: 0.3772, eval loss 0.7019233107566833
Epoch 132 train loss: 0.3841, eval loss 0.7017985582351685
Epoch 133 train loss: 0.3895, eval loss 0.7016856670379639
Epoch 134 train loss: 0.3753, eval loss 0.7015910744667053
Epoch 135 train loss: 0.3659, eval loss 0.7014528512954712
Epoch 136 train loss: 0.3547, eval loss 0.701321005821228
Epoch 137 train loss: 0.3673, eval loss 0.7012854218482971
Epoch 138 train loss: 0.4117, eval loss 0.7012841701507568
Epoch 139 train loss: 0.3933, eval loss 0.7011747360229492
Epoch 140 train loss: 0.3890, eval loss 0.7010185718536377
Epoch 141 train loss: 0.3743, eval loss 0.7008830308914185
Epoch 142 train loss: 0.3987, eval loss 0.700796365737915
Epoch 143 train loss: 0.3966, eval loss 0.7007476091384888
Epoch 144 train loss: 0.3866, eval loss 0.7006731629371643
Epoch 145 train loss: 0.3881, eval loss 0.7005882263183594
Epoch 146 train loss: 0.4075, eval loss 0.7004398703575134
Epoch 147 train loss: 0.3704, eval loss 0.7003726363182068
Epoch 148 train loss: 0.3895, eval loss 0.700339674949646
Epoch 149 train loss: 0.4096, eval loss 0.7002452611923218
Epoch 150 train loss: 0.3738, eval loss 0.7001515030860901
Epoch 151 train loss: 0.3552, eval loss 0.7000755667686462
Epoch 152 train loss: 0.4122, eval loss 0.7000067234039307
Epoch 153 train loss: 0.3868, eval loss 0.6999034881591797
Epoch 154 train loss: 0.3783, eval loss 0.699785590171814
Epoch 155 train loss: 0.3960, eval loss 0.6997497081756592
Epoch 156 train loss: 0.3443, eval loss 0.6996443271636963
Epoch 157 train loss: 0.3924, eval loss 0.6995765566825867
Epoch 158 train loss: 0.3675, eval loss 0.6994516253471375
Epoch 159 train loss: 0.3970, eval loss 0.6994103789329529
Epoch 160 train loss: 0.3726, eval loss 0.6993390917778015
Epoch 161 train loss: 0.3789, eval loss 0.6992347836494446
Epoch 162 train loss: 0.3636, eval loss 0.6992636322975159
Epoch 163 train loss: 0.3696, eval loss 0.6992079019546509
Epoch 164 train loss: 0.4027, eval loss 0.6990893483161926
Epoch 165 train loss: 0.3764, eval loss 0.6989359855651855
Epoch 166 train loss: 0.3867, eval loss 0.6988809108734131
Epoch 167 train loss: 0.3803, eval loss 0.6987667679786682
Epoch 168 train loss: 0.4091, eval loss 0.6986765265464783
Epoch 169 train loss: 0.3699, eval loss 0.6987003087997437
Epoch 170 train loss: 0.3600, eval loss 0.698591411113739
Epoch 171 train loss: 0.3756, eval loss 0.6985532641410828
Epoch 172 train loss: 0.3769, eval loss 0.6984434723854065
Epoch 173 train loss: 0.3813, eval loss 0.698372483253479
Epoch 174 train loss: 0.4015, eval loss 0.6983578205108643
Epoch 175 train loss: 0.4137, eval loss 0.6983200907707214
Epoch 176 train loss: 0.3641, eval loss 0.6982592344284058
Epoch 177 train loss: 0.3707, eval loss 0.6981958150863647
Epoch 178 train loss: 0.3809, eval loss 0.6980910897254944
Epoch 179 train loss: 0.3671, eval loss 0.698129415512085
Epoch 180 train loss: 0.3833, eval loss 0.6981008648872375
Epoch 181 train loss: 0.4258, eval loss 0.6980197429656982
Epoch 182 train loss: 0.3800, eval loss 0.6979659795761108
Epoch 183 train loss: 0.3858, eval loss 0.6979085206985474
Epoch 184 train loss: 0.3585, eval loss 0.697880744934082
Epoch 185 train loss: 0.4210, eval loss 0.6977826952934265
Epoch 186 train loss: 0.3541, eval loss 0.697681725025177
Epoch 187 train loss: 0.4049, eval loss 0.6977058053016663
Epoch 188 train loss: 0.3724, eval loss 0.6976835131645203
Epoch 189 train loss: 0.3760, eval loss 0.6975659728050232
Epoch 190 train loss: 0.3701, eval loss 0.6974442005157471
Epoch 191 train loss: 0.3996, eval loss 0.697385847568512
Epoch 192 train loss: 0.3832, eval loss 0.697351336479187
Epoch 193 train loss: 0.3858, eval loss 0.697209894657135
Epoch 194 train loss: 0.3764, eval loss 0.6971180438995361
Epoch 195 train loss: 0.3741, eval loss 0.6970224976539612
Epoch 196 train loss: 0.3615, eval loss 0.696982741355896
Epoch 197 train loss: 0.3752, eval loss 0.6969619393348694
Epoch 198 train loss: 0.3657, eval loss 0.6969533562660217
Epoch 199 train loss: 0.3589, eval loss 0.6968921422958374
Epoch 200 train loss: 0.3456, eval loss 0.6968883275985718
Epoch 201 train loss: 0.3544, eval loss 0.6967845559120178
Epoch 202 train loss: 0.3629, eval loss 0.6966912746429443
Epoch 203 train loss: 0.3659, eval loss 0.6967068910598755
Epoch 204 train loss: 0.3788, eval loss 0.6966730952262878
Epoch 205 train loss: 0.3902, eval loss 0.6966158747673035
Epoch 206 train loss: 0.3666, eval loss 0.6965816020965576
Epoch 207 train loss: 0.3931, eval loss 0.6965628862380981
Epoch 208 train loss: 0.3835, eval loss 0.6964662671089172
Epoch 209 train loss: 0.3602, eval loss 0.696416437625885
Epoch 210 train loss: 0.3617, eval loss 0.696419358253479
Epoch 211 train loss: 0.3796, eval loss 0.6963728666305542
Epoch 212 train loss: 0.3925, eval loss 0.6963205933570862
Epoch 213 train loss: 0.3519, eval loss 0.6962488293647766
Epoch 214 train loss: 0.3505, eval loss 0.6961947083473206
Epoch 215 train loss: 0.3862, eval loss 0.6961609125137329
Epoch 216 train loss: 0.3551, eval loss 0.6960450410842896
Epoch 217 train loss: 0.3787, eval loss 0.6959863901138306
Epoch 218 train loss: 0.3570, eval loss 0.6959823369979858
Epoch 219 train loss: 0.3597, eval loss 0.69593346118927
Epoch 220 train loss: 0.3660, eval loss 0.6958901882171631
Epoch 221 train loss: 0.3850, eval loss 0.6958471536636353
Epoch 222 train loss: 0.3689, eval loss 0.6958526968955994
Epoch 223 train loss: 0.3589, eval loss 0.6958857178688049
Epoch 224 train loss: 0.3686, eval loss 0.6957935094833374
Epoch 225 train loss: 0.3991, eval loss 0.695766270160675
Epoch 226 train loss: 0.3735, eval loss 0.6957316398620605
Epoch 227 train loss: 0.3463, eval loss 0.6956485509872437
Epoch 228 train loss: 0.3516, eval loss 0.6955118775367737
Epoch 229 train loss: 0.3890, eval loss 0.695419192314148
Epoch 230 train loss: 0.4000, eval loss 0.6954576969146729
Epoch 231 train loss: 0.3797, eval loss 0.6954153776168823
Epoch 232 train loss: 0.4223, eval loss 0.6953117847442627
Epoch 233 train loss: 0.3948, eval loss 0.6952800750732422
Epoch 234 train loss: 0.3749, eval loss 0.6952531337738037
Epoch 235 train loss: 0.3811, eval loss 0.695278525352478
Epoch 236 train loss: 0.3912, eval loss 0.6951786875724792
Epoch 237 train loss: 0.3819, eval loss 0.6951428055763245
Epoch 238 train loss: 0.3937, eval loss 0.6950604915618896
Epoch 239 train loss: 0.3887, eval loss 0.6950553059577942
Epoch 240 train loss: 0.3748, eval loss 0.6949936747550964
Epoch 241 train loss: 0.3433, eval loss 0.6949865221977234
Epoch 242 train loss: 0.3714, eval loss 0.6949794888496399
Epoch 243 train loss: 0.3680, eval loss 0.694897472858429
Epoch 244 train loss: 0.3899, eval loss 0.6948021650314331
Epoch 245 train loss: 0.3500, eval loss 0.6947320103645325
Epoch 246 train loss: 0.3436, eval loss 0.6947509050369263
Epoch 247 train loss: 0.3601, eval loss 0.6947082877159119
Epoch 248 train loss: 0.3812, eval loss 0.6946653723716736
Epoch 249 train loss: 0.3780, eval loss 0.6946221590042114
Epoch 250 train loss: 0.3813, eval loss 0.694658637046814
Epoch 251 train loss: 0.3572, eval loss 0.6946781873703003
Epoch 252 train loss: 0.3986, eval loss 0.6946726441383362
Epoch 253 train loss: 0.3843, eval loss 0.6946136355400085
Epoch 254 train loss: 0.3488, eval loss 0.6945663094520569
Epoch 255 train loss: 0.3814, eval loss 0.6945155262947083
Epoch 256 train loss: 0.3526, eval loss 0.6944079399108887
Epoch 257 train loss: 0.3913, eval loss 0.6943414807319641
Epoch 258 train loss: 0.3666, eval loss 0.6942801475524902
Epoch 259 train loss: 0.3973, eval loss 0.6942387223243713
Epoch 260 train loss: 0.3425, eval loss 0.694188117980957
Epoch 261 train loss: 0.3755, eval loss 0.6941350698471069
Epoch 262 train loss: 0.3769, eval loss 0.6940568089485168
Epoch 263 train loss: 0.3704, eval loss 0.6940329670906067
Epoch 264 train loss: 0.3752, eval loss 0.6940045356750488
Epoch 265 train loss: 0.3669, eval loss 0.6940960884094238
Epoch 266 train loss: 0.3621, eval loss 0.694042980670929
Epoch 267 train loss: 0.3674, eval loss 0.6940310597419739
Epoch 268 train loss: 0.3838, eval loss 0.6939846277236938
Epoch 269 train loss: 0.3813, eval loss 0.6939203143119812
Epoch 270 train loss: 0.3620, eval loss 0.6938971281051636
Epoch 271 train loss: 0.3738, eval loss 0.6938096284866333
Epoch 272 train loss: 0.3375, eval loss 0.6937267184257507
Epoch 273 train loss: 0.3506, eval loss 0.6936832070350647
Epoch 274 train loss: 0.3598, eval loss 0.6937447190284729
Epoch 275 train loss: 0.3728, eval loss 0.6937463283538818
Epoch 276 train loss: 0.3630, eval loss 0.6936777234077454
Epoch 277 train loss: 0.3646, eval loss 0.6936774849891663
Epoch 278 train loss: 0.3661, eval loss 0.6935334205627441
Epoch 279 train loss: 0.3692, eval loss 0.6935674548149109
Epoch 280 train loss: 0.3239, eval loss 0.693548321723938
Epoch 281 train loss: 0.3739, eval loss 0.6935914754867554
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[106]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">best_threshold</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'AUROC'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"F1: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'precision'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Recall: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'recall'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>AUROC: 90.09%
F1: 68.32%
Precision: 62.96%
Recall: 74.68%
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Wyniki wyglądają już dużo lepiej.</p>
<p>Na koniec laboratorium dołożymy do naszego modelu jeszcze 3 powrzechnie używane techniki, które są bardzo proste, a pozwalają często ulepszyć wynik modelu.</p>
<p>Pierwszą z nich są <strong>warstwy normalizacji (normalization layers)</strong>. Powstały one początkowo z założeniem, że przez przekształcenia przestrzeni dokonywane przez sieć zmienia się rozkład prawdopodobieństw pomiędzy warstwami, czyli tzw. <em>internal covariate shift</em>. Później okazało się, że zastosowanie takiej normalizacji wygładza powierzchnię funkcji kosztu, co ułatwia i przyspiesza optymalizację. Najpowszechniej używaną normalizacją jest <strong>batch normalization (batch norm)</strong>.</p>
<p>Drugim ulepszeniem jest dodanie <strong>wag klas (class weights)</strong>. Mamy do czynienia z problemem klasyfikacji niezbalansowanej, więc klasa mniejszościowa, ważniejsza dla nas, powinna dostać większą wagę. Implementuje się to trywialnie prosto - po prostu mnożymy wartość funkcji kosztu dla danego przykładu przez wagę dla prawdziwej klasy tego przykładu. Praktycznie każdy klasyfikator operujący na jakiejś ważonej funkcji może działać w ten sposób, nie tylko sieci neuronowe.</p>
<p>Ostatnim ulepszeniem jest zamiana SGD na optymalizator Adam, a konkretnie na optymalizator <code>AdamW</code>. Jest to przykład <strong>optymalizatora adaptacyjnego (adaptive optimizer)</strong>, który potrafi zaadaptować stałą uczącą dla każdego parametru z osobna w trakcie treningu. Wykorzystuje do tego gradienty - w uproszczeniu, im większa wariancja gradientu, tym mniejsze kroki w tym kierunku robimy.</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Zadanie-8-(0.5-punktu)">Zadanie 8 (0.5 punktu)<a class="anchor-link" href="#Zadanie-8-(0.5-punktu)">&#182;</a></h4><p>Zaimplementuj model <code>NormalizingMLP</code>, o takiej samej strukturze jak <code>RegularizedMLP</code>, ale dodatkowo z warstwami <code>BatchNorm1d</code> pomiędzy warstwami <code>Linear</code> oraz <code>ReLU</code>.</p>
<p>Za pomocą funkcji <code>compute_class_weight()</code> oblicz wagi dla poszczególnych klas. Użyj opcji <code>"balanced"</code>. Przekaż do funkcji kosztu wagę klasy pozytywnej (pamiętaj, aby zamienić ją na tensor).</p>
<p>Zamień używany optymalizator na <code>AdamW</code>.</p>
<p>Na koniec skopiuj resztę kodu do treningu z poprzedniego zadania, wytrenuj sieć i oblicz wyniki na zbiorze testowym.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[111]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">NormalizingMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>            
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">y_pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y_pred_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[117]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define all the hyperparameters</span>
<span class="c1"># your_code</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">compute_class_weight</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>


<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">dropout_p</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">l2_reg</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">early_stopping_patience</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">compute_class_weight</span><span class="p">(</span>
    <span class="s2">"balanced"</span><span class="p">,</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
<span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[118]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># training loop</span>
<span class="c1"># your_code</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">NormalizingMLP</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
    <span class="n">dropout_p</span><span class="o">=</span><span class="n">dropout_p</span>
<span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
    <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> 
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">l2_reg</span>
<span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">steps_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_threshold</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">epoch_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># note that we are using DataLoader to get batches</span>
    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
        <span class="c1"># model training</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># model evaluation, early stopping</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">valid_metrics</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">best_val_loss</span> <span class="o">&gt;</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]:</span>
        <span class="n">steps_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">best_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>
        <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'threshold'</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">steps_without_improvement</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">steps_without_improvement</span> <span class="o">==</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
            <span class="k">break</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="s2"> train loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, eval loss </span><span class="si">{</span><span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7869, eval loss 1.44856595993042
Epoch 1 train loss: 0.7464, eval loss 1.4412180185317993
Epoch 2 train loss: 0.7870, eval loss 1.437193512916565
Epoch 3 train loss: 0.7217, eval loss 1.4344581365585327
Epoch 4 train loss: 0.7118, eval loss 1.4328137636184692
Epoch 5 train loss: 0.7708, eval loss 1.4321856498718262
Epoch 6 train loss: 0.7051, eval loss 1.430405855178833
Epoch 7 train loss: 0.7059, eval loss 1.4293659925460815
Epoch 8 train loss: 0.6812, eval loss 1.4294514656066895
Epoch 9 train loss: 0.7394, eval loss 1.430424690246582
Epoch 10 train loss: 0.7216, eval loss 1.4290835857391357
Epoch 11 train loss: 0.6852, eval loss 1.4301484823226929
Epoch 12 train loss: 0.7425, eval loss 1.4270368814468384
Epoch 13 train loss: 0.6844, eval loss 1.4269318580627441
Epoch 14 train loss: 0.6379, eval loss 1.4273426532745361
Epoch 15 train loss: 0.6733, eval loss 1.4252169132232666
Epoch 16 train loss: 0.6584, eval loss 1.4285341501235962
Epoch 17 train loss: 0.7431, eval loss 1.424997329711914
Epoch 18 train loss: 0.7770, eval loss 1.4259560108184814
Epoch 19 train loss: 0.6831, eval loss 1.4249225854873657
Epoch 20 train loss: 0.6499, eval loss 1.4277982711791992
Epoch 21 train loss: 0.6947, eval loss 1.4284847974777222
Epoch 22 train loss: 0.6292, eval loss 1.4268122911453247
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[119]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">best_threshold</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'AUROC'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"F1: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'precision'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Recall: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'recall'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>AUROC: 90.73%
F1: 69.41%
Precision: 64.84%
Recall: 74.68%
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Akceleracja-sprz%C4%99towa-(dla-zainteresowanych)">Akceleracja sprz&#281;towa (dla zainteresowanych)<a class="anchor-link" href="#Akceleracja-sprz%C4%99towa-(dla-zainteresowanych)">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Jak wcześniej wspominaliśmy, użycie akceleracji sprzętowej, czyli po prostu GPU do obliczeń, jest bardzo efektywne w przypadku sieci neuronowych. Karty graficzne bardzo efektywnie mnożą macierze, a sieci neuronowe to, jak można było się przekonać, dużo mnożenia macierzy.</p>
<p>W PyTorchu jest to dosyć łatwe, ale trzeba robić to explicite. Służy do tego metoda <code>.to()</code>, która przenosi tensory między CPU i GPU. Poniżej przykład, jak to się robi (oczywiście trzeba mieć skonfigurowane GPU, żeby działało):</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span> 


<span class="k">class</span> <span class="nc">CudaMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">y_pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y_pred_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">CudaMLP</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># note that we are using loss function with sigmoid built in</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span><span class="n">pos_weight</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">))</span>

<span class="n">step_counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">time_from_eval</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span>
        <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">),</span> <span class="n">batch_y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">step_counter</span> <span class="o">%</span> <span class="n">evaluation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch_id</span><span class="si">}</span><span class="s2"> train loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_from_eval</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="n">time_from_eval</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="n">step_counter</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">test_res</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">),</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">),</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_res</span><span class="p">[</span><span class="s1">'AUROC'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"F1: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_res</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_res</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Co prawda ten model nie będzie tak dobry jak ten z laboratorium, ale zwróć uwagę, o ile jest większy, a przy tym szybszy.</p>
<p>Dla zainteresowanych polecamy <a href="https://medium.com/@adi.fu7/ai-accelerators-part-i-intro-822c2cdb4ca4">tę serie artykułów</a></p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Zadanie-dla-ch%C4%99tnych">Zadanie dla ch&#281;tnych<a class="anchor-link" href="#Zadanie-dla-ch%C4%99tnych">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Jak widzieliśmy, sieci neuronowe mają bardzo dużo hiperparametrów. Przeszukiwanie ich grid search'em jest więc niewykonalne, a chociaż random search by działał, to potrzebowałby wielu iteracji, co też jest kosztowne obliczeniowo.</p>
<p>Zaimplementuj inteligentne przeszukiwanie przestrzeni hiperparametrów za pomocą biblioteki <a href="https://optuna.org/">Optuna</a>. Implementuje ona między innymi algorytm Tree Parzen Estimator (TPE), należący do grupy algorytmów typu Bayesian search. Typowo osiągają one bardzo dobre wyniki, a właściwie zawsze lepsze od przeszukiwania losowego. Do tego wystarcza im często niewielka liczba kroków.</p>
<p>Zaimplementuj 3-warstwową sieć MLP, gdzie pierwsza warstwa ma rozmiar ukryty N, a druga N // 2. Ucz ją optymalizatorem Adam przez maksymalnie 300 epok z cierpliwością 10.</p>
<p>Przeszukaj wybrane zakresy dla hiperparametrów:</p>
<ul>
<li>rozmiar warstw ukrytych (N)</li>
<li>stała ucząca</li>
<li>batch size</li>
<li>siła regularyzacji L2</li>
<li>prawdopodobieństwo dropoutu</li>
</ul>
<p>Wykorzystaj przynajmniej 30 iteracji. Następnie przełącz algorytm na losowy (Optuna także jego implementuje), wykonaj 30 iteracji i porównaj jakość wyników.</p>
<p>Przydatne materiały:</p>
<ul>
<li><a href="https://optuna.org/#code_examples">Optuna code examples - PyTorch</a></li>
<li><a href="https://www.youtube.com/watch?v=P6NwZVl8ttc">Auto-Tuning Hyperparameters with Optuna and PyTorch</a></li>
<li><a href="https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837">Hyperparameter Tuning of Neural Networks with Optuna and PyTorch</a></li>
<li><a href="https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36">Using Optuna to Optimize PyTorch Hyperparameters</a></li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[126]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">OptimizedMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">hidden_layer_size</span>
        <span class="n">n_half</span> <span class="o">=</span> <span class="n">hidden_layer_size</span> <span class="o">//</span> <span class="mi">2</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>            
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>
            
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n_half</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n_half</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">),</span>
            
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_half</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">y_pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y_pred_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[162]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">150</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[163]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">optuna</span>

<span class="k">def</span> <span class="nf">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">hidden_layers_size</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span>
        <span class="s1">'hidden_layers_size'</span><span class="p">,</span> 
        <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> 
        <span class="mi">2</span> <span class="o">*</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span>

    <span class="n">dropout_p</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
        <span class="s1">'dropout_p'</span><span class="p">,</span>
        <span class="mf">0.25</span><span class="p">,</span>
        <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">OptimizedMLP</span><span class="p">(</span>
        <span class="n">input_size</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
        <span class="n">dropout_p</span> <span class="o">=</span> <span class="n">dropout_p</span><span class="p">,</span>
        <span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="n">hidden_layers_size</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="n">steps_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">best_threshold</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">epoch_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># note that we are using DataLoader to get batches</span>
        <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
            <span class="c1"># model training</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># model evaluation, early stopping</span>
        
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="n">valid_metrics</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">best_val_loss</span> <span class="o">&gt;</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]:</span>
            <span class="n">steps_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">best_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>
            <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'threshold'</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">steps_without_improvement</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="k">if</span> <span class="n">steps_without_improvement</span> <span class="o">==</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="s2"> train loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, eval loss </span><span class="si">{</span><span class="n">valid_metrics</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">best_val_loss</span><span class="p">,</span> <span class="n">best_threshold</span>

<span class="k">def</span> <span class="nf">train_optuna</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">)</span>

    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
        <span class="s1">'learning_rate'</span><span class="p">,</span> 
        <span class="mf">1e-6</span><span class="p">,</span> 
        <span class="mf">1e-1</span><span class="p">,</span> 
        <span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span>
        <span class="s1">'batch_size'</span><span class="p">,</span>
        <span class="mi">128</span><span class="p">,</span>
        <span class="mi">512</span><span class="p">,</span>
        <span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span>

    <span class="n">l2_reg</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
        <span class="s1">'l2_reg'</span><span class="p">,</span>
        <span class="mf">1e-5</span><span class="p">,</span>
        <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
        <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> 
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">l2_reg</span>
    <span class="p">)</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="n">compute_class_weight</span><span class="p">(</span>
        <span class="s2">"balanced"</span><span class="p">,</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
    <span class="p">)</span>

    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">train_optuna</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[164]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s2">"maximize"</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">TPESampler</span><span class="p">())</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:38:50,215] A new study created in memory with name: no-name-f220af00-cc84-4850-9f86-164e31e35988
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.6165, eval loss 1.4268232583999634
Epoch 1 train loss: 0.3124, eval loss 1.4239012002944946
Epoch 2 train loss: 0.3173, eval loss 1.4223229885101318
Epoch 3 train loss: 0.4300, eval loss 1.4196330308914185
Epoch 4 train loss: 0.3357, eval loss 1.42090904712677
Epoch 5 train loss: 0.3804, eval loss 1.4262138605117798
Epoch 6 train loss: 0.2801, eval loss 1.4227888584136963
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:38:55,868] Trial 0 finished with value: 1.4196330308914185 and parameters: {&#39;hidden_layers_size&#39;: 185, &#39;dropout_p&#39;: 0.4068804799715802, &#39;learning_rate&#39;: 0.010978991823991393, &#39;batch_size&#39;: 336, &#39;l2_reg&#39;: 1.34641142059497e-05}. Best is trial 0 with value: 1.4196330308914185.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4006, eval loss 1.8089185953140259
Epoch 1 train loss: 1.3063, eval loss 1.8107423782348633
Epoch 2 train loss: 1.5072, eval loss 1.8080438375473022
Epoch 3 train loss: 1.2947, eval loss 1.8089221715927124
Epoch 4 train loss: 1.5810, eval loss 1.8088653087615967
Epoch 5 train loss: 1.2184, eval loss 1.803401231765747
Epoch 6 train loss: 1.5646, eval loss 1.8060569763183594
Epoch 7 train loss: 1.5708, eval loss 1.8051623106002808
Epoch 8 train loss: 1.2308, eval loss 1.805528163909912
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:39:04,094] Trial 1 finished with value: 1.803401231765747 and parameters: {&#39;hidden_layers_size&#39;: 87, &#39;dropout_p&#39;: 0.489907983890005, &#39;learning_rate&#39;: 1.5461728272636294e-06, &#39;batch_size&#39;: 217, &#39;l2_reg&#39;: 3.202440992612983e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.0667, eval loss 1.639102816581726
Epoch 1 train loss: 0.9433, eval loss 1.5832183361053467
Epoch 2 train loss: 0.8702, eval loss 1.5496737957000732
Epoch 3 train loss: 0.7843, eval loss 1.5267010927200317
Epoch 4 train loss: 0.7905, eval loss 1.5078661441802979
Epoch 5 train loss: 0.7655, eval loss 1.4926570653915405
Epoch 6 train loss: 0.7302, eval loss 1.4817637205123901
Epoch 7 train loss: 0.7016, eval loss 1.4728914499282837
Epoch 8 train loss: 0.6590, eval loss 1.4652535915374756
Epoch 9 train loss: 0.6883, eval loss 1.4596012830734253
Epoch 10 train loss: 0.6854, eval loss 1.454770803451538
Epoch 11 train loss: 0.6550, eval loss 1.4515832662582397
Epoch 12 train loss: 0.6722, eval loss 1.4480564594268799
Epoch 13 train loss: 0.6607, eval loss 1.4452193975448608
Epoch 14 train loss: 0.6588, eval loss 1.4436118602752686
Epoch 15 train loss: 0.6329, eval loss 1.442274808883667
Epoch 16 train loss: 0.6586, eval loss 1.441723108291626
Epoch 17 train loss: 0.6220, eval loss 1.4393420219421387
Epoch 18 train loss: 0.6148, eval loss 1.4382113218307495
Epoch 19 train loss: 0.6167, eval loss 1.4390060901641846
Epoch 20 train loss: 0.6166, eval loss 1.4370743036270142
Epoch 21 train loss: 0.6414, eval loss 1.4359771013259888
Epoch 22 train loss: 0.6174, eval loss 1.4367042779922485
Epoch 23 train loss: 0.6275, eval loss 1.434579610824585
Epoch 24 train loss: 0.6210, eval loss 1.434201717376709
Epoch 25 train loss: 0.5864, eval loss 1.4344539642333984
Epoch 26 train loss: 0.6058, eval loss 1.4329931735992432
Epoch 27 train loss: 0.5602, eval loss 1.4331417083740234
Epoch 28 train loss: 0.5961, eval loss 1.433791160583496
Epoch 29 train loss: 0.6109, eval loss 1.4332058429718018
Epoch 30 train loss: 0.5723, eval loss 1.4322681427001953
Epoch 31 train loss: 0.5948, eval loss 1.4325464963912964
Epoch 32 train loss: 0.5785, eval loss 1.4316482543945312
Epoch 33 train loss: 0.5881, eval loss 1.431742548942566
Epoch 34 train loss: 0.5957, eval loss 1.432404637336731
Epoch 35 train loss: 0.6269, eval loss 1.4318515062332153
Epoch 36 train loss: 0.5890, eval loss 1.431180477142334
Epoch 37 train loss: 0.5957, eval loss 1.431395411491394
Epoch 38 train loss: 0.6278, eval loss 1.4301395416259766
Epoch 39 train loss: 0.5612, eval loss 1.4311411380767822
Epoch 40 train loss: 0.5937, eval loss 1.430301308631897
Epoch 41 train loss: 0.6031, eval loss 1.430803656578064
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:39:24,705] Trial 2 finished with value: 1.4301395416259766 and parameters: {&#39;hidden_layers_size&#39;: 65, &#39;dropout_p&#39;: 0.2828372333521446, &#39;learning_rate&#39;: 0.0003532557894056364, &#39;batch_size&#39;: 480, &#39;l2_reg&#39;: 0.0009952730340921808}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.0391, eval loss 1.5901604890823364
Epoch 1 train loss: 1.0020, eval loss 1.5303393602371216
Epoch 2 train loss: 0.8757, eval loss 1.4990736246109009
Epoch 3 train loss: 0.7983, eval loss 1.481130838394165
Epoch 4 train loss: 0.8153, eval loss 1.4686423540115356
Epoch 5 train loss: 0.7615, eval loss 1.4606677293777466
Epoch 6 train loss: 0.7651, eval loss 1.4554810523986816
Epoch 7 train loss: 0.6799, eval loss 1.451284646987915
Epoch 8 train loss: 0.6614, eval loss 1.4473800659179688
Epoch 9 train loss: 0.6153, eval loss 1.444901466369629
Epoch 10 train loss: 0.6636, eval loss 1.4433597326278687
Epoch 11 train loss: 0.5631, eval loss 1.4416804313659668
Epoch 12 train loss: 0.5281, eval loss 1.4404723644256592
Epoch 13 train loss: 0.6120, eval loss 1.4387907981872559
Epoch 14 train loss: 0.6434, eval loss 1.4377154111862183
Epoch 15 train loss: 0.5691, eval loss 1.4362729787826538
Epoch 16 train loss: 0.5504, eval loss 1.4362157583236694
Epoch 17 train loss: 0.5421, eval loss 1.435915231704712
Epoch 18 train loss: 0.5252, eval loss 1.4360144138336182
Epoch 19 train loss: 0.5927, eval loss 1.4343713521957397
Epoch 20 train loss: 0.5174, eval loss 1.4345661401748657
Epoch 21 train loss: 0.5311, eval loss 1.4346139430999756
Epoch 22 train loss: 0.5057, eval loss 1.4338819980621338
Epoch 23 train loss: 0.5412, eval loss 1.4336930513381958
Epoch 24 train loss: 0.5581, eval loss 1.4332866668701172
Epoch 25 train loss: 0.4556, eval loss 1.4320528507232666
Epoch 26 train loss: 0.4795, eval loss 1.4322551488876343
Epoch 27 train loss: 0.3712, eval loss 1.4306191205978394
Epoch 28 train loss: 0.5136, eval loss 1.4311975240707397
Epoch 29 train loss: 0.4568, eval loss 1.4318902492523193
Epoch 30 train loss: 0.4184, eval loss 1.431145429611206
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:39:50,437] Trial 3 finished with value: 1.4306191205978394 and parameters: {&#39;hidden_layers_size&#39;: 189, &#39;dropout_p&#39;: 0.335446125087379, &#39;learning_rate&#39;: 0.00018634702171506481, &#39;batch_size&#39;: 260, &#39;l2_reg&#39;: 6.065164275108682e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7101, eval loss 1.4648549556732178
Epoch 1 train loss: 0.6525, eval loss 1.4420949220657349
Epoch 2 train loss: 0.6222, eval loss 1.4417181015014648
Epoch 3 train loss: 0.6030, eval loss 1.4371815919876099
Epoch 4 train loss: 0.5852, eval loss 1.437233328819275
Epoch 5 train loss: 0.5928, eval loss 1.4368410110473633
Epoch 6 train loss: 0.5767, eval loss 1.436415672302246
Epoch 7 train loss: 0.6206, eval loss 1.434099555015564
Epoch 8 train loss: 0.5776, eval loss 1.4362107515335083
Epoch 9 train loss: 0.5927, eval loss 1.4324151277542114
Epoch 10 train loss: 0.5776, eval loss 1.433035135269165
Epoch 11 train loss: 0.5652, eval loss 1.4331684112548828
Epoch 12 train loss: 0.5829, eval loss 1.433249831199646
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:39:58,782] Trial 4 finished with value: 1.4324151277542114 and parameters: {&#39;hidden_layers_size&#39;: 111, &#39;dropout_p&#39;: 0.3002039437138742, &#39;learning_rate&#39;: 0.0029727208396297736, &#39;batch_size&#39;: 479, &#39;l2_reg&#39;: 0.0004831397700544172}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.2200, eval loss 1.4228744506835938
Epoch 1 train loss: 1.5240, eval loss 1.424627661705017
Epoch 2 train loss: 0.5862, eval loss 1.4265384674072266
Epoch 3 train loss: 0.7615, eval loss 1.4238454103469849
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:40:02,430] Trial 5 finished with value: 1.4228744506835938 and parameters: {&#39;hidden_layers_size&#39;: 100, &#39;dropout_p&#39;: 0.30626568843058916, &#39;learning_rate&#39;: 0.01473230680293548, &#39;batch_size&#39;: 251, &#39;l2_reg&#39;: 2.3166256377940516e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.6699, eval loss 1.8016992807388306
Epoch 1 train loss: 1.6497, eval loss 1.7856029272079468
Epoch 2 train loss: 1.5298, eval loss 1.7725859880447388
Epoch 3 train loss: 1.4894, eval loss 1.759587049484253
Epoch 4 train loss: 1.5360, eval loss 1.7461634874343872
Epoch 5 train loss: 1.4696, eval loss 1.735628366470337
Epoch 6 train loss: 1.4066, eval loss 1.7246735095977783
Epoch 7 train loss: 1.4880, eval loss 1.7139297723770142
Epoch 8 train loss: 1.3360, eval loss 1.7058454751968384
Epoch 9 train loss: 1.3030, eval loss 1.6972993612289429
Epoch 10 train loss: 1.2669, eval loss 1.688965082168579
Epoch 11 train loss: 1.2152, eval loss 1.6797707080841064
Epoch 12 train loss: 1.2954, eval loss 1.6718412637710571
Epoch 13 train loss: 1.3042, eval loss 1.6656986474990845
Epoch 14 train loss: 1.2156, eval loss 1.6593745946884155
Epoch 15 train loss: 1.1645, eval loss 1.6524603366851807
Epoch 16 train loss: 1.1380, eval loss 1.6486958265304565
Epoch 17 train loss: 1.1759, eval loss 1.6407350301742554
Epoch 18 train loss: 1.1640, eval loss 1.634558916091919
Epoch 19 train loss: 1.0818, eval loss 1.6285488605499268
Epoch 20 train loss: 1.1409, eval loss 1.622857928276062
Epoch 21 train loss: 1.0949, eval loss 1.618492603302002
Epoch 22 train loss: 1.0803, eval loss 1.6117292642593384
Epoch 23 train loss: 1.0637, eval loss 1.609265923500061
Epoch 24 train loss: 1.0803, eval loss 1.6050031185150146
Epoch 25 train loss: 1.0090, eval loss 1.6005512475967407
Epoch 26 train loss: 1.0586, eval loss 1.5938721895217896
Epoch 27 train loss: 0.9790, eval loss 1.5909181833267212
Epoch 28 train loss: 0.9927, eval loss 1.587903380393982
Epoch 29 train loss: 0.9975, eval loss 1.583985447883606
Epoch 30 train loss: 0.9600, eval loss 1.5794833898544312
Epoch 31 train loss: 0.9684, eval loss 1.5754896402359009
Epoch 32 train loss: 0.9574, eval loss 1.5719006061553955
Epoch 33 train loss: 0.9508, eval loss 1.567445993423462
Epoch 34 train loss: 0.9923, eval loss 1.5647518634796143
Epoch 35 train loss: 0.9737, eval loss 1.5604335069656372
Epoch 36 train loss: 0.8961, eval loss 1.5573360919952393
Epoch 37 train loss: 0.9108, eval loss 1.5550050735473633
Epoch 38 train loss: 0.9401, eval loss 1.5506829023361206
Epoch 39 train loss: 0.9177, eval loss 1.547379493713379
Epoch 40 train loss: 0.9231, eval loss 1.545825719833374
Epoch 41 train loss: 0.8827, eval loss 1.5431911945343018
Epoch 42 train loss: 0.9013, eval loss 1.5384799242019653
Epoch 43 train loss: 0.8497, eval loss 1.5374996662139893
Epoch 44 train loss: 0.8911, eval loss 1.5331547260284424
Epoch 45 train loss: 0.9135, eval loss 1.531075358390808
Epoch 46 train loss: 0.9234, eval loss 1.528848648071289
Epoch 47 train loss: 0.8796, eval loss 1.5257123708724976
Epoch 48 train loss: 0.8745, eval loss 1.5234793424606323
Epoch 49 train loss: 0.8856, eval loss 1.52005136013031
Epoch 50 train loss: 0.8124, eval loss 1.5172702074050903
Epoch 51 train loss: 0.8890, eval loss 1.516763687133789
Epoch 52 train loss: 0.7924, eval loss 1.5149588584899902
Epoch 53 train loss: 0.8400, eval loss 1.512819528579712
Epoch 54 train loss: 0.8502, eval loss 1.5106505155563354
Epoch 55 train loss: 0.8398, eval loss 1.5081615447998047
Epoch 56 train loss: 0.9005, eval loss 1.5058271884918213
Epoch 57 train loss: 0.7846, eval loss 1.5043561458587646
Epoch 58 train loss: 0.7754, eval loss 1.5018864870071411
Epoch 59 train loss: 0.7727, eval loss 1.5000813007354736
Epoch 60 train loss: 0.7975, eval loss 1.49947988986969
Epoch 61 train loss: 0.7536, eval loss 1.4966392517089844
Epoch 62 train loss: 0.7543, eval loss 1.4946093559265137
Epoch 63 train loss: 0.7961, eval loss 1.4929084777832031
Epoch 64 train loss: 0.8572, eval loss 1.491731882095337
Epoch 65 train loss: 0.7491, eval loss 1.489554762840271
Epoch 66 train loss: 0.7930, eval loss 1.4880799055099487
Epoch 67 train loss: 0.7957, eval loss 1.4872444868087769
Epoch 68 train loss: 0.7758, eval loss 1.4841591119766235
Epoch 69 train loss: 0.7258, eval loss 1.4841735363006592
Epoch 70 train loss: 0.7812, eval loss 1.4828404188156128
Epoch 71 train loss: 0.7518, eval loss 1.480738639831543
Epoch 72 train loss: 0.7439, eval loss 1.480164885520935
Epoch 73 train loss: 0.7682, eval loss 1.4779590368270874
Epoch 74 train loss: 0.7093, eval loss 1.4767645597457886
Epoch 75 train loss: 0.7767, eval loss 1.4758574962615967
Epoch 76 train loss: 0.7658, eval loss 1.474073052406311
Epoch 77 train loss: 0.7690, eval loss 1.4729076623916626
Epoch 78 train loss: 0.8140, eval loss 1.4731075763702393
Epoch 79 train loss: 0.7225, eval loss 1.4719288349151611
Epoch 80 train loss: 0.7645, eval loss 1.4698455333709717
Epoch 81 train loss: 0.7477, eval loss 1.4690333604812622
Epoch 82 train loss: 0.7604, eval loss 1.4681764841079712
Epoch 83 train loss: 0.6761, eval loss 1.4683641195297241
Epoch 84 train loss: 0.7650, eval loss 1.467284917831421
Epoch 85 train loss: 0.8347, eval loss 1.466341257095337
Epoch 86 train loss: 0.8314, eval loss 1.4636174440383911
Epoch 87 train loss: 0.7387, eval loss 1.4640828371047974
Epoch 88 train loss: 0.7881, eval loss 1.463499665260315
Epoch 89 train loss: 0.7606, eval loss 1.462046504020691
Epoch 90 train loss: 0.8032, eval loss 1.4616669416427612
Epoch 91 train loss: 0.7557, eval loss 1.4607808589935303
Epoch 92 train loss: 0.7102, eval loss 1.4612168073654175
Epoch 93 train loss: 0.7275, eval loss 1.4596590995788574
Epoch 94 train loss: 0.7650, eval loss 1.459149956703186
Epoch 95 train loss: 0.7271, eval loss 1.4587626457214355
Epoch 96 train loss: 0.7520, eval loss 1.4579203128814697
Epoch 97 train loss: 0.8317, eval loss 1.4561989307403564
Epoch 98 train loss: 0.7345, eval loss 1.4564491510391235
Epoch 99 train loss: 0.6612, eval loss 1.4558125734329224
Epoch 100 train loss: 0.6806, eval loss 1.4550824165344238
Epoch 101 train loss: 0.8046, eval loss 1.4551901817321777
Epoch 102 train loss: 0.7548, eval loss 1.4549497365951538
Epoch 103 train loss: 0.7179, eval loss 1.4545493125915527
Epoch 104 train loss: 0.7267, eval loss 1.4537991285324097
Epoch 105 train loss: 0.7203, eval loss 1.4534190893173218
Epoch 106 train loss: 0.6919, eval loss 1.4522143602371216
Epoch 107 train loss: 0.6610, eval loss 1.451969861984253
Epoch 108 train loss: 0.7182, eval loss 1.4516774415969849
Epoch 109 train loss: 0.6822, eval loss 1.4513895511627197
Epoch 110 train loss: 0.6786, eval loss 1.4515290260314941
Epoch 111 train loss: 0.6311, eval loss 1.4504663944244385
Epoch 112 train loss: 0.7588, eval loss 1.4511898756027222
Epoch 113 train loss: 0.7873, eval loss 1.4506075382232666
Epoch 114 train loss: 0.7808, eval loss 1.4493201971054077
Epoch 115 train loss: 0.7201, eval loss 1.4499626159667969
Epoch 116 train loss: 0.7099, eval loss 1.4492477178573608
Epoch 117 train loss: 0.7099, eval loss 1.4484987258911133
Epoch 118 train loss: 0.6836, eval loss 1.448036789894104
Epoch 119 train loss: 0.7526, eval loss 1.4487088918685913
Epoch 120 train loss: 0.6991, eval loss 1.4479246139526367
Epoch 121 train loss: 0.6833, eval loss 1.4469679594039917
Epoch 122 train loss: 0.8528, eval loss 1.4476804733276367
Epoch 123 train loss: 0.7155, eval loss 1.4475998878479004
Epoch 124 train loss: 0.7075, eval loss 1.4464120864868164
Epoch 125 train loss: 0.7285, eval loss 1.4462188482284546
Epoch 126 train loss: 0.7296, eval loss 1.446033000946045
Epoch 127 train loss: 0.6743, eval loss 1.446428894996643
Epoch 128 train loss: 0.7866, eval loss 1.445650577545166
Epoch 129 train loss: 0.7161, eval loss 1.445623517036438
Epoch 130 train loss: 0.7108, eval loss 1.44606351852417
Epoch 131 train loss: 0.7697, eval loss 1.4451706409454346
Epoch 132 train loss: 0.7739, eval loss 1.4458459615707397
Epoch 133 train loss: 0.6980, eval loss 1.4458417892456055
Epoch 134 train loss: 0.7386, eval loss 1.4452126026153564
Epoch 135 train loss: 0.6964, eval loss 1.4445562362670898
Epoch 136 train loss: 0.7420, eval loss 1.4444639682769775
Epoch 137 train loss: 0.7708, eval loss 1.4445425271987915
Epoch 138 train loss: 0.6912, eval loss 1.4447767734527588
Epoch 139 train loss: 0.7671, eval loss 1.443927526473999
Epoch 140 train loss: 0.7424, eval loss 1.443878412246704
Epoch 141 train loss: 0.6911, eval loss 1.4440687894821167
Epoch 142 train loss: 0.6826, eval loss 1.443906307220459
Epoch 143 train loss: 0.6962, eval loss 1.4429848194122314
Epoch 144 train loss: 0.7127, eval loss 1.4434078931808472
Epoch 145 train loss: 0.7231, eval loss 1.442967176437378
Epoch 146 train loss: 0.7263, eval loss 1.4430404901504517
Epoch 147 train loss: 0.7582, eval loss 1.4426188468933105
Epoch 148 train loss: 0.6586, eval loss 1.4420490264892578
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:42:11,962] Trial 6 finished with value: 1.4420490264892578 and parameters: {&#39;hidden_layers_size&#39;: 84, &#39;dropout_p&#39;: 0.355192902719554, &#39;learning_rate&#39;: 1.1856994355524345e-05, &#39;batch_size&#39;: 147, &#39;l2_reg&#39;: 1.1533970697156625e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7004, eval loss 1.4422955513000488
Epoch 0 train loss: 0.7592, eval loss 1.4392565488815308
Epoch 1 train loss: 0.7097, eval loss 1.4312855005264282
Epoch 2 train loss: 0.6643, eval loss 1.427862286567688
Epoch 3 train loss: 0.6484, eval loss 1.4265140295028687
Epoch 4 train loss: 0.6531, eval loss 1.4262874126434326
Epoch 5 train loss: 0.7326, eval loss 1.4252033233642578
Epoch 6 train loss: 0.6856, eval loss 1.4260015487670898
Epoch 7 train loss: 0.6636, eval loss 1.4266576766967773
Epoch 8 train loss: 0.6856, eval loss 1.425023078918457
Epoch 9 train loss: 0.5903, eval loss 1.4265354871749878
Epoch 10 train loss: 0.6423, eval loss 1.4254704713821411
Epoch 11 train loss: 0.6942, eval loss 1.4237393140792847
Epoch 12 train loss: 0.6342, eval loss 1.4245840311050415
Epoch 13 train loss: 0.5949, eval loss 1.4243565797805786
Epoch 14 train loss: 0.6283, eval loss 1.4231367111206055
Epoch 15 train loss: 0.6178, eval loss 1.4227485656738281
Epoch 16 train loss: 0.7032, eval loss 1.4238309860229492
Epoch 17 train loss: 0.5609, eval loss 1.4228121042251587
Epoch 18 train loss: 0.6001, eval loss 1.4235873222351074
Epoch 19 train loss: 0.6500, eval loss 1.4222842454910278
Epoch 20 train loss: 0.6411, eval loss 1.4223191738128662
Epoch 21 train loss: 0.6135, eval loss 1.42316734790802
Epoch 22 train loss: 0.5872, eval loss 1.422120213508606
Epoch 23 train loss: 0.5283, eval loss 1.4248380661010742
Epoch 24 train loss: 0.4965, eval loss 1.4259033203125
Epoch 25 train loss: 0.5722, eval loss 1.4222320318222046
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:42:43,105] Trial 7 finished with value: 1.422120213508606 and parameters: {&#39;hidden_layers_size&#39;: 135, &#39;dropout_p&#39;: 0.2877508594801334, &#39;learning_rate&#39;: 0.0012921275464269674, &#39;batch_size&#39;: 134, &#39;l2_reg&#39;: 0.00010354605429446324}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.6664, eval loss 1.4368209838867188
Epoch 1 train loss: 0.6912, eval loss 1.4383376836776733
Epoch 2 train loss: 0.6330, eval loss 1.439626932144165
Epoch 3 train loss: 0.6815, eval loss 1.4426182508468628
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:42:46,498] Trial 8 finished with value: 1.4368209838867188 and parameters: {&#39;hidden_layers_size&#39;: 57, &#39;dropout_p&#39;: 0.39520546062488676, &#39;learning_rate&#39;: 0.04739320270422495, &#39;batch_size&#39;: 299, &#39;l2_reg&#39;: 0.00027050363398514217}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7169, eval loss 1.437097430229187
Epoch 1 train loss: 0.6942, eval loss 1.4335131645202637
Epoch 2 train loss: 0.6211, eval loss 1.4369632005691528
Epoch 3 train loss: 0.5548, eval loss 1.432682752609253
Epoch 4 train loss: 0.4627, eval loss 1.4263136386871338
Epoch 5 train loss: 0.4237, eval loss 1.4300023317337036
Epoch 6 train loss: 0.4951, eval loss 1.4350719451904297
Epoch 7 train loss: 0.4578, eval loss 1.4267882108688354
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:42:52,393] Trial 9 finished with value: 1.4263136386871338 and parameters: {&#39;hidden_layers_size&#39;: 54, &#39;dropout_p&#39;: 0.27146235362128895, &#39;learning_rate&#39;: 0.033780962695344606, &#39;batch_size&#39;: 416, &#39;l2_reg&#39;: 0.0005398007559151257}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.6318, eval loss 1.7973930835723877
Epoch 1 train loss: 1.6002, eval loss 1.796926736831665
Epoch 2 train loss: 1.6157, eval loss 1.7940939664840698
Epoch 3 train loss: 1.5813, eval loss 1.7941765785217285
Epoch 4 train loss: 1.6756, eval loss 1.7914142608642578
Epoch 5 train loss: 1.6057, eval loss 1.792375087738037
Epoch 6 train loss: 1.6146, eval loss 1.7913492918014526
Epoch 7 train loss: 1.5977, eval loss 1.7900804281234741
Epoch 8 train loss: 1.5971, eval loss 1.7896268367767334
Epoch 9 train loss: 1.5961, eval loss 1.7872806787490845
Epoch 10 train loss: 1.5491, eval loss 1.7876583337783813
Epoch 11 train loss: 1.5600, eval loss 1.786561131477356
Epoch 12 train loss: 1.5939, eval loss 1.7874130010604858
Epoch 13 train loss: 1.5272, eval loss 1.7850030660629272
Epoch 14 train loss: 1.5095, eval loss 1.7855640649795532
Epoch 15 train loss: 1.5599, eval loss 1.78235924243927
Epoch 16 train loss: 1.6034, eval loss 1.7819253206253052
Epoch 17 train loss: 1.4992, eval loss 1.7817376852035522
Epoch 18 train loss: 1.5742, eval loss 1.7811191082000732
Epoch 19 train loss: 1.5720, eval loss 1.7803540229797363
Epoch 20 train loss: 1.5188, eval loss 1.7784830331802368
Epoch 21 train loss: 1.6284, eval loss 1.7795604467391968
Epoch 22 train loss: 1.5497, eval loss 1.7764678001403809
Epoch 23 train loss: 1.5303, eval loss 1.778303861618042
Epoch 24 train loss: 1.4943, eval loss 1.7758839130401611
Epoch 25 train loss: 1.4996, eval loss 1.7742345333099365
Epoch 26 train loss: 1.5342, eval loss 1.7746669054031372
Epoch 27 train loss: 1.4758, eval loss 1.7741087675094604
Epoch 28 train loss: 1.4156, eval loss 1.772607684135437
Epoch 29 train loss: 1.5492, eval loss 1.7711381912231445
Epoch 30 train loss: 1.5378, eval loss 1.7713180780410767
Epoch 31 train loss: 1.5496, eval loss 1.7711883783340454
Epoch 32 train loss: 1.4927, eval loss 1.7704815864562988
Epoch 33 train loss: 1.5266, eval loss 1.7678653001785278
Epoch 34 train loss: 1.5215, eval loss 1.7679048776626587
Epoch 35 train loss: 1.5421, eval loss 1.7671693563461304
Epoch 36 train loss: 1.5486, eval loss 1.7651704549789429
Epoch 37 train loss: 1.5192, eval loss 1.765358805656433
Epoch 38 train loss: 1.4675, eval loss 1.7650904655456543
Epoch 39 train loss: 1.5190, eval loss 1.7628147602081299
Epoch 40 train loss: 1.5934, eval loss 1.7614825963974
Epoch 41 train loss: 1.4542, eval loss 1.7622405290603638
Epoch 42 train loss: 1.4441, eval loss 1.7608944177627563
Epoch 43 train loss: 1.4920, eval loss 1.760528326034546
Epoch 44 train loss: 1.5279, eval loss 1.7580983638763428
Epoch 45 train loss: 1.5449, eval loss 1.7592554092407227
Epoch 46 train loss: 1.3923, eval loss 1.759053349494934
Epoch 47 train loss: 1.4729, eval loss 1.7577433586120605
Epoch 48 train loss: 1.5021, eval loss 1.756988525390625
Epoch 49 train loss: 1.4489, eval loss 1.7551144361495972
Epoch 50 train loss: 1.4601, eval loss 1.7563542127609253
Epoch 51 train loss: 1.4878, eval loss 1.7548794746398926
Epoch 52 train loss: 1.4664, eval loss 1.7538247108459473
Epoch 53 train loss: 1.4402, eval loss 1.7525420188903809
Epoch 54 train loss: 1.4746, eval loss 1.7524384260177612
Epoch 55 train loss: 1.4872, eval loss 1.7505831718444824
Epoch 56 train loss: 1.4231, eval loss 1.749868631362915
Epoch 57 train loss: 1.4093, eval loss 1.7489101886749268
Epoch 58 train loss: 1.4167, eval loss 1.7483218908309937
Epoch 59 train loss: 1.4568, eval loss 1.7466069459915161
Epoch 60 train loss: 1.3651, eval loss 1.746770977973938
Epoch 61 train loss: 1.4520, eval loss 1.7469158172607422
Epoch 62 train loss: 1.3957, eval loss 1.7458343505859375
Epoch 63 train loss: 1.4053, eval loss 1.7469652891159058
Epoch 64 train loss: 1.4768, eval loss 1.7457165718078613
Epoch 65 train loss: 1.4467, eval loss 1.7443095445632935
Epoch 66 train loss: 1.4575, eval loss 1.7419847249984741
Epoch 67 train loss: 1.4021, eval loss 1.7421622276306152
Epoch 68 train loss: 1.4200, eval loss 1.740753173828125
Epoch 69 train loss: 1.4054, eval loss 1.7415751218795776
Epoch 70 train loss: 1.3760, eval loss 1.74049711227417
Epoch 71 train loss: 1.4248, eval loss 1.7410472631454468
Epoch 72 train loss: 1.4468, eval loss 1.739323377609253
Epoch 73 train loss: 1.3298, eval loss 1.7385668754577637
Epoch 74 train loss: 1.4285, eval loss 1.736103892326355
Epoch 75 train loss: 1.3471, eval loss 1.736605167388916
Epoch 76 train loss: 1.3971, eval loss 1.737483263015747
Epoch 77 train loss: 1.3560, eval loss 1.7349069118499756
Epoch 78 train loss: 1.3214, eval loss 1.7355058193206787
Epoch 79 train loss: 1.4128, eval loss 1.7343909740447998
Epoch 80 train loss: 1.3944, eval loss 1.7330044507980347
Epoch 81 train loss: 1.3977, eval loss 1.7321697473526
Epoch 82 train loss: 1.3650, eval loss 1.7324614524841309
Epoch 83 train loss: 1.3644, eval loss 1.7293366193771362
Epoch 84 train loss: 1.3753, eval loss 1.7310136556625366
Epoch 85 train loss: 1.3253, eval loss 1.7307064533233643
Epoch 86 train loss: 1.3737, eval loss 1.7284531593322754
Epoch 87 train loss: 1.3638, eval loss 1.7275105714797974
Epoch 88 train loss: 1.3547, eval loss 1.7277889251708984
Epoch 89 train loss: 1.3452, eval loss 1.727121114730835
Epoch 90 train loss: 1.4130, eval loss 1.7255934476852417
Epoch 91 train loss: 1.3998, eval loss 1.7256163358688354
Epoch 92 train loss: 1.3902, eval loss 1.7251936197280884
Epoch 93 train loss: 1.3286, eval loss 1.7231608629226685
Epoch 94 train loss: 1.2983, eval loss 1.7228481769561768
Epoch 95 train loss: 1.3632, eval loss 1.7228000164031982
Epoch 96 train loss: 1.3349, eval loss 1.7226454019546509
Epoch 97 train loss: 1.4063, eval loss 1.7206428050994873
Epoch 98 train loss: 1.3292, eval loss 1.720682144165039
Epoch 99 train loss: 1.3508, eval loss 1.7198140621185303
Epoch 100 train loss: 1.3305, eval loss 1.7198797464370728
Epoch 101 train loss: 1.3111, eval loss 1.7182456254959106
Epoch 102 train loss: 1.3268, eval loss 1.7169724702835083
Epoch 103 train loss: 1.3537, eval loss 1.7180862426757812
Epoch 104 train loss: 1.2488, eval loss 1.7180230617523193
Epoch 105 train loss: 1.3810, eval loss 1.7174699306488037
Epoch 106 train loss: 1.3200, eval loss 1.7149995565414429
Epoch 107 train loss: 1.3049, eval loss 1.713407039642334
Epoch 108 train loss: 1.3186, eval loss 1.713971734046936
Epoch 109 train loss: 1.2934, eval loss 1.7134974002838135
Epoch 110 train loss: 1.2997, eval loss 1.7138559818267822
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:44:28,580] Trial 10 finished with value: 1.713407039642334 and parameters: {&#39;hidden_layers_size&#39;: 78, &#39;dropout_p&#39;: 0.4910729724376275, &#39;learning_rate&#39;: 1.1621568817979394e-06, &#39;batch_size&#39;: 185, &#39;l2_reg&#39;: 3.8426680434817866e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.3505, eval loss 1.7458510398864746
Epoch 1 train loss: 1.4506, eval loss 1.7476296424865723
Epoch 2 train loss: 1.6246, eval loss 1.7434031963348389
Epoch 3 train loss: 1.3902, eval loss 1.7433992624282837
Epoch 4 train loss: 1.2796, eval loss 1.742552399635315
Epoch 5 train loss: 1.5304, eval loss 1.7440767288208008
Epoch 6 train loss: 1.3807, eval loss 1.7423486709594727
Epoch 7 train loss: 1.4468, eval loss 1.7437301874160767
Epoch 8 train loss: 1.3772, eval loss 1.7398512363433838
Epoch 9 train loss: 1.3458, eval loss 1.7365080118179321
Epoch 10 train loss: 1.4339, eval loss 1.738708257675171
Epoch 11 train loss: 1.4199, eval loss 1.73784601688385
Epoch 12 train loss: 1.3294, eval loss 1.7347745895385742
Epoch 13 train loss: 1.3824, eval loss 1.7365102767944336
Epoch 14 train loss: 1.3253, eval loss 1.7370673418045044
Epoch 15 train loss: 1.4182, eval loss 1.7333968877792358
Epoch 16 train loss: 1.4185, eval loss 1.7358115911483765
Epoch 17 train loss: 1.3776, eval loss 1.7329570055007935
Epoch 18 train loss: 1.5551, eval loss 1.73142409324646
Epoch 19 train loss: 1.3110, eval loss 1.730339765548706
Epoch 20 train loss: 1.5562, eval loss 1.7303712368011475
Epoch 21 train loss: 1.2186, eval loss 1.7308940887451172
Epoch 22 train loss: 1.2656, eval loss 1.7297781705856323
Epoch 23 train loss: 1.2852, eval loss 1.7293438911437988
Epoch 24 train loss: 1.3581, eval loss 1.7263926267623901
Epoch 25 train loss: 1.4185, eval loss 1.7252845764160156
Epoch 26 train loss: 1.3750, eval loss 1.7269313335418701
Epoch 27 train loss: 1.4366, eval loss 1.7244364023208618
Epoch 28 train loss: 1.2807, eval loss 1.724387764930725
Epoch 29 train loss: 1.3855, eval loss 1.7210564613342285
Epoch 30 train loss: 1.3996, eval loss 1.7229435443878174
Epoch 31 train loss: 1.3354, eval loss 1.7207221984863281
Epoch 32 train loss: 1.3122, eval loss 1.7196489572525024
Epoch 33 train loss: 1.3369, eval loss 1.718311071395874
Epoch 34 train loss: 1.3726, eval loss 1.717880129814148
Epoch 35 train loss: 1.3721, eval loss 1.7201381921768188
Epoch 36 train loss: 1.3861, eval loss 1.7154780626296997
Epoch 37 train loss: 1.4021, eval loss 1.717442274093628
Epoch 38 train loss: 1.2420, eval loss 1.7137306928634644
Epoch 39 train loss: 1.4700, eval loss 1.716137409210205
Epoch 40 train loss: 1.2427, eval loss 1.7144205570220947
Epoch 41 train loss: 1.2774, eval loss 1.7137333154678345
Epoch 42 train loss: 1.2292, eval loss 1.7122368812561035
Epoch 43 train loss: 1.2016, eval loss 1.7116039991378784
Epoch 44 train loss: 1.2712, eval loss 1.711971402168274
Epoch 45 train loss: 1.2904, eval loss 1.7107570171356201
Epoch 46 train loss: 1.2438, eval loss 1.7108920812606812
Epoch 47 train loss: 1.3075, eval loss 1.7105425596237183
Epoch 48 train loss: 1.2767, eval loss 1.7091178894042969
Epoch 49 train loss: 1.3638, eval loss 1.7075575590133667
Epoch 50 train loss: 1.3835, eval loss 1.705471396446228
Epoch 51 train loss: 1.2842, eval loss 1.7054766416549683
Epoch 52 train loss: 1.2966, eval loss 1.7026890516281128
Epoch 53 train loss: 1.1752, eval loss 1.7045233249664307
Epoch 54 train loss: 1.3497, eval loss 1.70432710647583
Epoch 55 train loss: 1.3437, eval loss 1.7040495872497559
Epoch 56 train loss: 1.3222, eval loss 1.7019009590148926
Epoch 57 train loss: 1.2845, eval loss 1.701688289642334
Epoch 58 train loss: 1.3356, eval loss 1.7043287754058838
Epoch 59 train loss: 1.3652, eval loss 1.69980788230896
Epoch 60 train loss: 1.2849, eval loss 1.7001556158065796
Epoch 61 train loss: 1.2543, eval loss 1.6975685358047485
Epoch 62 train loss: 1.4672, eval loss 1.698020100593567
Epoch 63 train loss: 1.4363, eval loss 1.6979811191558838
Epoch 64 train loss: 1.2959, eval loss 1.7002378702163696
Epoch 65 train loss: 1.2403, eval loss 1.6966832876205444
Epoch 66 train loss: 1.1722, eval loss 1.6946477890014648
Epoch 67 train loss: 1.2036, eval loss 1.69508695602417
Epoch 68 train loss: 1.2053, eval loss 1.693541407585144
Epoch 69 train loss: 1.2420, eval loss 1.6958141326904297
Epoch 70 train loss: 1.2227, eval loss 1.692574143409729
Epoch 71 train loss: 1.2002, eval loss 1.6918610334396362
Epoch 72 train loss: 1.2226, eval loss 1.691811442375183
Epoch 73 train loss: 1.1923, eval loss 1.6906547546386719
Epoch 74 train loss: 1.1325, eval loss 1.6919276714324951
Epoch 75 train loss: 1.2392, eval loss 1.6914095878601074
Epoch 76 train loss: 1.3771, eval loss 1.6875888109207153
Epoch 77 train loss: 1.2845, eval loss 1.6868525743484497
Epoch 78 train loss: 1.2786, eval loss 1.6871377229690552
Epoch 79 train loss: 1.3281, eval loss 1.6858446598052979
Epoch 80 train loss: 1.2435, eval loss 1.685321569442749
Epoch 81 train loss: 1.1295, eval loss 1.6863970756530762
Epoch 82 train loss: 1.2788, eval loss 1.6862276792526245
Epoch 83 train loss: 1.2405, eval loss 1.684199333190918
Epoch 84 train loss: 1.1968, eval loss 1.6829135417938232
Epoch 85 train loss: 1.3198, eval loss 1.683470606803894
Epoch 86 train loss: 1.3817, eval loss 1.6802082061767578
Epoch 87 train loss: 1.2060, eval loss 1.6802618503570557
Epoch 88 train loss: 1.3056, eval loss 1.6804393529891968
Epoch 89 train loss: 1.2474, eval loss 1.679996371269226
Epoch 90 train loss: 1.1881, eval loss 1.6810623407363892
Epoch 91 train loss: 1.1684, eval loss 1.6768361330032349
Epoch 92 train loss: 1.2729, eval loss 1.6786175966262817
Epoch 93 train loss: 1.1260, eval loss 1.6776829957962036
Epoch 94 train loss: 1.1712, eval loss 1.6760671138763428
Epoch 95 train loss: 1.3693, eval loss 1.6771034002304077
Epoch 96 train loss: 1.1372, eval loss 1.674038290977478
Epoch 97 train loss: 1.1997, eval loss 1.6748460531234741
Epoch 98 train loss: 1.2216, eval loss 1.6716227531433105
Epoch 99 train loss: 1.1177, eval loss 1.6759041547775269
Epoch 100 train loss: 1.1722, eval loss 1.674620270729065
Epoch 101 train loss: 1.2552, eval loss 1.6731897592544556
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:45:39,739] Trial 11 finished with value: 1.6716227531433105 and parameters: {&#39;hidden_layers_size&#39;: 79, &#39;dropout_p&#39;: 0.4995540527585774, &#39;learning_rate&#39;: 1.0013372175504955e-06, &#39;batch_size&#39;: 189, &#39;l2_reg&#39;: 5.62465192894945e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4351, eval loss 1.761287808418274
Epoch 1 train loss: 1.4471, eval loss 1.761607050895691
Epoch 2 train loss: 1.4363, eval loss 1.7590199708938599
Epoch 3 train loss: 1.4894, eval loss 1.757539987564087
Epoch 4 train loss: 1.4315, eval loss 1.7598501443862915
Epoch 5 train loss: 1.4426, eval loss 1.7580764293670654
Epoch 6 train loss: 1.4760, eval loss 1.7573615312576294
Epoch 7 train loss: 1.4877, eval loss 1.7588859796524048
Epoch 8 train loss: 1.5256, eval loss 1.7556606531143188
Epoch 9 train loss: 1.4199, eval loss 1.7555103302001953
Epoch 10 train loss: 1.5000, eval loss 1.7545783519744873
Epoch 11 train loss: 1.3404, eval loss 1.7536920309066772
Epoch 12 train loss: 1.3763, eval loss 1.7520778179168701
Epoch 13 train loss: 1.3986, eval loss 1.752812147140503
Epoch 14 train loss: 1.4000, eval loss 1.7498860359191895
Epoch 15 train loss: 1.3531, eval loss 1.7502676248550415
Epoch 16 train loss: 1.4340, eval loss 1.749920129776001
Epoch 17 train loss: 1.4970, eval loss 1.7505730390548706
Epoch 18 train loss: 1.3575, eval loss 1.74783456325531
Epoch 19 train loss: 1.4830, eval loss 1.7483608722686768
Epoch 20 train loss: 1.3039, eval loss 1.7467058897018433
Epoch 21 train loss: 1.4072, eval loss 1.7474030256271362
Epoch 22 train loss: 1.4720, eval loss 1.7461462020874023
Epoch 23 train loss: 1.4379, eval loss 1.7448270320892334
Epoch 24 train loss: 1.4008, eval loss 1.743793249130249
Epoch 25 train loss: 1.3590, eval loss 1.7443376779556274
Epoch 26 train loss: 1.3005, eval loss 1.7442824840545654
Epoch 27 train loss: 1.3634, eval loss 1.7430570125579834
Epoch 28 train loss: 1.2442, eval loss 1.7428765296936035
Epoch 29 train loss: 1.4280, eval loss 1.7415416240692139
Epoch 30 train loss: 1.3837, eval loss 1.7418056726455688
Epoch 31 train loss: 1.4474, eval loss 1.7385265827178955
Epoch 32 train loss: 1.3989, eval loss 1.7394555807113647
Epoch 33 train loss: 1.2642, eval loss 1.7383168935775757
Epoch 34 train loss: 1.3049, eval loss 1.7371768951416016
Epoch 35 train loss: 1.3699, eval loss 1.737854242324829
Epoch 36 train loss: 1.3563, eval loss 1.7381001710891724
Epoch 37 train loss: 1.2987, eval loss 1.7356367111206055
Epoch 38 train loss: 1.3300, eval loss 1.7355055809020996
Epoch 39 train loss: 1.3311, eval loss 1.7339335680007935
Epoch 40 train loss: 1.3201, eval loss 1.7335104942321777
Epoch 41 train loss: 1.2952, eval loss 1.732022762298584
Epoch 42 train loss: 1.3087, eval loss 1.7319821119308472
Epoch 43 train loss: 1.2110, eval loss 1.7304447889328003
Epoch 44 train loss: 1.3069, eval loss 1.7315504550933838
Epoch 45 train loss: 1.3305, eval loss 1.7307186126708984
Epoch 46 train loss: 1.3635, eval loss 1.7305670976638794
Epoch 47 train loss: 1.3415, eval loss 1.730050802230835
Epoch 48 train loss: 1.4243, eval loss 1.7277729511260986
Epoch 49 train loss: 1.3559, eval loss 1.7278177738189697
Epoch 50 train loss: 1.2816, eval loss 1.7266758680343628
Epoch 51 train loss: 1.3194, eval loss 1.727379322052002
Epoch 52 train loss: 1.3032, eval loss 1.7240732908248901
Epoch 53 train loss: 1.2477, eval loss 1.72511625289917
Epoch 54 train loss: 1.3922, eval loss 1.724213719367981
Epoch 55 train loss: 1.3916, eval loss 1.724128246307373
Epoch 56 train loss: 1.2865, eval loss 1.7228811979293823
Epoch 57 train loss: 1.4285, eval loss 1.7206062078475952
Epoch 58 train loss: 1.2544, eval loss 1.7210521697998047
Epoch 59 train loss: 1.2823, eval loss 1.7197610139846802
Epoch 60 train loss: 1.2526, eval loss 1.720039963722229
Epoch 61 train loss: 1.2844, eval loss 1.719326138496399
Epoch 62 train loss: 1.3054, eval loss 1.7178844213485718
Epoch 63 train loss: 1.2517, eval loss 1.7170679569244385
Epoch 64 train loss: 1.2875, eval loss 1.7186298370361328
Epoch 65 train loss: 1.2543, eval loss 1.7184104919433594
Epoch 66 train loss: 1.3352, eval loss 1.716409683227539
Epoch 67 train loss: 1.2876, eval loss 1.7156418561935425
Epoch 68 train loss: 1.2509, eval loss 1.7154865264892578
Epoch 69 train loss: 1.2747, eval loss 1.714583396911621
Epoch 70 train loss: 1.3125, eval loss 1.7127432823181152
Epoch 71 train loss: 1.3916, eval loss 1.7133691310882568
Epoch 72 train loss: 1.3135, eval loss 1.7129219770431519
Epoch 73 train loss: 1.2665, eval loss 1.7120834589004517
Epoch 74 train loss: 1.2683, eval loss 1.7113864421844482
Epoch 75 train loss: 1.2960, eval loss 1.711060881614685
Epoch 76 train loss: 1.2527, eval loss 1.7090235948562622
Epoch 77 train loss: 1.2639, eval loss 1.7092739343643188
Epoch 78 train loss: 1.3089, eval loss 1.7080578804016113
Epoch 79 train loss: 1.2854, eval loss 1.7079075574874878
Epoch 80 train loss: 1.3227, eval loss 1.707171082496643
Epoch 81 train loss: 1.3429, eval loss 1.7074683904647827
Epoch 82 train loss: 1.3047, eval loss 1.7056899070739746
Epoch 83 train loss: 1.2550, eval loss 1.7067654132843018
Epoch 84 train loss: 1.2925, eval loss 1.7048020362854004
Epoch 85 train loss: 1.2673, eval loss 1.704369068145752
Epoch 86 train loss: 1.3661, eval loss 1.7038103342056274
Epoch 87 train loss: 1.2136, eval loss 1.7040363550186157
Epoch 88 train loss: 1.2812, eval loss 1.702325701713562
Epoch 89 train loss: 1.2227, eval loss 1.7008440494537354
Epoch 90 train loss: 1.2067, eval loss 1.7016080617904663
Epoch 91 train loss: 1.2631, eval loss 1.6991788148880005
Epoch 92 train loss: 1.2403, eval loss 1.6997325420379639
Epoch 93 train loss: 1.2203, eval loss 1.6980122327804565
Epoch 94 train loss: 1.2176, eval loss 1.7000105381011963
Epoch 95 train loss: 1.3053, eval loss 1.6989327669143677
Epoch 96 train loss: 1.2480, eval loss 1.6956533193588257
Epoch 97 train loss: 1.2072, eval loss 1.6964199542999268
Epoch 98 train loss: 1.1480, eval loss 1.6953544616699219
Epoch 99 train loss: 1.1836, eval loss 1.6960166692733765
Epoch 100 train loss: 1.3271, eval loss 1.6934962272644043
Epoch 101 train loss: 1.2714, eval loss 1.6963269710540771
Epoch 102 train loss: 1.2290, eval loss 1.695198893547058
Epoch 103 train loss: 1.2258, eval loss 1.693738341331482
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:46:42,914] Trial 12 finished with value: 1.6934962272644043 and parameters: {&#39;hidden_layers_size&#39;: 71, &#39;dropout_p&#39;: 0.4939836605682455, &#39;learning_rate&#39;: 1.033644192116278e-06, &#39;batch_size&#39;: 194, &#39;l2_reg&#39;: 2.9209239251884415e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.5979, eval loss 1.7865238189697266
Epoch 1 train loss: 1.5293, eval loss 1.7772608995437622
Epoch 2 train loss: 1.4897, eval loss 1.7661323547363281
Epoch 3 train loss: 1.4827, eval loss 1.7574682235717773
Epoch 4 train loss: 1.4255, eval loss 1.7513375282287598
Epoch 5 train loss: 1.4739, eval loss 1.743520975112915
Epoch 6 train loss: 1.3635, eval loss 1.7355067729949951
Epoch 7 train loss: 1.3755, eval loss 1.7291876077651978
Epoch 8 train loss: 1.3983, eval loss 1.7203670740127563
Epoch 9 train loss: 1.3532, eval loss 1.7151226997375488
Epoch 10 train loss: 1.2783, eval loss 1.7068841457366943
Epoch 11 train loss: 1.1985, eval loss 1.7004923820495605
Epoch 12 train loss: 1.1922, eval loss 1.6932398080825806
Epoch 13 train loss: 1.2779, eval loss 1.6890958547592163
Epoch 14 train loss: 1.2338, eval loss 1.6832895278930664
Epoch 15 train loss: 1.2380, eval loss 1.6787375211715698
Epoch 16 train loss: 1.1496, eval loss 1.6729170083999634
Epoch 17 train loss: 1.1784, eval loss 1.6660369634628296
Epoch 18 train loss: 1.1861, eval loss 1.6624172925949097
Epoch 19 train loss: 1.1903, eval loss 1.657949686050415
Epoch 20 train loss: 1.1716, eval loss 1.6532809734344482
Epoch 21 train loss: 1.2003, eval loss 1.647663950920105
Epoch 22 train loss: 1.1315, eval loss 1.6444920301437378
Epoch 23 train loss: 1.1169, eval loss 1.641392707824707
Epoch 24 train loss: 1.1295, eval loss 1.6363179683685303
Epoch 25 train loss: 1.0966, eval loss 1.633334755897522
Epoch 26 train loss: 1.1513, eval loss 1.6276742219924927
Epoch 27 train loss: 1.1390, eval loss 1.625372290611267
Epoch 28 train loss: 1.2161, eval loss 1.6239700317382812
Epoch 29 train loss: 1.0697, eval loss 1.6215112209320068
Epoch 30 train loss: 1.0418, eval loss 1.617396354675293
Epoch 31 train loss: 1.0354, eval loss 1.6137460470199585
Epoch 32 train loss: 1.0471, eval loss 1.609309196472168
Epoch 33 train loss: 1.0816, eval loss 1.606711983680725
Epoch 34 train loss: 1.0804, eval loss 1.6040585041046143
Epoch 35 train loss: 1.0420, eval loss 1.6012146472930908
Epoch 36 train loss: 1.1040, eval loss 1.5975583791732788
Epoch 37 train loss: 1.0448, eval loss 1.5956238508224487
Epoch 38 train loss: 1.0171, eval loss 1.5940293073654175
Epoch 39 train loss: 1.1101, eval loss 1.591147780418396
Epoch 40 train loss: 1.0024, eval loss 1.5860683917999268
Epoch 41 train loss: 0.9821, eval loss 1.5860459804534912
Epoch 42 train loss: 0.9773, eval loss 1.582424283027649
Epoch 43 train loss: 1.0530, eval loss 1.580909252166748
Epoch 44 train loss: 0.9995, eval loss 1.5795150995254517
Epoch 45 train loss: 0.9694, eval loss 1.5742011070251465
Epoch 46 train loss: 1.0338, eval loss 1.5737743377685547
Epoch 47 train loss: 1.0271, eval loss 1.5722020864486694
Epoch 48 train loss: 0.9304, eval loss 1.5685055255889893
Epoch 49 train loss: 0.9320, eval loss 1.5662522315979004
Epoch 50 train loss: 1.0306, eval loss 1.5628975629806519
Epoch 51 train loss: 0.9847, eval loss 1.5623382329940796
Epoch 52 train loss: 0.9575, eval loss 1.558984637260437
Epoch 53 train loss: 0.9078, eval loss 1.558192491531372
Epoch 54 train loss: 0.9979, eval loss 1.555570363998413
Epoch 55 train loss: 0.8812, eval loss 1.5551342964172363
Epoch 56 train loss: 1.0197, eval loss 1.5520116090774536
Epoch 57 train loss: 0.9612, eval loss 1.5499016046524048
Epoch 58 train loss: 0.9199, eval loss 1.5482462644577026
Epoch 59 train loss: 0.9243, eval loss 1.5463765859603882
Epoch 60 train loss: 0.9523, eval loss 1.5446351766586304
Epoch 61 train loss: 0.9589, eval loss 1.5436676740646362
Epoch 62 train loss: 0.8840, eval loss 1.5412722826004028
Epoch 63 train loss: 0.9819, eval loss 1.539108157157898
Epoch 64 train loss: 0.9430, eval loss 1.5389245748519897
Epoch 65 train loss: 1.0038, eval loss 1.5375940799713135
Epoch 66 train loss: 0.9421, eval loss 1.5343068838119507
Epoch 67 train loss: 0.9135, eval loss 1.5334248542785645
Epoch 68 train loss: 0.8620, eval loss 1.5299453735351562
Epoch 69 train loss: 0.9479, eval loss 1.5289050340652466
Epoch 70 train loss: 0.9173, eval loss 1.5293138027191162
Epoch 71 train loss: 0.9008, eval loss 1.526592493057251
Epoch 72 train loss: 0.9147, eval loss 1.5254038572311401
Epoch 73 train loss: 0.8544, eval loss 1.5236001014709473
Epoch 74 train loss: 0.9020, eval loss 1.5220133066177368
Epoch 75 train loss: 0.8937, eval loss 1.5202906131744385
Epoch 76 train loss: 0.8318, eval loss 1.519127368927002
Epoch 77 train loss: 0.8777, eval loss 1.519373893737793
Epoch 78 train loss: 0.8601, eval loss 1.515852689743042
Epoch 79 train loss: 0.8919, eval loss 1.5144373178482056
Epoch 80 train loss: 0.8808, eval loss 1.5144680738449097
Epoch 81 train loss: 0.8398, eval loss 1.5131278038024902
Epoch 82 train loss: 0.8601, eval loss 1.5123475790023804
Epoch 83 train loss: 0.8143, eval loss 1.5108237266540527
Epoch 84 train loss: 0.9048, eval loss 1.5092633962631226
Epoch 85 train loss: 0.8932, eval loss 1.5066826343536377
Epoch 86 train loss: 0.8821, eval loss 1.5050040483474731
Epoch 87 train loss: 0.8432, eval loss 1.5048326253890991
Epoch 88 train loss: 0.8851, eval loss 1.5046372413635254
Epoch 89 train loss: 0.8567, eval loss 1.5018326044082642
Epoch 90 train loss: 0.8153, eval loss 1.5008121728897095
Epoch 91 train loss: 0.8539, eval loss 1.5000094175338745
Epoch 92 train loss: 0.7984, eval loss 1.4989523887634277
Epoch 93 train loss: 0.8652, eval loss 1.4985556602478027
Epoch 94 train loss: 0.8772, eval loss 1.4986541271209717
Epoch 95 train loss: 0.8976, eval loss 1.4974499940872192
Epoch 96 train loss: 0.7906, eval loss 1.4949486255645752
Epoch 97 train loss: 0.8525, eval loss 1.4930477142333984
Epoch 98 train loss: 0.8176, eval loss 1.4929308891296387
Epoch 99 train loss: 0.8532, eval loss 1.4918595552444458
Epoch 100 train loss: 0.8524, eval loss 1.4911363124847412
Epoch 101 train loss: 0.8484, eval loss 1.4901211261749268
Epoch 102 train loss: 0.8938, eval loss 1.490060567855835
Epoch 103 train loss: 0.8946, eval loss 1.488224983215332
Epoch 104 train loss: 0.7640, eval loss 1.486849069595337
Epoch 105 train loss: 0.7742, eval loss 1.4867533445358276
Epoch 106 train loss: 0.8322, eval loss 1.4851016998291016
Epoch 107 train loss: 0.7784, eval loss 1.4856820106506348
Epoch 108 train loss: 0.7765, eval loss 1.484365463256836
Epoch 109 train loss: 0.7758, eval loss 1.4838199615478516
Epoch 110 train loss: 0.8535, eval loss 1.4822626113891602
Epoch 111 train loss: 0.8390, eval loss 1.4815537929534912
Epoch 112 train loss: 0.8151, eval loss 1.481494665145874
Epoch 113 train loss: 0.8264, eval loss 1.4802186489105225
Epoch 114 train loss: 0.8083, eval loss 1.4800745248794556
Epoch 115 train loss: 0.8013, eval loss 1.4786161184310913
Epoch 116 train loss: 0.8135, eval loss 1.4775835275650024
Epoch 117 train loss: 0.8061, eval loss 1.4767924547195435
Epoch 118 train loss: 0.8322, eval loss 1.4770387411117554
Epoch 119 train loss: 0.8288, eval loss 1.4754292964935303
Epoch 120 train loss: 0.8560, eval loss 1.4755836725234985
Epoch 121 train loss: 0.8552, eval loss 1.4755884408950806
Epoch 122 train loss: 0.7452, eval loss 1.4743075370788574
Epoch 123 train loss: 0.7554, eval loss 1.4737391471862793
Epoch 124 train loss: 0.8413, eval loss 1.4719481468200684
Epoch 125 train loss: 0.8141, eval loss 1.472381830215454
Epoch 126 train loss: 0.8207, eval loss 1.470941185951233
Epoch 127 train loss: 0.7711, eval loss 1.4714840650558472
Epoch 128 train loss: 0.7860, eval loss 1.4697911739349365
Epoch 129 train loss: 0.8717, eval loss 1.4710230827331543
Epoch 130 train loss: 0.7858, eval loss 1.4693732261657715
Epoch 131 train loss: 0.7640, eval loss 1.4687607288360596
Epoch 132 train loss: 0.7678, eval loss 1.4679826498031616
Epoch 133 train loss: 0.8071, eval loss 1.4680536985397339
Epoch 134 train loss: 0.8178, eval loss 1.4688305854797363
Epoch 135 train loss: 0.8636, eval loss 1.4664438962936401
Epoch 136 train loss: 0.7595, eval loss 1.4667885303497314
Epoch 137 train loss: 0.7187, eval loss 1.4650890827178955
Epoch 138 train loss: 0.8307, eval loss 1.4663695096969604
Epoch 139 train loss: 0.8079, eval loss 1.4643263816833496
Epoch 140 train loss: 0.8590, eval loss 1.4644792079925537
Epoch 141 train loss: 0.7710, eval loss 1.4636268615722656
Epoch 142 train loss: 0.7749, eval loss 1.463363766670227
Epoch 143 train loss: 0.8352, eval loss 1.4630954265594482
Epoch 144 train loss: 0.8989, eval loss 1.4625409841537476
Epoch 145 train loss: 0.7482, eval loss 1.4625217914581299
Epoch 146 train loss: 0.7564, eval loss 1.4621177911758423
Epoch 147 train loss: 0.8020, eval loss 1.4621050357818604
Epoch 148 train loss: 0.8799, eval loss 1.4605149030685425
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:48:15,033] Trial 13 finished with value: 1.4605149030685425 and parameters: {&#39;hidden_layers_size&#39;: 90, &#39;dropout_p&#39;: 0.4494963209683946, &#39;learning_rate&#39;: 9.15472107702422e-06, &#39;batch_size&#39;: 192, &#39;l2_reg&#39;: 3.1114172681127265e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.8082, eval loss 1.4607032537460327
Epoch 0 train loss: 1.4237, eval loss 1.777103066444397
Epoch 1 train loss: 1.4358, eval loss 1.7700467109680176
Epoch 2 train loss: 1.6049, eval loss 1.7624844312667847
Epoch 3 train loss: 1.5080, eval loss 1.7560837268829346
Epoch 4 train loss: 1.4703, eval loss 1.7485874891281128
Epoch 5 train loss: 1.4186, eval loss 1.7424554824829102
Epoch 6 train loss: 1.3537, eval loss 1.7363533973693848
Epoch 7 train loss: 1.1912, eval loss 1.731629729270935
Epoch 8 train loss: 1.3146, eval loss 1.7257176637649536
Epoch 9 train loss: 1.4118, eval loss 1.7181777954101562
Epoch 10 train loss: 1.2648, eval loss 1.714492678642273
Epoch 11 train loss: 1.4052, eval loss 1.7104334831237793
Epoch 12 train loss: 1.2246, eval loss 1.7051151990890503
Epoch 13 train loss: 1.2678, eval loss 1.6993274688720703
Epoch 14 train loss: 1.2306, eval loss 1.6943269968032837
Epoch 15 train loss: 1.1662, eval loss 1.690213918685913
Epoch 16 train loss: 1.2703, eval loss 1.6855360269546509
Epoch 17 train loss: 1.2143, eval loss 1.6807312965393066
Epoch 18 train loss: 1.2966, eval loss 1.676662564277649
Epoch 19 train loss: 1.1441, eval loss 1.6704189777374268
Epoch 20 train loss: 1.2290, eval loss 1.6678937673568726
Epoch 21 train loss: 1.2431, eval loss 1.6638339757919312
Epoch 22 train loss: 1.1357, eval loss 1.6620343923568726
Epoch 23 train loss: 1.1017, eval loss 1.6576647758483887
Epoch 24 train loss: 1.0888, eval loss 1.6535063982009888
Epoch 25 train loss: 1.1190, eval loss 1.6525182723999023
Epoch 26 train loss: 1.0484, eval loss 1.6470320224761963
Epoch 27 train loss: 1.0649, eval loss 1.643450140953064
Epoch 28 train loss: 1.1371, eval loss 1.6417078971862793
Epoch 29 train loss: 1.0988, eval loss 1.6361172199249268
Epoch 30 train loss: 1.0769, eval loss 1.634699821472168
Epoch 31 train loss: 1.1106, eval loss 1.631257176399231
Epoch 32 train loss: 1.0587, eval loss 1.628818392753601
Epoch 33 train loss: 1.0024, eval loss 1.6253771781921387
Epoch 34 train loss: 1.0911, eval loss 1.6245386600494385
Epoch 35 train loss: 1.1371, eval loss 1.6212596893310547
Epoch 36 train loss: 1.1361, eval loss 1.6174402236938477
Epoch 37 train loss: 1.0348, eval loss 1.6170555353164673
Epoch 38 train loss: 1.0073, eval loss 1.615592360496521
Epoch 39 train loss: 1.0951, eval loss 1.6095614433288574
Epoch 40 train loss: 1.0397, eval loss 1.6067982912063599
Epoch 41 train loss: 0.9433, eval loss 1.6056832075119019
Epoch 42 train loss: 1.0469, eval loss 1.6022584438323975
Epoch 43 train loss: 0.9492, eval loss 1.5998170375823975
Epoch 44 train loss: 1.0256, eval loss 1.5978983640670776
Epoch 45 train loss: 0.8691, eval loss 1.59601891040802
Epoch 46 train loss: 1.0154, eval loss 1.595819354057312
Epoch 47 train loss: 0.9590, eval loss 1.5923306941986084
Epoch 48 train loss: 0.8769, eval loss 1.586993932723999
Epoch 49 train loss: 0.9101, eval loss 1.5882596969604492
Epoch 50 train loss: 0.8967, eval loss 1.5857056379318237
Epoch 51 train loss: 0.9798, eval loss 1.5829983949661255
Epoch 52 train loss: 0.8781, eval loss 1.5807148218154907
Epoch 53 train loss: 0.9715, eval loss 1.5788425207138062
Epoch 54 train loss: 0.8283, eval loss 1.5789821147918701
Epoch 55 train loss: 1.0438, eval loss 1.5755155086517334
Epoch 56 train loss: 0.8452, eval loss 1.5748435258865356
Epoch 57 train loss: 0.9326, eval loss 1.5727996826171875
Epoch 58 train loss: 0.9198, eval loss 1.5702824592590332
Epoch 59 train loss: 0.9260, eval loss 1.568302869796753
Epoch 60 train loss: 0.8860, eval loss 1.5667767524719238
Epoch 61 train loss: 0.8801, eval loss 1.5642907619476318
Epoch 62 train loss: 0.8526, eval loss 1.5621488094329834
Epoch 63 train loss: 0.8840, eval loss 1.5639396905899048
Epoch 64 train loss: 0.8742, eval loss 1.5607701539993286
Epoch 65 train loss: 0.9383, eval loss 1.5579394102096558
Epoch 66 train loss: 0.8528, eval loss 1.5580507516860962
Epoch 67 train loss: 0.9320, eval loss 1.5562126636505127
Epoch 68 train loss: 0.9271, eval loss 1.5542418956756592
Epoch 69 train loss: 0.9171, eval loss 1.5514477491378784
Epoch 70 train loss: 0.8424, eval loss 1.5505280494689941
Epoch 71 train loss: 0.8727, eval loss 1.5509737730026245
Epoch 72 train loss: 0.8511, eval loss 1.5477274656295776
Epoch 73 train loss: 0.8192, eval loss 1.546722173690796
Epoch 74 train loss: 0.7661, eval loss 1.5445858240127563
Epoch 75 train loss: 0.8355, eval loss 1.5441217422485352
Epoch 76 train loss: 0.8017, eval loss 1.5418823957443237
Epoch 77 train loss: 0.9625, eval loss 1.5408167839050293
Epoch 78 train loss: 0.8532, eval loss 1.54034423828125
Epoch 79 train loss: 0.8291, eval loss 1.5392173528671265
Epoch 80 train loss: 0.8109, eval loss 1.5389947891235352
Epoch 81 train loss: 0.8542, eval loss 1.5368883609771729
Epoch 82 train loss: 0.8599, eval loss 1.5339899063110352
Epoch 83 train loss: 0.8260, eval loss 1.5326883792877197
Epoch 84 train loss: 0.8132, eval loss 1.5322308540344238
Epoch 85 train loss: 0.7468, eval loss 1.5290535688400269
Epoch 86 train loss: 0.8787, eval loss 1.5305120944976807
Epoch 87 train loss: 0.8571, eval loss 1.5271912813186646
Epoch 88 train loss: 0.8117, eval loss 1.5257799625396729
Epoch 89 train loss: 0.9218, eval loss 1.526273250579834
Epoch 90 train loss: 0.8597, eval loss 1.52469003200531
Epoch 91 train loss: 0.9020, eval loss 1.5230276584625244
Epoch 92 train loss: 0.8364, eval loss 1.5215665102005005
Epoch 93 train loss: 0.7579, eval loss 1.520590901374817
Epoch 94 train loss: 0.7479, eval loss 1.5199294090270996
Epoch 95 train loss: 0.8117, eval loss 1.5196789503097534
Epoch 96 train loss: 0.7521, eval loss 1.5172911882400513
Epoch 97 train loss: 0.8742, eval loss 1.5154327154159546
Epoch 98 train loss: 0.8338, eval loss 1.5153981447219849
Epoch 99 train loss: 0.8909, eval loss 1.5144089460372925
Epoch 100 train loss: 0.7712, eval loss 1.5142958164215088
Epoch 101 train loss: 0.7706, eval loss 1.5129897594451904
Epoch 102 train loss: 0.8447, eval loss 1.5120501518249512
Epoch 103 train loss: 0.7352, eval loss 1.5095841884613037
Epoch 104 train loss: 0.8015, eval loss 1.5078082084655762
Epoch 105 train loss: 0.7570, eval loss 1.5074808597564697
Epoch 106 train loss: 0.7969, eval loss 1.5084158182144165
Epoch 107 train loss: 0.7889, eval loss 1.5058895349502563
Epoch 108 train loss: 0.8279, eval loss 1.5046393871307373
Epoch 109 train loss: 0.7328, eval loss 1.505436658859253
Epoch 110 train loss: 0.7209, eval loss 1.5023902654647827
Epoch 111 train loss: 0.8179, eval loss 1.5018671751022339
Epoch 112 train loss: 0.7367, eval loss 1.5024179220199585
Epoch 113 train loss: 0.7753, eval loss 1.501105785369873
Epoch 114 train loss: 0.7332, eval loss 1.49958074092865
Epoch 115 train loss: 0.6730, eval loss 1.4989603757858276
Epoch 116 train loss: 0.7094, eval loss 1.4976718425750732
Epoch 117 train loss: 0.7604, eval loss 1.4971468448638916
Epoch 118 train loss: 0.7558, eval loss 1.4968373775482178
Epoch 119 train loss: 0.7059, eval loss 1.4956218004226685
Epoch 120 train loss: 0.7348, eval loss 1.4944133758544922
Epoch 121 train loss: 0.6820, eval loss 1.4935933351516724
Epoch 122 train loss: 0.7981, eval loss 1.4939537048339844
Epoch 123 train loss: 0.7563, eval loss 1.492270827293396
Epoch 124 train loss: 0.7645, eval loss 1.4909560680389404
Epoch 125 train loss: 0.8412, eval loss 1.4907852411270142
Epoch 126 train loss: 0.6329, eval loss 1.4911961555480957
Epoch 127 train loss: 0.7571, eval loss 1.489540934562683
Epoch 128 train loss: 0.7254, eval loss 1.4889811277389526
Epoch 129 train loss: 0.7554, eval loss 1.4881751537322998
Epoch 130 train loss: 0.7565, eval loss 1.486466646194458
Epoch 131 train loss: 0.7490, eval loss 1.4864531755447388
Epoch 132 train loss: 0.8002, eval loss 1.4844658374786377
Epoch 133 train loss: 0.7538, eval loss 1.4848514795303345
Epoch 134 train loss: 0.7342, eval loss 1.4839030504226685
Epoch 135 train loss: 0.7199, eval loss 1.4832110404968262
Epoch 136 train loss: 0.7972, eval loss 1.4834766387939453
Epoch 137 train loss: 0.7146, eval loss 1.4821995496749878
Epoch 138 train loss: 0.7421, eval loss 1.4817825555801392
Epoch 139 train loss: 0.7088, eval loss 1.481015920639038
Epoch 140 train loss: 0.7766, eval loss 1.4792245626449585
Epoch 141 train loss: 0.7330, eval loss 1.4784979820251465
Epoch 142 train loss: 0.7743, eval loss 1.47877037525177
Epoch 143 train loss: 0.8235, eval loss 1.4785504341125488
Epoch 144 train loss: 0.6999, eval loss 1.477510929107666
Epoch 145 train loss: 0.6374, eval loss 1.476528525352478
Epoch 146 train loss: 0.6677, eval loss 1.4745573997497559
Epoch 147 train loss: 0.6702, eval loss 1.475503921508789
Epoch 148 train loss: 0.7420, eval loss 1.4757143259048462
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:49:56,093] Trial 14 finished with value: 1.4745573997497559 and parameters: {&#39;hidden_layers_size&#39;: 73, &#39;dropout_p&#39;: 0.4487116717919587, &#39;learning_rate&#39;: 7.333617542604693e-06, &#39;batch_size&#39;: 165, &#39;l2_reg&#39;: 8.575543293736724e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7016, eval loss 1.4751015901565552
Epoch 0 train loss: 1.4657, eval loss 1.7590045928955078
Epoch 1 train loss: 1.3376, eval loss 1.7187418937683105
Epoch 2 train loss: 1.2415, eval loss 1.6887831687927246
Epoch 3 train loss: 1.1990, eval loss 1.664432168006897
Epoch 4 train loss: 1.1063, eval loss 1.6439323425292969
Epoch 5 train loss: 1.0439, eval loss 1.6281195878982544
Epoch 6 train loss: 0.9804, eval loss 1.6134161949157715
Epoch 7 train loss: 0.9675, eval loss 1.6012543439865112
Epoch 8 train loss: 0.9640, eval loss 1.5894718170166016
Epoch 9 train loss: 0.8970, eval loss 1.579715609550476
Epoch 10 train loss: 0.9028, eval loss 1.5691709518432617
Epoch 11 train loss: 0.8642, eval loss 1.5611250400543213
Epoch 12 train loss: 0.8643, eval loss 1.5530167818069458
Epoch 13 train loss: 0.8394, eval loss 1.5453025102615356
Epoch 14 train loss: 0.8127, eval loss 1.539689540863037
Epoch 15 train loss: 0.7857, eval loss 1.5333051681518555
Epoch 16 train loss: 0.8321, eval loss 1.5262490510940552
Epoch 17 train loss: 0.7779, eval loss 1.5219483375549316
Epoch 18 train loss: 0.7926, eval loss 1.5161103010177612
Epoch 19 train loss: 0.7488, eval loss 1.5113104581832886
Epoch 20 train loss: 0.7535, eval loss 1.5068707466125488
Epoch 21 train loss: 0.7732, eval loss 1.5028525590896606
Epoch 22 train loss: 0.7296, eval loss 1.4978269338607788
Epoch 23 train loss: 0.7528, eval loss 1.4940543174743652
Epoch 24 train loss: 0.7337, eval loss 1.4908126592636108
Epoch 25 train loss: 0.7198, eval loss 1.48737633228302
Epoch 26 train loss: 0.7591, eval loss 1.4846562147140503
Epoch 27 train loss: 0.7391, eval loss 1.4818003177642822
Epoch 28 train loss: 0.6807, eval loss 1.4784659147262573
Epoch 29 train loss: 0.7181, eval loss 1.47628915309906
Epoch 30 train loss: 0.7005, eval loss 1.473912000656128
Epoch 31 train loss: 0.7037, eval loss 1.4708892107009888
Epoch 32 train loss: 0.6993, eval loss 1.4684138298034668
Epoch 33 train loss: 0.6888, eval loss 1.4665838479995728
Epoch 34 train loss: 0.6843, eval loss 1.4643763303756714
Epoch 35 train loss: 0.6960, eval loss 1.4628807306289673
Epoch 36 train loss: 0.7107, eval loss 1.4608763456344604
Epoch 37 train loss: 0.6918, eval loss 1.4584236145019531
Epoch 38 train loss: 0.6574, eval loss 1.4577275514602661
Epoch 39 train loss: 0.7022, eval loss 1.456038475036621
Epoch 40 train loss: 0.6662, eval loss 1.4549607038497925
Epoch 41 train loss: 0.6600, eval loss 1.4531769752502441
Epoch 42 train loss: 0.6857, eval loss 1.4518554210662842
Epoch 43 train loss: 0.6755, eval loss 1.451002597808838
Epoch 44 train loss: 0.6696, eval loss 1.4497473239898682
Epoch 45 train loss: 0.6774, eval loss 1.448779582977295
Epoch 46 train loss: 0.6561, eval loss 1.447975754737854
Epoch 47 train loss: 0.6541, eval loss 1.4472441673278809
Epoch 48 train loss: 0.6824, eval loss 1.4460806846618652
Epoch 49 train loss: 0.6894, eval loss 1.444967269897461
Epoch 50 train loss: 0.6545, eval loss 1.4441289901733398
Epoch 51 train loss: 0.6510, eval loss 1.4437514543533325
Epoch 52 train loss: 0.6556, eval loss 1.442929983139038
Epoch 53 train loss: 0.6402, eval loss 1.4419227838516235
Epoch 54 train loss: 0.6750, eval loss 1.4413915872573853
Epoch 55 train loss: 0.6481, eval loss 1.4406453371047974
Epoch 56 train loss: 0.6617, eval loss 1.4406330585479736
Epoch 57 train loss: 0.6476, eval loss 1.4395787715911865
Epoch 58 train loss: 0.6547, eval loss 1.4391076564788818
Epoch 59 train loss: 0.6724, eval loss 1.4384373426437378
Epoch 60 train loss: 0.6662, eval loss 1.438289999961853
Epoch 61 train loss: 0.6461, eval loss 1.4374125003814697
Epoch 62 train loss: 0.6858, eval loss 1.4373095035552979
Epoch 63 train loss: 0.6708, eval loss 1.437207579612732
Epoch 64 train loss: 0.6992, eval loss 1.4360315799713135
Epoch 65 train loss: 0.6548, eval loss 1.4362729787826538
Epoch 66 train loss: 0.6755, eval loss 1.4359784126281738
Epoch 67 train loss: 0.6674, eval loss 1.4356365203857422
Epoch 68 train loss: 0.6511, eval loss 1.4349457025527954
Epoch 69 train loss: 0.6658, eval loss 1.434849739074707
Epoch 70 train loss: 0.6559, eval loss 1.4348212480545044
Epoch 71 train loss: 0.6428, eval loss 1.434562087059021
Epoch 72 train loss: 0.6297, eval loss 1.434370756149292
Epoch 73 train loss: 0.6471, eval loss 1.433780550956726
Epoch 74 train loss: 0.6445, eval loss 1.433701992034912
Epoch 75 train loss: 0.6758, eval loss 1.4336519241333008
Epoch 76 train loss: 0.6687, eval loss 1.4336626529693604
Epoch 77 train loss: 0.6537, eval loss 1.4332151412963867
Epoch 78 train loss: 0.6760, eval loss 1.432658076286316
Epoch 79 train loss: 0.6857, eval loss 1.4330580234527588
Epoch 80 train loss: 0.6582, eval loss 1.4326716661453247
Epoch 81 train loss: 0.6364, eval loss 1.43268620967865
Epoch 82 train loss: 0.6107, eval loss 1.4319311380386353
Epoch 83 train loss: 0.6365, eval loss 1.4323461055755615
Epoch 84 train loss: 0.6708, eval loss 1.431673288345337
Epoch 85 train loss: 0.6232, eval loss 1.4321491718292236
Epoch 86 train loss: 0.6658, eval loss 1.432038426399231
Epoch 87 train loss: 0.6998, eval loss 1.4320348501205444
Epoch 88 train loss: 0.6701, eval loss 1.4313690662384033
Epoch 89 train loss: 0.6295, eval loss 1.4315259456634521
Epoch 90 train loss: 0.6464, eval loss 1.4313517808914185
Epoch 91 train loss: 0.6169, eval loss 1.431636929512024
Epoch 92 train loss: 0.6622, eval loss 1.4316213130950928
Epoch 93 train loss: 0.6568, eval loss 1.4318000078201294
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:50:53,195] Trial 15 finished with value: 1.4313517808914185 and parameters: {&#39;hidden_layers_size&#39;: 115, &#39;dropout_p&#39;: 0.2531603926074821, &#39;learning_rate&#39;: 3.7253343416482775e-05, &#39;batch_size&#39;: 215, &#39;l2_reg&#39;: 1.9092539539330737e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.7144, eval loss 1.786270022392273
Epoch 1 train loss: 1.5476, eval loss 1.7817648649215698
Epoch 2 train loss: 1.5744, eval loss 1.779555320739746
Epoch 3 train loss: 1.7134, eval loss 1.7772307395935059
Epoch 4 train loss: 1.5446, eval loss 1.7724343538284302
Epoch 5 train loss: 1.6539, eval loss 1.7685959339141846
Epoch 6 train loss: 1.5811, eval loss 1.76680326461792
Epoch 7 train loss: 1.6468, eval loss 1.765135645866394
Epoch 8 train loss: 1.6630, eval loss 1.7624340057373047
Epoch 9 train loss: 1.4899, eval loss 1.758819580078125
Epoch 10 train loss: 1.6336, eval loss 1.7547831535339355
Epoch 11 train loss: 1.3787, eval loss 1.751784086227417
Epoch 12 train loss: 1.4748, eval loss 1.7488884925842285
Epoch 13 train loss: 1.4539, eval loss 1.7456883192062378
Epoch 14 train loss: 1.3625, eval loss 1.7426722049713135
Epoch 15 train loss: 1.3371, eval loss 1.7398943901062012
Epoch 16 train loss: 1.4768, eval loss 1.7363457679748535
Epoch 17 train loss: 1.5363, eval loss 1.7335671186447144
Epoch 18 train loss: 1.4452, eval loss 1.7300385236740112
Epoch 19 train loss: 1.4041, eval loss 1.7296428680419922
Epoch 20 train loss: 1.3623, eval loss 1.7273147106170654
Epoch 21 train loss: 1.4467, eval loss 1.7227503061294556
Epoch 22 train loss: 1.4593, eval loss 1.721766710281372
Epoch 23 train loss: 1.4615, eval loss 1.7173182964324951
Epoch 24 train loss: 1.3936, eval loss 1.7155163288116455
Epoch 25 train loss: 1.3837, eval loss 1.7131669521331787
Epoch 26 train loss: 1.3880, eval loss 1.7109053134918213
Epoch 27 train loss: 1.4119, eval loss 1.7067722082138062
Epoch 28 train loss: 1.2346, eval loss 1.7052228450775146
Epoch 29 train loss: 1.4505, eval loss 1.7043046951293945
Epoch 30 train loss: 1.2615, eval loss 1.7019866704940796
Epoch 31 train loss: 1.3776, eval loss 1.6999523639678955
Epoch 32 train loss: 1.3277, eval loss 1.695858359336853
Epoch 33 train loss: 1.2500, eval loss 1.6939764022827148
Epoch 34 train loss: 1.2192, eval loss 1.6927931308746338
Epoch 35 train loss: 1.3061, eval loss 1.6909799575805664
Epoch 36 train loss: 1.2100, eval loss 1.687072992324829
Epoch 37 train loss: 1.2785, eval loss 1.6845502853393555
Epoch 38 train loss: 1.1605, eval loss 1.6842608451843262
Epoch 39 train loss: 1.1775, eval loss 1.681497573852539
Epoch 40 train loss: 1.3910, eval loss 1.6799834966659546
Epoch 41 train loss: 1.2728, eval loss 1.6785995960235596
Epoch 42 train loss: 1.1858, eval loss 1.6767313480377197
Epoch 43 train loss: 1.3170, eval loss 1.6739295721054077
Epoch 44 train loss: 1.3617, eval loss 1.6714433431625366
Epoch 45 train loss: 1.1393, eval loss 1.6682788133621216
Epoch 46 train loss: 1.1453, eval loss 1.66729736328125
Epoch 47 train loss: 1.1967, eval loss 1.6657755374908447
Epoch 48 train loss: 1.2347, eval loss 1.6642740964889526
Epoch 49 train loss: 1.3344, eval loss 1.6619142293930054
Epoch 50 train loss: 1.1267, eval loss 1.6595251560211182
Epoch 51 train loss: 1.2753, eval loss 1.6574070453643799
Epoch 52 train loss: 1.1213, eval loss 1.6552633047103882
Epoch 53 train loss: 1.1984, eval loss 1.6554166078567505
Epoch 54 train loss: 1.0883, eval loss 1.6517139673233032
Epoch 55 train loss: 1.0992, eval loss 1.6509495973587036
Epoch 56 train loss: 1.2390, eval loss 1.6490658521652222
Epoch 57 train loss: 1.1147, eval loss 1.6471714973449707
Epoch 58 train loss: 1.0838, eval loss 1.6449822187423706
Epoch 59 train loss: 1.2361, eval loss 1.6446759700775146
Epoch 60 train loss: 1.0987, eval loss 1.641809105873108
Epoch 61 train loss: 1.1230, eval loss 1.6427048444747925
Epoch 62 train loss: 1.1832, eval loss 1.6382644176483154
Epoch 63 train loss: 1.0311, eval loss 1.6383056640625
Epoch 64 train loss: 1.0089, eval loss 1.637952446937561
Epoch 65 train loss: 1.0059, eval loss 1.6353580951690674
Epoch 66 train loss: 1.0992, eval loss 1.6334539651870728
Epoch 67 train loss: 1.0544, eval loss 1.6326932907104492
Epoch 68 train loss: 1.1079, eval loss 1.6301333904266357
Epoch 69 train loss: 1.1294, eval loss 1.6287697553634644
Epoch 70 train loss: 1.1314, eval loss 1.62690007686615
Epoch 71 train loss: 1.1519, eval loss 1.6270779371261597
Epoch 72 train loss: 1.0541, eval loss 1.6241897344589233
Epoch 73 train loss: 1.1090, eval loss 1.6229814291000366
Epoch 74 train loss: 1.0021, eval loss 1.6213057041168213
Epoch 75 train loss: 1.0277, eval loss 1.619919776916504
Epoch 76 train loss: 1.0521, eval loss 1.6183346509933472
Epoch 77 train loss: 1.1538, eval loss 1.6173774003982544
Epoch 78 train loss: 1.0717, eval loss 1.617794394493103
Epoch 79 train loss: 0.9910, eval loss 1.6138468980789185
Epoch 80 train loss: 1.0140, eval loss 1.613153100013733
Epoch 81 train loss: 1.1358, eval loss 1.6133251190185547
Epoch 82 train loss: 1.0609, eval loss 1.6123285293579102
Epoch 83 train loss: 1.0500, eval loss 1.6100682020187378
Epoch 84 train loss: 0.9884, eval loss 1.6089463233947754
Epoch 85 train loss: 1.0250, eval loss 1.605735421180725
Epoch 86 train loss: 1.0996, eval loss 1.6068061590194702
Epoch 87 train loss: 0.9917, eval loss 1.6028063297271729
Epoch 88 train loss: 1.0380, eval loss 1.6029894351959229
Epoch 89 train loss: 0.9832, eval loss 1.6021146774291992
Epoch 90 train loss: 0.9579, eval loss 1.6017656326293945
Epoch 91 train loss: 1.0398, eval loss 1.5986050367355347
Epoch 92 train loss: 1.0246, eval loss 1.6002066135406494
Epoch 93 train loss: 0.9826, eval loss 1.5997722148895264
Epoch 94 train loss: 1.0681, eval loss 1.594683051109314
Epoch 95 train loss: 1.0464, eval loss 1.5954066514968872
Epoch 96 train loss: 1.1054, eval loss 1.5939422845840454
Epoch 97 train loss: 0.9868, eval loss 1.5955810546875
Epoch 98 train loss: 1.0274, eval loss 1.5906047821044922
Epoch 99 train loss: 1.1574, eval loss 1.5905789136886597
Epoch 100 train loss: 1.0543, eval loss 1.5897632837295532
Epoch 101 train loss: 0.9698, eval loss 1.5879446268081665
Epoch 102 train loss: 1.0321, eval loss 1.5884398221969604
Epoch 103 train loss: 1.0064, eval loss 1.587699294090271
Epoch 104 train loss: 0.9977, eval loss 1.5862679481506348
Epoch 105 train loss: 0.9079, eval loss 1.5855822563171387
Epoch 106 train loss: 0.9447, eval loss 1.5844671726226807
Epoch 107 train loss: 1.0219, eval loss 1.5830742120742798
Epoch 108 train loss: 0.9798, eval loss 1.5800790786743164
Epoch 109 train loss: 0.9020, eval loss 1.581099510192871
Epoch 110 train loss: 0.9670, eval loss 1.5795161724090576
Epoch 111 train loss: 1.0399, eval loss 1.5782287120819092
Epoch 112 train loss: 1.0221, eval loss 1.5781570672988892
Epoch 113 train loss: 0.9144, eval loss 1.5777504444122314
Epoch 114 train loss: 1.0074, eval loss 1.5740277767181396
Epoch 115 train loss: 0.9543, eval loss 1.5744706392288208
Epoch 116 train loss: 0.9390, eval loss 1.5732663869857788
Epoch 117 train loss: 0.8964, eval loss 1.572096824645996
Epoch 118 train loss: 0.8319, eval loss 1.572440266609192
Epoch 119 train loss: 0.9579, eval loss 1.5704855918884277
Epoch 120 train loss: 0.9707, eval loss 1.570806622505188
Epoch 121 train loss: 0.8806, eval loss 1.5713095664978027
Epoch 122 train loss: 0.9726, eval loss 1.5686522722244263
Epoch 123 train loss: 0.8538, eval loss 1.5680378675460815
Epoch 124 train loss: 0.8430, eval loss 1.5655293464660645
Epoch 125 train loss: 0.8731, eval loss 1.5664530992507935
Epoch 126 train loss: 0.8306, eval loss 1.5649393796920776
Epoch 127 train loss: 1.0637, eval loss 1.5654553174972534
Epoch 128 train loss: 0.9563, eval loss 1.5635265111923218
Epoch 129 train loss: 0.8984, eval loss 1.560272455215454
Epoch 130 train loss: 0.9540, eval loss 1.5614057779312134
Epoch 131 train loss: 0.8880, eval loss 1.5621708631515503
Epoch 132 train loss: 0.9190, eval loss 1.5578256845474243
Epoch 133 train loss: 0.9667, eval loss 1.559767484664917
Epoch 134 train loss: 0.9926, eval loss 1.5564111471176147
Epoch 135 train loss: 0.8785, eval loss 1.5574429035186768
Epoch 136 train loss: 0.9121, eval loss 1.5558098554611206
Epoch 137 train loss: 0.7992, eval loss 1.5565203428268433
Epoch 138 train loss: 0.8255, eval loss 1.5556904077529907
Epoch 139 train loss: 0.9682, eval loss 1.5538398027420044
Epoch 140 train loss: 0.9093, eval loss 1.553713321685791
Epoch 141 train loss: 0.9322, eval loss 1.5514686107635498
Epoch 142 train loss: 0.8723, eval loss 1.551190972328186
Epoch 143 train loss: 0.8718, eval loss 1.5511822700500488
Epoch 144 train loss: 0.7794, eval loss 1.5487169027328491
Epoch 145 train loss: 0.8647, eval loss 1.548546552658081
Epoch 146 train loss: 0.7913, eval loss 1.5495350360870361
Epoch 147 train loss: 0.8911, eval loss 1.5473084449768066
Epoch 148 train loss: 0.9664, eval loss 1.5474313497543335
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:52:31,844] Trial 16 finished with value: 1.5469430685043335 and parameters: {&#39;hidden_layers_size&#39;: 88, &#39;dropout_p&#39;: 0.4522788736177, &#39;learning_rate&#39;: 3.1629953132741747e-06, &#39;batch_size&#39;: 160, &#39;l2_reg&#39;: 4.099293694265519e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.8466, eval loss 1.5469430685043335
Epoch 0 train loss: 1.4749, eval loss 1.7728410959243774
Epoch 1 train loss: 1.4255, eval loss 1.7479106187820435
Epoch 2 train loss: 1.3062, eval loss 1.7252166271209717
Epoch 3 train loss: 1.2784, eval loss 1.7031853199005127
Epoch 4 train loss: 1.1953, eval loss 1.6845165491104126
Epoch 5 train loss: 1.2204, eval loss 1.6656266450881958
Epoch 6 train loss: 1.1710, eval loss 1.6514856815338135
Epoch 7 train loss: 1.2647, eval loss 1.6378757953643799
Epoch 8 train loss: 1.0162, eval loss 1.6219855546951294
Epoch 9 train loss: 1.0394, eval loss 1.6117557287216187
Epoch 10 train loss: 1.0019, eval loss 1.6023176908493042
Epoch 11 train loss: 1.0163, eval loss 1.5910587310791016
Epoch 12 train loss: 0.9322, eval loss 1.580617070198059
Epoch 13 train loss: 0.9432, eval loss 1.5730935335159302
Epoch 14 train loss: 0.8868, eval loss 1.5639398097991943
Epoch 15 train loss: 0.9143, eval loss 1.556567668914795
Epoch 16 train loss: 0.9373, eval loss 1.5491204261779785
Epoch 17 train loss: 0.8590, eval loss 1.5404380559921265
Epoch 18 train loss: 0.8513, eval loss 1.5375325679779053
Epoch 19 train loss: 0.9069, eval loss 1.5306057929992676
Epoch 20 train loss: 0.8927, eval loss 1.5245208740234375
Epoch 21 train loss: 0.8787, eval loss 1.520855188369751
Epoch 22 train loss: 0.8331, eval loss 1.5145517587661743
Epoch 23 train loss: 0.8640, eval loss 1.5098727941513062
Epoch 24 train loss: 0.7818, eval loss 1.5064514875411987
Epoch 25 train loss: 0.8566, eval loss 1.501720905303955
Epoch 26 train loss: 0.8197, eval loss 1.4986730813980103
Epoch 27 train loss: 0.7895, eval loss 1.4957555532455444
Epoch 28 train loss: 0.7983, eval loss 1.4921400547027588
Epoch 29 train loss: 0.8724, eval loss 1.4876360893249512
Epoch 30 train loss: 0.7995, eval loss 1.486581563949585
Epoch 31 train loss: 0.7422, eval loss 1.4841006994247437
Epoch 32 train loss: 0.7285, eval loss 1.4790983200073242
Epoch 33 train loss: 0.8182, eval loss 1.477839469909668
Epoch 34 train loss: 0.7875, eval loss 1.4768444299697876
Epoch 35 train loss: 0.7380, eval loss 1.4737321138381958
Epoch 36 train loss: 0.7532, eval loss 1.4721566438674927
Epoch 37 train loss: 0.8346, eval loss 1.4699608087539673
Epoch 38 train loss: 0.7676, eval loss 1.4694973230361938
Epoch 39 train loss: 0.7320, eval loss 1.4672658443450928
Epoch 40 train loss: 0.7320, eval loss 1.4654755592346191
Epoch 41 train loss: 0.7696, eval loss 1.4647523164749146
Epoch 42 train loss: 0.7461, eval loss 1.4620611667633057
Epoch 43 train loss: 0.7400, eval loss 1.4625921249389648
Epoch 44 train loss: 0.7496, eval loss 1.4596774578094482
Epoch 45 train loss: 0.7169, eval loss 1.4590237140655518
Epoch 46 train loss: 0.7751, eval loss 1.4589076042175293
Epoch 47 train loss: 0.7050, eval loss 1.4573549032211304
Epoch 48 train loss: 0.8329, eval loss 1.4555118083953857
Epoch 49 train loss: 0.7635, eval loss 1.4556560516357422
Epoch 50 train loss: 0.7738, eval loss 1.4558743238449097
Epoch 51 train loss: 0.8771, eval loss 1.453601360321045
Epoch 52 train loss: 0.7596, eval loss 1.4531811475753784
Epoch 53 train loss: 0.7718, eval loss 1.452892541885376
Epoch 54 train loss: 0.7271, eval loss 1.4519882202148438
Epoch 55 train loss: 0.7875, eval loss 1.4518572092056274
Epoch 56 train loss: 0.7196, eval loss 1.4505271911621094
Epoch 57 train loss: 0.7429, eval loss 1.4488998651504517
Epoch 58 train loss: 0.6997, eval loss 1.4499846696853638
Epoch 59 train loss: 0.7854, eval loss 1.4501363039016724
Epoch 60 train loss: 0.7518, eval loss 1.4492136240005493
Epoch 61 train loss: 0.8221, eval loss 1.448241949081421
Epoch 62 train loss: 0.7465, eval loss 1.4490693807601929
Epoch 63 train loss: 0.7906, eval loss 1.4468629360198975
Epoch 64 train loss: 0.7626, eval loss 1.4471296072006226
Epoch 65 train loss: 0.6346, eval loss 1.446917176246643
Epoch 66 train loss: 0.7307, eval loss 1.4462769031524658
Epoch 67 train loss: 0.7938, eval loss 1.4465339183807373
Epoch 68 train loss: 0.6354, eval loss 1.4451038837432861
Epoch 69 train loss: 0.6404, eval loss 1.4461278915405273
Epoch 70 train loss: 0.6820, eval loss 1.444210410118103
Epoch 71 train loss: 0.8392, eval loss 1.4441728591918945
Epoch 72 train loss: 0.7961, eval loss 1.4453747272491455
Epoch 73 train loss: 0.8433, eval loss 1.4448573589324951
Epoch 74 train loss: 0.6416, eval loss 1.4434272050857544
Epoch 75 train loss: 0.6416, eval loss 1.4445698261260986
Epoch 76 train loss: 0.7062, eval loss 1.4440969228744507
Epoch 77 train loss: 0.7861, eval loss 1.444455862045288
Epoch 78 train loss: 0.7338, eval loss 1.4425759315490723
Epoch 79 train loss: 0.7221, eval loss 1.4436115026474
Epoch 80 train loss: 0.7495, eval loss 1.4430592060089111
Epoch 81 train loss: 0.7134, eval loss 1.4421428442001343
Epoch 82 train loss: 0.7650, eval loss 1.441368579864502
Epoch 83 train loss: 0.7704, eval loss 1.442738652229309
Epoch 84 train loss: 0.6788, eval loss 1.4416545629501343
Epoch 85 train loss: 0.6894, eval loss 1.4423720836639404
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 19:53:22,277] Trial 17 finished with value: 1.441368579864502 and parameters: {&#39;hidden_layers_size&#39;: 98, &#39;dropout_p&#39;: 0.49977313487729114, &#39;learning_rate&#39;: 4.4882934157749176e-05, &#39;batch_size&#39;: 233, &#39;l2_reg&#39;: 1.797092635932884e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.5185, eval loss 1.7818670272827148
Epoch 1 train loss: 1.5892, eval loss 1.7793103456497192
Epoch 2 train loss: 1.4807, eval loss 1.7737443447113037
Epoch 3 train loss: 1.4993, eval loss 1.772374153137207
Epoch 4 train loss: 1.4975, eval loss 1.7692302465438843
Epoch 5 train loss: 1.4759, eval loss 1.7674707174301147
Epoch 6 train loss: 1.4724, eval loss 1.7641863822937012
Epoch 7 train loss: 1.5820, eval loss 1.7622827291488647
Epoch 8 train loss: 1.5265, eval loss 1.7618460655212402
Epoch 9 train loss: 1.4430, eval loss 1.7570180892944336
Epoch 10 train loss: 1.4452, eval loss 1.7538065910339355
Epoch 11 train loss: 1.4392, eval loss 1.7512365579605103
Epoch 12 train loss: 1.4346, eval loss 1.7500845193862915
Epoch 13 train loss: 1.4426, eval loss 1.7465213537216187
Epoch 14 train loss: 1.3959, eval loss 1.7452397346496582
Epoch 15 train loss: 1.4705, eval loss 1.7425554990768433
Epoch 16 train loss: 1.4072, eval loss 1.7409945726394653
Epoch 17 train loss: 1.4258, eval loss 1.7376458644866943
Epoch 18 train loss: 1.3388, eval loss 1.7352948188781738
Epoch 19 train loss: 1.3893, eval loss 1.7315616607666016
Epoch 20 train loss: 1.3316, eval loss 1.7306190729141235
Epoch 21 train loss: 1.3338, eval loss 1.728284478187561
Epoch 22 train loss: 1.3527, eval loss 1.7287259101867676
Epoch 23 train loss: 1.4534, eval loss 1.7230912446975708
Epoch 24 train loss: 1.3034, eval loss 1.722852110862732
Epoch 25 train loss: 1.2888, eval loss 1.7217166423797607
Epoch 26 train loss: 1.3589, eval loss 1.7180649042129517
Epoch 27 train loss: 1.3626, eval loss 1.7147893905639648
Epoch 28 train loss: 1.2765, eval loss 1.7103898525238037
Epoch 29 train loss: 1.2814, eval loss 1.7119883298873901
Epoch 30 train loss: 1.3729, eval loss 1.7084970474243164
Epoch 31 train loss: 1.2891, eval loss 1.7074936628341675
Epoch 32 train loss: 1.1940, eval loss 1.7043849229812622
Epoch 33 train loss: 1.2426, eval loss 1.704535722732544
Epoch 34 train loss: 1.3421, eval loss 1.7010440826416016
Epoch 35 train loss: 1.2694, eval loss 1.6999504566192627
Epoch 36 train loss: 1.2383, eval loss 1.698708176612854
Epoch 37 train loss: 1.3226, eval loss 1.69706130027771
Epoch 38 train loss: 1.2570, eval loss 1.6946219205856323
Epoch 39 train loss: 1.2921, eval loss 1.6910804510116577
Epoch 40 train loss: 1.3195, eval loss 1.6899151802062988
Epoch 41 train loss: 1.2677, eval loss 1.6878454685211182
Epoch 42 train loss: 1.1787, eval loss 1.6852531433105469
Epoch 43 train loss: 1.2984, eval loss 1.6846050024032593
Epoch 44 train loss: 1.2370, eval loss 1.6817556619644165
Epoch 45 train loss: 1.2570, eval loss 1.6826633214950562
Epoch 46 train loss: 1.2458, eval loss 1.677140235900879
Epoch 47 train loss: 1.2007, eval loss 1.6776288747787476
Epoch 48 train loss: 1.2422, eval loss 1.6749002933502197
Epoch 49 train loss: 1.2445, eval loss 1.6729750633239746
Epoch 50 train loss: 1.2175, eval loss 1.6715186834335327
Epoch 51 train loss: 1.2233, eval loss 1.6683844327926636
Epoch 52 train loss: 1.2026, eval loss 1.6696664094924927
Epoch 53 train loss: 1.1972, eval loss 1.6662392616271973
Epoch 54 train loss: 1.2032, eval loss 1.6652017831802368
Epoch 55 train loss: 1.1885, eval loss 1.6639914512634277
Epoch 56 train loss: 1.2142, eval loss 1.6637681722640991
Epoch 57 train loss: 1.2396, eval loss 1.6600629091262817
Epoch 58 train loss: 1.2205, eval loss 1.6578091382980347
Epoch 59 train loss: 1.2177, eval loss 1.6569504737854004
Epoch 60 train loss: 1.1601, eval loss 1.6554300785064697
Epoch 61 train loss: 1.1535, eval loss 1.6534178256988525
Epoch 62 train loss: 1.1356, eval loss 1.6536049842834473
Epoch 63 train loss: 1.0775, eval loss 1.6502549648284912
Epoch 64 train loss: 1.1390, eval loss 1.6495404243469238
Epoch 65 train loss: 1.1512, eval loss 1.6484639644622803
Epoch 66 train loss: 1.1685, eval loss 1.6458830833435059
Epoch 67 train loss: 1.1702, eval loss 1.646912693977356
Epoch 68 train loss: 1.1312, eval loss 1.643426537513733
Epoch 69 train loss: 1.1558, eval loss 1.6428133249282837
Epoch 70 train loss: 1.1503, eval loss 1.6425211429595947
Epoch 71 train loss: 1.1559, eval loss 1.6408731937408447
Epoch 72 train loss: 1.1625, eval loss 1.6394411325454712
Epoch 73 train loss: 1.1169, eval loss 1.6389833688735962
Epoch 74 train loss: 1.1230, eval loss 1.635699987411499
Epoch 75 train loss: 1.1446, eval loss 1.63494074344635
Epoch 76 train loss: 1.1437, eval loss 1.6327348947525024
Epoch 77 train loss: 1.0716, eval loss 1.6319165229797363
Epoch 78 train loss: 1.1468, eval loss 1.630664587020874
Epoch 79 train loss: 1.0772, eval loss 1.6282117366790771
Epoch 80 train loss: 1.0873, eval loss 1.6284288167953491
Epoch 81 train loss: 1.1088, eval loss 1.6270121335983276
Epoch 82 train loss: 1.0554, eval loss 1.6265716552734375
Epoch 83 train loss: 1.1349, eval loss 1.625102162361145
Epoch 84 train loss: 1.0690, eval loss 1.6248893737792969
Epoch 85 train loss: 1.0517, eval loss 1.621917963027954
Epoch 86 train loss: 1.0758, eval loss 1.6206127405166626
Epoch 87 train loss: 1.1000, eval loss 1.6189677715301514
Epoch 88 train loss: 1.0684, eval loss 1.616856336593628
Epoch 89 train loss: 1.0810, eval loss 1.6180363893508911
Epoch 90 train loss: 1.1309, eval loss 1.6167402267456055
Epoch 91 train loss: 1.0984, eval loss 1.61648690700531
Epoch 92 train loss: 1.0657, eval loss 1.6149431467056274
Epoch 93 train loss: 1.0460, eval loss 1.6123534440994263
Epoch 94 train loss: 1.0487, eval loss 1.6109007596969604
Epoch 95 train loss: 1.0773, eval loss 1.6105389595031738
Epoch 96 train loss: 1.1271, eval loss 1.608135461807251
Epoch 97 train loss: 1.1445, eval loss 1.608803153038025
Epoch 98 train loss: 1.0011, eval loss 1.6068978309631348
Epoch 99 train loss: 1.0564, eval loss 1.6050087213516235
Epoch 100 train loss: 1.0016, eval loss 1.6057837009429932
Epoch 101 train loss: 0.9932, eval loss 1.6015737056732178
Epoch 102 train loss: 0.9978, eval loss 1.6027557849884033
Epoch 103 train loss: 1.0628, eval loss 1.6016921997070312
Epoch 104 train loss: 0.9444, eval loss 1.5995419025421143
Epoch 105 train loss: 1.0349, eval loss 1.5990091562271118
Epoch 106 train loss: 1.0230, eval loss 1.5975141525268555
Epoch 107 train loss: 1.0195, eval loss 1.5972322225570679
Epoch 108 train loss: 1.0198, eval loss 1.5951827764511108
Epoch 109 train loss: 1.0320, eval loss 1.5960237979888916
Epoch 110 train loss: 1.0139, eval loss 1.5934644937515259
Epoch 111 train loss: 0.9368, eval loss 1.594652533531189
Epoch 112 train loss: 1.0521, eval loss 1.592246413230896
Epoch 113 train loss: 0.9900, eval loss 1.5919430255889893
Epoch 114 train loss: 1.0075, eval loss 1.5893999338150024
Epoch 115 train loss: 0.9671, eval loss 1.5900907516479492
Epoch 116 train loss: 1.0321, eval loss 1.5868059396743774
Epoch 117 train loss: 1.0624, eval loss 1.585813045501709
Epoch 118 train loss: 0.9950, eval loss 1.5850902795791626
Epoch 119 train loss: 1.0251, eval loss 1.5854823589324951
Epoch 120 train loss: 0.9821, eval loss 1.5841835737228394
Epoch 121 train loss: 1.0623, eval loss 1.5816562175750732
Epoch 122 train loss: 1.0222, eval loss 1.583062767982483
Epoch 123 train loss: 0.9584, eval loss 1.581038236618042
Epoch 124 train loss: 1.0126, eval loss 1.5787622928619385
Epoch 125 train loss: 0.9395, eval loss 1.5804039239883423
Epoch 126 train loss: 1.0355, eval loss 1.578343152999878
Epoch 127 train loss: 0.9817, eval loss 1.5765517950057983
Epoch 128 train loss: 1.0032, eval loss 1.5759235620498657
Epoch 129 train loss: 0.9675, eval loss 1.57696533203125
Epoch 130 train loss: 0.9164, eval loss 1.5760406255722046
Epoch 131 train loss: 0.9638, eval loss 1.5746660232543945
Epoch 132 train loss: 0.9549, eval loss 1.5738136768341064
Epoch 133 train loss: 0.9676, eval loss 1.5729644298553467
Epoch 134 train loss: 0.9414, eval loss 1.5710358619689941
Epoch 135 train loss: 0.9553, eval loss 1.5713584423065186
Epoch 136 train loss: 0.9938, eval loss 1.5687830448150635
Epoch 137 train loss: 0.9543, eval loss 1.5686918497085571
Epoch 138 train loss: 0.9507, eval loss 1.5662401914596558
Epoch 139 train loss: 0.9147, eval loss 1.5659959316253662
Epoch 140 train loss: 0.9104, eval loss 1.5660405158996582
Epoch 141 train loss: 0.9520, eval loss 1.5653952360153198
Epoch 142 train loss: 0.9263, eval loss 1.562921166419983
Epoch 143 train loss: 0.8829, eval loss 1.5633361339569092
Epoch 144 train loss: 0.9663, eval loss 1.5629453659057617
Epoch 145 train loss: 0.9622, eval loss 1.5618784427642822
Epoch 146 train loss: 0.9235, eval loss 1.5612924098968506
Epoch 147 train loss: 0.9984, eval loss 1.5599592924118042
Epoch 148 train loss: 0.9261, eval loss 1.5599220991134644
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-26 22:56:36,070] Trial 18 finished with value: 1.5564539432525635 and parameters: {&#39;hidden_layers_size&#39;: 64, &#39;dropout_p&#39;: 0.402003374821153, &#39;learning_rate&#39;: 2.925001742148384e-06, &#39;batch_size&#39;: 128, &#39;l2_reg&#39;: 0.00014214787537244022}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.9608, eval loss 1.5564539432525635
Epoch 0 train loss: 1.4237, eval loss 1.7518784999847412
Epoch 1 train loss: 1.3585, eval loss 1.7327529191970825
Epoch 2 train loss: 1.2998, eval loss 1.7173981666564941
Epoch 3 train loss: 1.2192, eval loss 1.701725721359253
Epoch 4 train loss: 1.2220, eval loss 1.6877527236938477
Epoch 5 train loss: 1.1711, eval loss 1.6736961603164673
Epoch 6 train loss: 1.1422, eval loss 1.660018801689148
Epoch 7 train loss: 1.0869, eval loss 1.6502035856246948
Epoch 8 train loss: 1.0851, eval loss 1.6387524604797363
Epoch 9 train loss: 1.0721, eval loss 1.6298624277114868
Epoch 10 train loss: 1.0508, eval loss 1.620577335357666
Epoch 11 train loss: 1.0140, eval loss 1.6112985610961914
Epoch 12 train loss: 1.0173, eval loss 1.6012847423553467
Epoch 13 train loss: 0.9918, eval loss 1.5942553281784058
Epoch 14 train loss: 0.9412, eval loss 1.5863847732543945
Epoch 15 train loss: 0.9572, eval loss 1.5790684223175049
Epoch 16 train loss: 0.8800, eval loss 1.57260000705719
Epoch 17 train loss: 0.8827, eval loss 1.5653220415115356
Epoch 18 train loss: 0.8906, eval loss 1.5607333183288574
Epoch 19 train loss: 0.8806, eval loss 1.5556141138076782
Epoch 20 train loss: 0.8875, eval loss 1.5486234426498413
Epoch 21 train loss: 0.8600, eval loss 1.5442379713058472
Epoch 22 train loss: 0.8625, eval loss 1.5374544858932495
Epoch 23 train loss: 0.8215, eval loss 1.5315980911254883
Epoch 24 train loss: 0.8855, eval loss 1.52921724319458
Epoch 25 train loss: 0.9030, eval loss 1.525841236114502
Epoch 26 train loss: 0.8402, eval loss 1.5220195055007935
Epoch 27 train loss: 0.7994, eval loss 1.5164028406143188
Epoch 28 train loss: 0.7794, eval loss 1.5125811100006104
Epoch 29 train loss: 0.7731, eval loss 1.5112515687942505
Epoch 30 train loss: 0.7969, eval loss 1.507583498954773
Epoch 31 train loss: 0.7911, eval loss 1.5030803680419922
Epoch 32 train loss: 0.7748, eval loss 1.5024003982543945
Epoch 33 train loss: 0.7840, eval loss 1.4984217882156372
Epoch 34 train loss: 0.7990, eval loss 1.4960566759109497
Epoch 35 train loss: 0.8158, eval loss 1.4918735027313232
Epoch 36 train loss: 0.7655, eval loss 1.4911211729049683
Epoch 37 train loss: 0.8321, eval loss 1.4865466356277466
Epoch 38 train loss: 0.7520, eval loss 1.4857897758483887
Epoch 39 train loss: 0.7814, eval loss 1.4837238788604736
Epoch 40 train loss: 0.7813, eval loss 1.4809082746505737
Epoch 41 train loss: 0.7808, eval loss 1.4791823625564575
Epoch 42 train loss: 0.7741, eval loss 1.4785563945770264
Epoch 43 train loss: 0.8160, eval loss 1.4770073890686035
Epoch 44 train loss: 0.7539, eval loss 1.475518822669983
Epoch 45 train loss: 0.8418, eval loss 1.472933292388916
Epoch 46 train loss: 0.7363, eval loss 1.4715173244476318
Epoch 47 train loss: 0.7223, eval loss 1.4707845449447632
Epoch 48 train loss: 0.7975, eval loss 1.4689043760299683
Epoch 49 train loss: 0.7475, eval loss 1.4688429832458496
Epoch 50 train loss: 0.7425, eval loss 1.4660677909851074
Epoch 51 train loss: 0.7824, eval loss 1.4648652076721191
Epoch 52 train loss: 0.7732, eval loss 1.465348720550537
Epoch 53 train loss: 0.7750, eval loss 1.4627032279968262
Epoch 54 train loss: 0.7934, eval loss 1.4623249769210815
Epoch 55 train loss: 0.7408, eval loss 1.4619144201278687
Epoch 56 train loss: 0.7583, eval loss 1.4614382982254028
Epoch 57 train loss: 0.7327, eval loss 1.460315465927124
Epoch 58 train loss: 0.8096, eval loss 1.4585391283035278
Epoch 59 train loss: 0.8152, eval loss 1.4586269855499268
Epoch 60 train loss: 0.7364, eval loss 1.4566106796264648
Epoch 61 train loss: 0.7671, eval loss 1.457824468612671
Epoch 62 train loss: 0.7679, eval loss 1.4559587240219116
Epoch 63 train loss: 0.8489, eval loss 1.4560447931289673
Epoch 64 train loss: 0.7214, eval loss 1.4542845487594604
Epoch 65 train loss: 0.7805, eval loss 1.4550830125808716
Epoch 66 train loss: 0.7583, eval loss 1.4536653757095337
Epoch 67 train loss: 0.8174, eval loss 1.45457124710083
Epoch 68 train loss: 0.7050, eval loss 1.453822135925293
Epoch 69 train loss: 0.6427, eval loss 1.452039122581482
Epoch 70 train loss: 0.7948, eval loss 1.4527071714401245
Epoch 71 train loss: 0.7295, eval loss 1.4510992765426636
Epoch 72 train loss: 0.7939, eval loss 1.451401948928833
Epoch 73 train loss: 0.8261, eval loss 1.4514498710632324
Epoch 74 train loss: 0.7061, eval loss 1.4508124589920044
Epoch 75 train loss: 0.7226, eval loss 1.450002908706665
Epoch 76 train loss: 0.6422, eval loss 1.4498189687728882
Epoch 77 train loss: 0.7945, eval loss 1.4497112035751343
Epoch 78 train loss: 0.8328, eval loss 1.449005126953125
Epoch 79 train loss: 0.7843, eval loss 1.4489245414733887
Epoch 80 train loss: 0.7383, eval loss 1.4492058753967285
Epoch 81 train loss: 0.7819, eval loss 1.448482871055603
Epoch 82 train loss: 0.7445, eval loss 1.4488004446029663
Epoch 83 train loss: 0.7842, eval loss 1.448081135749817
Epoch 84 train loss: 0.7091, eval loss 1.447717547416687
Epoch 85 train loss: 0.7661, eval loss 1.4460344314575195
Epoch 86 train loss: 0.7429, eval loss 1.4473978281021118
Epoch 87 train loss: 0.7140, eval loss 1.4472627639770508
Epoch 88 train loss: 0.7559, eval loss 1.4472023248672485
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:42:41,064] Trial 19 finished with value: 1.4460344314575195 and parameters: {&#39;hidden_layers_size&#39;: 75, &#39;dropout_p&#39;: 0.4588624374776901, &#39;learning_rate&#39;: 2.7174157288421963e-05, &#39;batch_size&#39;: 171, &#39;l2_reg&#39;: 4.677829356538687e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4269, eval loss 1.7673331499099731
Epoch 1 train loss: 1.4530, eval loss 1.7630044221878052
Epoch 2 train loss: 1.3523, eval loss 1.7583152055740356
Epoch 3 train loss: 1.3817, eval loss 1.7568224668502808
Epoch 4 train loss: 1.4731, eval loss 1.7527133226394653
Epoch 5 train loss: 1.3015, eval loss 1.7478392124176025
Epoch 6 train loss: 1.4865, eval loss 1.7453664541244507
Epoch 7 train loss: 1.4300, eval loss 1.7425817251205444
Epoch 8 train loss: 1.2708, eval loss 1.738852620124817
Epoch 9 train loss: 1.2890, eval loss 1.7351007461547852
Epoch 10 train loss: 1.2935, eval loss 1.7327368259429932
Epoch 11 train loss: 1.3577, eval loss 1.7305092811584473
Epoch 12 train loss: 1.3683, eval loss 1.7265955209732056
Epoch 13 train loss: 1.2783, eval loss 1.7229878902435303
Epoch 14 train loss: 1.3557, eval loss 1.720778465270996
Epoch 15 train loss: 1.2791, eval loss 1.7178107500076294
Epoch 16 train loss: 1.3057, eval loss 1.7160099744796753
Epoch 17 train loss: 1.2994, eval loss 1.7130117416381836
Epoch 18 train loss: 1.3013, eval loss 1.7086949348449707
Epoch 19 train loss: 1.2894, eval loss 1.706137776374817
Epoch 20 train loss: 1.2883, eval loss 1.7045378684997559
Epoch 21 train loss: 1.1237, eval loss 1.6998927593231201
Epoch 22 train loss: 1.2220, eval loss 1.699904203414917
Epoch 23 train loss: 1.2567, eval loss 1.6960686445236206
Epoch 24 train loss: 1.2209, eval loss 1.6939966678619385
Epoch 25 train loss: 1.1252, eval loss 1.6906827688217163
Epoch 26 train loss: 1.2184, eval loss 1.688563585281372
Epoch 27 train loss: 1.1804, eval loss 1.685500979423523
Epoch 28 train loss: 1.1871, eval loss 1.683287262916565
Epoch 29 train loss: 1.2428, eval loss 1.6816511154174805
Epoch 30 train loss: 1.2048, eval loss 1.6785337924957275
Epoch 31 train loss: 1.1954, eval loss 1.6788541078567505
Epoch 32 train loss: 1.1832, eval loss 1.6737573146820068
Epoch 33 train loss: 1.1478, eval loss 1.6724720001220703
Epoch 34 train loss: 1.1812, eval loss 1.669743299484253
Epoch 35 train loss: 1.0904, eval loss 1.6672452688217163
Epoch 36 train loss: 1.1298, eval loss 1.663902997970581
Epoch 37 train loss: 1.1082, eval loss 1.662822961807251
Epoch 38 train loss: 1.1234, eval loss 1.661940336227417
Epoch 39 train loss: 1.0809, eval loss 1.6575700044631958
Epoch 40 train loss: 1.1318, eval loss 1.6576111316680908
Epoch 41 train loss: 1.0894, eval loss 1.65571129322052
Epoch 42 train loss: 1.0538, eval loss 1.6524832248687744
Epoch 43 train loss: 1.1231, eval loss 1.6515247821807861
Epoch 44 train loss: 1.1146, eval loss 1.6496491432189941
Epoch 45 train loss: 1.0186, eval loss 1.646246314048767
Epoch 46 train loss: 1.0670, eval loss 1.6448777914047241
Epoch 47 train loss: 1.1173, eval loss 1.6442506313323975
Epoch 48 train loss: 1.0347, eval loss 1.6416758298873901
Epoch 49 train loss: 1.0999, eval loss 1.6392885446548462
Epoch 50 train loss: 1.0429, eval loss 1.6372931003570557
Epoch 51 train loss: 1.0428, eval loss 1.6357113122940063
Epoch 52 train loss: 0.9868, eval loss 1.6352057456970215
Epoch 53 train loss: 0.9727, eval loss 1.6328517198562622
Epoch 54 train loss: 1.1011, eval loss 1.6321595907211304
Epoch 55 train loss: 1.0286, eval loss 1.6296125650405884
Epoch 56 train loss: 0.9797, eval loss 1.6280646324157715
Epoch 57 train loss: 1.0543, eval loss 1.6261872053146362
Epoch 58 train loss: 1.0125, eval loss 1.6244335174560547
Epoch 59 train loss: 1.0558, eval loss 1.6233570575714111
Epoch 60 train loss: 1.0378, eval loss 1.6222556829452515
Epoch 61 train loss: 0.9566, eval loss 1.6213167905807495
Epoch 62 train loss: 1.0098, eval loss 1.6188651323318481
Epoch 63 train loss: 1.0004, eval loss 1.6164735555648804
Epoch 64 train loss: 0.9889, eval loss 1.6159043312072754
Epoch 65 train loss: 0.9346, eval loss 1.6156089305877686
Epoch 66 train loss: 0.9727, eval loss 1.6133579015731812
Epoch 67 train loss: 1.0540, eval loss 1.6125341653823853
Epoch 68 train loss: 1.0025, eval loss 1.6110576391220093
Epoch 69 train loss: 1.0544, eval loss 1.609477162361145
Epoch 70 train loss: 0.9384, eval loss 1.6054922342300415
Epoch 71 train loss: 0.9472, eval loss 1.6054461002349854
Epoch 72 train loss: 1.0473, eval loss 1.60489821434021
Epoch 73 train loss: 0.9845, eval loss 1.6044921875
Epoch 74 train loss: 0.9386, eval loss 1.6026074886322021
Epoch 75 train loss: 1.0192, eval loss 1.60328209400177
Epoch 76 train loss: 0.9403, eval loss 1.6001654863357544
Epoch 77 train loss: 0.9749, eval loss 1.5984513759613037
Epoch 78 train loss: 0.9764, eval loss 1.597381591796875
Epoch 79 train loss: 0.9538, eval loss 1.5966540575027466
Epoch 80 train loss: 0.9529, eval loss 1.5937621593475342
Epoch 81 train loss: 0.9384, eval loss 1.5946931838989258
Epoch 82 train loss: 0.9902, eval loss 1.5935704708099365
Epoch 83 train loss: 0.9249, eval loss 1.591626524925232
Epoch 84 train loss: 0.9809, eval loss 1.588984489440918
Epoch 85 train loss: 0.9287, eval loss 1.5897369384765625
Epoch 86 train loss: 0.8836, eval loss 1.5886932611465454
Epoch 87 train loss: 0.8911, eval loss 1.5868459939956665
Epoch 88 train loss: 0.9211, eval loss 1.5845189094543457
Epoch 89 train loss: 0.9213, eval loss 1.5853534936904907
Epoch 90 train loss: 1.0039, eval loss 1.5839834213256836
Epoch 91 train loss: 0.9146, eval loss 1.5823851823806763
Epoch 92 train loss: 0.9130, eval loss 1.5799546241760254
Epoch 93 train loss: 0.9635, eval loss 1.5809227228164673
Epoch 94 train loss: 0.9768, eval loss 1.581597924232483
Epoch 95 train loss: 0.8882, eval loss 1.5780303478240967
Epoch 96 train loss: 0.8612, eval loss 1.576328158378601
Epoch 97 train loss: 0.9160, eval loss 1.5769944190979004
Epoch 98 train loss: 0.8941, eval loss 1.5753928422927856
Epoch 99 train loss: 0.9174, eval loss 1.5740717649459839
Epoch 100 train loss: 0.8949, eval loss 1.573195457458496
Epoch 101 train loss: 0.9514, eval loss 1.5720970630645752
Epoch 102 train loss: 0.8503, eval loss 1.5713040828704834
Epoch 103 train loss: 0.8819, eval loss 1.5704208612442017
Epoch 104 train loss: 0.9319, eval loss 1.5694799423217773
Epoch 105 train loss: 0.8716, eval loss 1.5681172609329224
Epoch 106 train loss: 0.9180, eval loss 1.5668061971664429
Epoch 107 train loss: 0.8340, eval loss 1.5674591064453125
Epoch 108 train loss: 0.8636, eval loss 1.5664979219436646
Epoch 109 train loss: 0.9107, eval loss 1.565218210220337
Epoch 110 train loss: 0.8316, eval loss 1.5632264614105225
Epoch 111 train loss: 0.9185, eval loss 1.5633087158203125
Epoch 112 train loss: 0.8126, eval loss 1.561916708946228
Epoch 113 train loss: 0.9063, eval loss 1.5604935884475708
Epoch 114 train loss: 0.8631, eval loss 1.5601571798324585
Epoch 115 train loss: 0.8783, eval loss 1.5582797527313232
Epoch 116 train loss: 0.9273, eval loss 1.5595866441726685
Epoch 117 train loss: 0.8815, eval loss 1.556955099105835
Epoch 118 train loss: 0.8284, eval loss 1.5569323301315308
Epoch 119 train loss: 0.8727, eval loss 1.5554864406585693
Epoch 120 train loss: 0.8359, eval loss 1.5553467273712158
Epoch 121 train loss: 0.9118, eval loss 1.5546088218688965
Epoch 122 train loss: 0.9503, eval loss 1.5535914897918701
Epoch 123 train loss: 0.8926, eval loss 1.5515034198760986
Epoch 124 train loss: 0.8173, eval loss 1.5513049364089966
Epoch 125 train loss: 0.8077, eval loss 1.5516326427459717
Epoch 126 train loss: 0.8541, eval loss 1.5507276058197021
Epoch 127 train loss: 0.8332, eval loss 1.5505772829055786
Epoch 128 train loss: 0.8252, eval loss 1.5488331317901611
Epoch 129 train loss: 0.8678, eval loss 1.5484150648117065
Epoch 130 train loss: 0.9102, eval loss 1.546929121017456
Epoch 131 train loss: 0.8551, eval loss 1.5471117496490479
Epoch 132 train loss: 0.8272, eval loss 1.5448980331420898
Epoch 133 train loss: 0.8180, eval loss 1.5453758239746094
Epoch 134 train loss: 0.8502, eval loss 1.5431642532348633
Epoch 135 train loss: 0.8968, eval loss 1.5430562496185303
Epoch 136 train loss: 0.8317, eval loss 1.5432058572769165
Epoch 137 train loss: 0.8370, eval loss 1.541237235069275
Epoch 138 train loss: 0.8309, eval loss 1.5410281419754028
Epoch 139 train loss: 0.8866, eval loss 1.5408674478530884
Epoch 140 train loss: 0.9000, eval loss 1.5390127897262573
Epoch 141 train loss: 0.7722, eval loss 1.5389695167541504
Epoch 142 train loss: 0.8511, eval loss 1.5378317832946777
Epoch 143 train loss: 0.8052, eval loss 1.5371854305267334
Epoch 144 train loss: 0.8267, eval loss 1.5371801853179932
Epoch 145 train loss: 0.8429, eval loss 1.5356162786483765
Epoch 146 train loss: 0.8578, eval loss 1.5345615148544312
Epoch 147 train loss: 0.8684, eval loss 1.5337110757827759
Epoch 148 train loss: 0.8118, eval loss 1.5322023630142212
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:44:11,008] Trial 20 finished with value: 1.5322023630142212 and parameters: {&#39;hidden_layers_size&#39;: 122, &#39;dropout_p&#39;: 0.41861694589624343, &#39;learning_rate&#39;: 3.0356108100441192e-06, &#39;batch_size&#39;: 212, &#39;l2_reg&#39;: 3.439449349888914e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.8130, eval loss 1.5334504842758179
Epoch 0 train loss: 1.3047, eval loss 1.725730299949646
Epoch 1 train loss: 1.2731, eval loss 1.7242501974105835
Epoch 2 train loss: 1.1229, eval loss 1.7224653959274292
Epoch 3 train loss: 1.2695, eval loss 1.7231342792510986
Epoch 4 train loss: 1.2164, eval loss 1.7227023839950562
Epoch 5 train loss: 1.3150, eval loss 1.7227174043655396
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:44:15,504] Trial 21 finished with value: 1.7224653959274292 and parameters: {&#39;hidden_layers_size&#39;: 71, &#39;dropout_p&#39;: 0.49736577627839546, &#39;learning_rate&#39;: 1.0551039883362064e-06, &#39;batch_size&#39;: 198, &#39;l2_reg&#39;: 2.6094790630653748e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.3705, eval loss 1.733750581741333
Epoch 1 train loss: 1.3743, eval loss 1.731155514717102
Epoch 2 train loss: 1.3849, eval loss 1.7319997549057007
Epoch 3 train loss: 1.2764, eval loss 1.7319679260253906
Epoch 4 train loss: 1.3692, eval loss 1.7291090488433838
Epoch 5 train loss: 1.3313, eval loss 1.728620171546936
Epoch 6 train loss: 1.3177, eval loss 1.7274119853973389
Epoch 7 train loss: 1.3013, eval loss 1.7271579504013062
Epoch 8 train loss: 1.2869, eval loss 1.7253220081329346
Epoch 9 train loss: 1.3078, eval loss 1.7242521047592163
Epoch 10 train loss: 1.3349, eval loss 1.7224780321121216
Epoch 11 train loss: 1.2946, eval loss 1.7216899394989014
Epoch 12 train loss: 1.2717, eval loss 1.7211766242980957
Epoch 13 train loss: 1.3488, eval loss 1.7201303243637085
Epoch 14 train loss: 1.3259, eval loss 1.7197123765945435
Epoch 15 train loss: 1.3178, eval loss 1.716759443283081
Epoch 16 train loss: 1.3303, eval loss 1.7160741090774536
Epoch 17 train loss: 1.3054, eval loss 1.7153841257095337
Epoch 18 train loss: 1.3528, eval loss 1.714979648590088
Epoch 19 train loss: 1.2877, eval loss 1.713847279548645
Epoch 20 train loss: 1.3019, eval loss 1.7107549905776978
Epoch 21 train loss: 1.2999, eval loss 1.710797667503357
Epoch 22 train loss: 1.2636, eval loss 1.7098394632339478
Epoch 23 train loss: 1.2630, eval loss 1.709180474281311
Epoch 24 train loss: 1.2589, eval loss 1.7079102993011475
Epoch 25 train loss: 1.3377, eval loss 1.7067316770553589
Epoch 26 train loss: 1.2558, eval loss 1.7055634260177612
Epoch 27 train loss: 1.2217, eval loss 1.7050402164459229
Epoch 28 train loss: 1.2864, eval loss 1.7039774656295776
Epoch 29 train loss: 1.2974, eval loss 1.7036683559417725
Epoch 30 train loss: 1.2831, eval loss 1.702599048614502
Epoch 31 train loss: 1.2596, eval loss 1.7000839710235596
Epoch 32 train loss: 1.1772, eval loss 1.699746012687683
Epoch 33 train loss: 1.2184, eval loss 1.6981828212738037
Epoch 34 train loss: 1.2913, eval loss 1.6986676454544067
Epoch 35 train loss: 1.2875, eval loss 1.6969705820083618
Epoch 36 train loss: 1.2444, eval loss 1.6974561214447021
Epoch 37 train loss: 1.3087, eval loss 1.6948143243789673
Epoch 38 train loss: 1.3094, eval loss 1.6943782567977905
Epoch 39 train loss: 1.2628, eval loss 1.6923824548721313
Epoch 40 train loss: 1.2365, eval loss 1.6932772397994995
Epoch 41 train loss: 1.2799, eval loss 1.6908628940582275
Epoch 42 train loss: 1.2883, eval loss 1.6889207363128662
Epoch 43 train loss: 1.2860, eval loss 1.6887258291244507
Epoch 44 train loss: 1.1552, eval loss 1.688542127609253
Epoch 45 train loss: 1.2627, eval loss 1.6868417263031006
Epoch 46 train loss: 1.2356, eval loss 1.6869571208953857
Epoch 47 train loss: 1.2442, eval loss 1.685944676399231
Epoch 48 train loss: 1.2139, eval loss 1.684516191482544
Epoch 49 train loss: 1.1889, eval loss 1.6828631162643433
Epoch 50 train loss: 1.2898, eval loss 1.6828241348266602
Epoch 51 train loss: 1.1940, eval loss 1.6806361675262451
Epoch 52 train loss: 1.1484, eval loss 1.6805193424224854
Epoch 53 train loss: 1.1584, eval loss 1.6787465810775757
Epoch 54 train loss: 1.2127, eval loss 1.6783390045166016
Epoch 55 train loss: 1.1654, eval loss 1.678597331047058
Epoch 56 train loss: 1.1647, eval loss 1.6768004894256592
Epoch 57 train loss: 1.2513, eval loss 1.6734812259674072
Epoch 58 train loss: 1.1906, eval loss 1.6740549802780151
Epoch 59 train loss: 1.1351, eval loss 1.673482894897461
Epoch 60 train loss: 1.1911, eval loss 1.6734989881515503
Epoch 61 train loss: 1.2208, eval loss 1.6722768545150757
Epoch 62 train loss: 1.2728, eval loss 1.67180597782135
Epoch 63 train loss: 1.2050, eval loss 1.6707137823104858
Epoch 64 train loss: 1.1818, eval loss 1.6696107387542725
Epoch 65 train loss: 1.1131, eval loss 1.6680840253829956
Epoch 66 train loss: 1.1932, eval loss 1.6681917905807495
Epoch 67 train loss: 1.1656, eval loss 1.6658263206481934
Epoch 68 train loss: 1.2114, eval loss 1.6650910377502441
Epoch 69 train loss: 1.1692, eval loss 1.6651313304901123
Epoch 70 train loss: 1.1479, eval loss 1.6641918420791626
Epoch 71 train loss: 1.2021, eval loss 1.6627424955368042
Epoch 72 train loss: 1.1372, eval loss 1.6627672910690308
Epoch 73 train loss: 1.1449, eval loss 1.6614347696304321
Epoch 74 train loss: 1.1844, eval loss 1.6608390808105469
Epoch 75 train loss: 1.1645, eval loss 1.6599299907684326
Epoch 76 train loss: 1.1493, eval loss 1.658995270729065
Epoch 77 train loss: 1.1848, eval loss 1.6577764749526978
Epoch 78 train loss: 1.1267, eval loss 1.6569712162017822
Epoch 79 train loss: 1.1027, eval loss 1.656029224395752
Epoch 80 train loss: 1.1888, eval loss 1.6558458805084229
Epoch 81 train loss: 1.1475, eval loss 1.6549596786499023
Epoch 82 train loss: 1.1338, eval loss 1.653656005859375
Epoch 83 train loss: 1.1668, eval loss 1.6539651155471802
Epoch 84 train loss: 1.1613, eval loss 1.6520715951919556
Epoch 85 train loss: 1.1640, eval loss 1.6517417430877686
Epoch 86 train loss: 1.1216, eval loss 1.6508949995040894
Epoch 87 train loss: 1.1173, eval loss 1.6500529050827026
Epoch 88 train loss: 1.1152, eval loss 1.6490997076034546
Epoch 89 train loss: 1.1668, eval loss 1.646999478340149
Epoch 90 train loss: 1.1435, eval loss 1.6472240686416626
Epoch 91 train loss: 1.1106, eval loss 1.6454671621322632
Epoch 92 train loss: 1.1422, eval loss 1.6451047658920288
Epoch 93 train loss: 1.1422, eval loss 1.6445043087005615
Epoch 94 train loss: 1.1407, eval loss 1.6457023620605469
Epoch 95 train loss: 1.0431, eval loss 1.6438438892364502
Epoch 96 train loss: 1.1217, eval loss 1.6423280239105225
Epoch 97 train loss: 1.1230, eval loss 1.6421599388122559
Epoch 98 train loss: 1.0131, eval loss 1.641148328781128
Epoch 99 train loss: 1.0565, eval loss 1.6418731212615967
Epoch 100 train loss: 1.0461, eval loss 1.6414194107055664
Epoch 101 train loss: 1.0924, eval loss 1.6396631002426147
Epoch 102 train loss: 1.1315, eval loss 1.6384748220443726
Epoch 103 train loss: 1.1041, eval loss 1.6377041339874268
Epoch 104 train loss: 1.0586, eval loss 1.6372647285461426
Epoch 105 train loss: 1.0267, eval loss 1.6360137462615967
Epoch 106 train loss: 1.1138, eval loss 1.6362828016281128
Epoch 107 train loss: 1.0691, eval loss 1.6342219114303589
Epoch 108 train loss: 1.0741, eval loss 1.6343525648117065
Epoch 109 train loss: 1.1463, eval loss 1.6325238943099976
Epoch 110 train loss: 1.0909, eval loss 1.632598876953125
Epoch 111 train loss: 1.1276, eval loss 1.6305137872695923
Epoch 112 train loss: 1.0242, eval loss 1.630598783493042
Epoch 113 train loss: 1.0996, eval loss 1.6300376653671265
Epoch 114 train loss: 1.0995, eval loss 1.6278963088989258
Epoch 115 train loss: 1.0172, eval loss 1.6277921199798584
Epoch 116 train loss: 1.0796, eval loss 1.6273844242095947
Epoch 117 train loss: 1.0318, eval loss 1.6271922588348389
Epoch 118 train loss: 1.0542, eval loss 1.6270301342010498
Epoch 119 train loss: 1.0534, eval loss 1.6263940334320068
Epoch 120 train loss: 1.0192, eval loss 1.6252282857894897
Epoch 121 train loss: 1.1287, eval loss 1.624140977859497
Epoch 122 train loss: 1.0502, eval loss 1.624626636505127
Epoch 123 train loss: 1.0417, eval loss 1.6228504180908203
Epoch 124 train loss: 1.0302, eval loss 1.6211061477661133
Epoch 125 train loss: 0.9984, eval loss 1.620654821395874
Epoch 126 train loss: 1.0991, eval loss 1.6217716932296753
Epoch 127 train loss: 1.1200, eval loss 1.619053602218628
Epoch 128 train loss: 1.1091, eval loss 1.619455337524414
Epoch 129 train loss: 1.0784, eval loss 1.6197524070739746
Epoch 130 train loss: 1.0075, eval loss 1.6179970502853394
Epoch 131 train loss: 1.0474, eval loss 1.6177520751953125
Epoch 132 train loss: 1.0710, eval loss 1.6163396835327148
Epoch 133 train loss: 1.0423, eval loss 1.6145164966583252
Epoch 134 train loss: 1.0222, eval loss 1.615534782409668
Epoch 135 train loss: 1.0395, eval loss 1.614393949508667
Epoch 136 train loss: 0.9983, eval loss 1.6150981187820435
Epoch 137 train loss: 1.0423, eval loss 1.6142224073410034
Epoch 138 train loss: 1.0493, eval loss 1.6143430471420288
Epoch 139 train loss: 1.0362, eval loss 1.613107442855835
Epoch 140 train loss: 1.0285, eval loss 1.61228609085083
Epoch 141 train loss: 1.0200, eval loss 1.6115580797195435
Epoch 142 train loss: 1.0751, eval loss 1.610437273979187
Epoch 143 train loss: 1.0698, eval loss 1.6107455492019653
Epoch 144 train loss: 1.0432, eval loss 1.6084901094436646
Epoch 145 train loss: 1.0258, eval loss 1.6079570055007935
Epoch 146 train loss: 1.0511, eval loss 1.60891854763031
Epoch 147 train loss: 1.1164, eval loss 1.6079124212265015
Epoch 148 train loss: 1.0058, eval loss 1.6074211597442627
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:45:39,605] Trial 22 finished with value: 1.6054496765136719 and parameters: {&#39;hidden_layers_size&#39;: 84, &#39;dropout_p&#39;: 0.47029535203187567, &#39;learning_rate&#39;: 1.4477541362750555e-06, &#39;batch_size&#39;: 185, &#39;l2_reg&#39;: 2.360547036473938e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 1.0208, eval loss 1.6054496765136719
Epoch 0 train loss: 1.5935, eval loss 1.7880141735076904
Epoch 1 train loss: 1.5351, eval loss 1.7857710123062134
Epoch 2 train loss: 1.5461, eval loss 1.7841145992279053
Epoch 3 train loss: 1.4897, eval loss 1.7827039957046509
Epoch 4 train loss: 1.4503, eval loss 1.7825782299041748
Epoch 5 train loss: 1.5530, eval loss 1.781283974647522
Epoch 6 train loss: 1.5136, eval loss 1.779823899269104
Epoch 7 train loss: 1.5754, eval loss 1.7769471406936646
Epoch 8 train loss: 1.5425, eval loss 1.7757607698440552
Epoch 9 train loss: 1.5614, eval loss 1.7736562490463257
Epoch 10 train loss: 1.4793, eval loss 1.7723870277404785
Epoch 11 train loss: 1.4729, eval loss 1.7714372873306274
Epoch 12 train loss: 1.4448, eval loss 1.771135687828064
Epoch 13 train loss: 1.4714, eval loss 1.768185019493103
Epoch 14 train loss: 1.4410, eval loss 1.7664580345153809
Epoch 15 train loss: 1.4678, eval loss 1.7658615112304688
Epoch 16 train loss: 1.4633, eval loss 1.7633495330810547
Epoch 17 train loss: 1.4400, eval loss 1.7631474733352661
Epoch 18 train loss: 1.4228, eval loss 1.7615065574645996
Epoch 19 train loss: 1.3871, eval loss 1.7610012292861938
Epoch 20 train loss: 1.4665, eval loss 1.7583627700805664
Epoch 21 train loss: 1.4885, eval loss 1.7572134733200073
Epoch 22 train loss: 1.4407, eval loss 1.7563495635986328
Epoch 23 train loss: 1.4162, eval loss 1.7546942234039307
Epoch 24 train loss: 1.4607, eval loss 1.7530972957611084
Epoch 25 train loss: 1.3852, eval loss 1.752567172050476
Epoch 26 train loss: 1.3528, eval loss 1.750510573387146
Epoch 27 train loss: 1.4447, eval loss 1.7494328022003174
Epoch 28 train loss: 1.4090, eval loss 1.7472563982009888
Epoch 29 train loss: 1.4602, eval loss 1.7464513778686523
Epoch 30 train loss: 1.3401, eval loss 1.7444686889648438
Epoch 31 train loss: 1.3789, eval loss 1.7438815832138062
Epoch 32 train loss: 1.4337, eval loss 1.7424105405807495
Epoch 33 train loss: 1.4119, eval loss 1.740817904472351
Epoch 34 train loss: 1.3901, eval loss 1.7404839992523193
Epoch 35 train loss: 1.4129, eval loss 1.7389905452728271
Epoch 36 train loss: 1.4048, eval loss 1.7375463247299194
Epoch 37 train loss: 1.3694, eval loss 1.7357193231582642
Epoch 38 train loss: 1.3544, eval loss 1.7345114946365356
Epoch 39 train loss: 1.3505, eval loss 1.7323508262634277
Epoch 40 train loss: 1.3589, eval loss 1.7305388450622559
Epoch 41 train loss: 1.3170, eval loss 1.7314262390136719
Epoch 42 train loss: 1.3939, eval loss 1.7286044359207153
Epoch 43 train loss: 1.4110, eval loss 1.7283326387405396
Epoch 44 train loss: 1.2941, eval loss 1.727417230606079
Epoch 45 train loss: 1.3187, eval loss 1.725979208946228
Epoch 46 train loss: 1.2600, eval loss 1.723677396774292
Epoch 47 train loss: 1.3153, eval loss 1.7235126495361328
Epoch 48 train loss: 1.2610, eval loss 1.7206988334655762
Epoch 49 train loss: 1.3305, eval loss 1.7214537858963013
Epoch 50 train loss: 1.2817, eval loss 1.719382405281067
Epoch 51 train loss: 1.3510, eval loss 1.717875361442566
Epoch 52 train loss: 1.2328, eval loss 1.7165358066558838
Epoch 53 train loss: 1.3329, eval loss 1.715855598449707
Epoch 54 train loss: 1.3135, eval loss 1.7143968343734741
Epoch 55 train loss: 1.1967, eval loss 1.7124384641647339
Epoch 56 train loss: 1.3139, eval loss 1.7108107805252075
Epoch 57 train loss: 1.2604, eval loss 1.7107669115066528
Epoch 58 train loss: 1.2867, eval loss 1.7086666822433472
Epoch 59 train loss: 1.2541, eval loss 1.708951711654663
Epoch 60 train loss: 1.2520, eval loss 1.707767128944397
Epoch 61 train loss: 1.3067, eval loss 1.706236720085144
Epoch 62 train loss: 1.2809, eval loss 1.7050538063049316
Epoch 63 train loss: 1.2274, eval loss 1.7028656005859375
Epoch 64 train loss: 1.3166, eval loss 1.7037975788116455
Epoch 65 train loss: 1.3104, eval loss 1.6998305320739746
Epoch 66 train loss: 1.2926, eval loss 1.7010048627853394
Epoch 67 train loss: 1.3039, eval loss 1.6992483139038086
Epoch 68 train loss: 1.2155, eval loss 1.6995999813079834
Epoch 69 train loss: 1.2019, eval loss 1.6974924802780151
Epoch 70 train loss: 1.2102, eval loss 1.6958646774291992
Epoch 71 train loss: 1.2045, eval loss 1.694856882095337
Epoch 72 train loss: 1.2488, eval loss 1.6936492919921875
Epoch 73 train loss: 1.2208, eval loss 1.6925960779190063
Epoch 74 train loss: 1.1970, eval loss 1.6903376579284668
Epoch 75 train loss: 1.2320, eval loss 1.690843939781189
Epoch 76 train loss: 1.1987, eval loss 1.6896551847457886
Epoch 77 train loss: 1.2319, eval loss 1.689412236213684
Epoch 78 train loss: 1.2234, eval loss 1.688734531402588
Epoch 79 train loss: 1.2498, eval loss 1.6859339475631714
Epoch 80 train loss: 1.2077, eval loss 1.684126615524292
Epoch 81 train loss: 1.1737, eval loss 1.6850192546844482
Epoch 82 train loss: 1.2154, eval loss 1.6830295324325562
Epoch 83 train loss: 1.2352, eval loss 1.6831227540969849
Epoch 84 train loss: 1.1488, eval loss 1.6795365810394287
Epoch 85 train loss: 1.1342, eval loss 1.6799654960632324
Epoch 86 train loss: 1.2107, eval loss 1.6795397996902466
Epoch 87 train loss: 1.1494, eval loss 1.6776201725006104
Epoch 88 train loss: 1.2369, eval loss 1.676268219947815
Epoch 89 train loss: 1.1441, eval loss 1.6748626232147217
Epoch 90 train loss: 1.2213, eval loss 1.6754790544509888
Epoch 91 train loss: 1.1870, eval loss 1.673515796661377
Epoch 92 train loss: 1.1453, eval loss 1.6729786396026611
Epoch 93 train loss: 1.1632, eval loss 1.6719518899917603
Epoch 94 train loss: 1.2167, eval loss 1.670576572418213
Epoch 95 train loss: 1.1869, eval loss 1.6709797382354736
Epoch 96 train loss: 1.1822, eval loss 1.6698026657104492
Epoch 97 train loss: 1.1911, eval loss 1.6690245866775513
Epoch 98 train loss: 1.2527, eval loss 1.6658203601837158
Epoch 99 train loss: 1.1220, eval loss 1.6653409004211426
Epoch 100 train loss: 1.1436, eval loss 1.6656262874603271
Epoch 101 train loss: 1.1550, eval loss 1.6644266843795776
Epoch 102 train loss: 1.1144, eval loss 1.6630940437316895
Epoch 103 train loss: 1.1216, eval loss 1.6615591049194336
Epoch 104 train loss: 1.1542, eval loss 1.660296082496643
Epoch 105 train loss: 1.0979, eval loss 1.6597023010253906
Epoch 106 train loss: 1.1257, eval loss 1.6593830585479736
Epoch 107 train loss: 1.0805, eval loss 1.6591391563415527
Epoch 108 train loss: 1.1684, eval loss 1.6582908630371094
Epoch 109 train loss: 1.1554, eval loss 1.6570606231689453
Epoch 110 train loss: 1.0918, eval loss 1.6561259031295776
Epoch 111 train loss: 1.1547, eval loss 1.6552890539169312
Epoch 112 train loss: 1.1618, eval loss 1.6517044305801392
Epoch 113 train loss: 1.0699, eval loss 1.6523261070251465
Epoch 114 train loss: 1.0840, eval loss 1.6504502296447754
Epoch 115 train loss: 1.1129, eval loss 1.6514098644256592
Epoch 116 train loss: 1.0331, eval loss 1.6508616209030151
Epoch 117 train loss: 1.0353, eval loss 1.649013876914978
Epoch 118 train loss: 1.0308, eval loss 1.648156762123108
Epoch 119 train loss: 1.0804, eval loss 1.6478043794631958
Epoch 120 train loss: 1.1206, eval loss 1.645969271659851
Epoch 121 train loss: 1.1169, eval loss 1.6463595628738403
Epoch 122 train loss: 1.1667, eval loss 1.645134449005127
Epoch 123 train loss: 1.1528, eval loss 1.644189715385437
Epoch 124 train loss: 1.0961, eval loss 1.6430745124816895
Epoch 125 train loss: 1.0439, eval loss 1.641608715057373
Epoch 126 train loss: 1.0221, eval loss 1.6417489051818848
Epoch 127 train loss: 1.0161, eval loss 1.641656517982483
Epoch 128 train loss: 1.1446, eval loss 1.6412816047668457
Epoch 129 train loss: 1.0373, eval loss 1.6390169858932495
Epoch 130 train loss: 1.1071, eval loss 1.6384353637695312
Epoch 131 train loss: 1.0638, eval loss 1.6381710767745972
Epoch 132 train loss: 1.0723, eval loss 1.6394087076187134
Epoch 133 train loss: 1.1222, eval loss 1.6367027759552002
Epoch 134 train loss: 1.0875, eval loss 1.6354811191558838
Epoch 135 train loss: 1.0545, eval loss 1.6345593929290771
Epoch 136 train loss: 1.0479, eval loss 1.63283371925354
Epoch 137 train loss: 1.0655, eval loss 1.6309117078781128
Epoch 138 train loss: 1.0605, eval loss 1.6311973333358765
Epoch 139 train loss: 1.1031, eval loss 1.6306841373443604
Epoch 140 train loss: 1.0302, eval loss 1.6308344602584839
Epoch 141 train loss: 1.0621, eval loss 1.6296682357788086
Epoch 142 train loss: 1.0524, eval loss 1.6272556781768799
Epoch 143 train loss: 1.0577, eval loss 1.6263642311096191
Epoch 144 train loss: 1.0353, eval loss 1.6273634433746338
Epoch 145 train loss: 1.0454, eval loss 1.6251420974731445
Epoch 146 train loss: 1.0160, eval loss 1.6246689558029175
Epoch 147 train loss: 0.9668, eval loss 1.6229764223098755
Epoch 148 train loss: 1.0688, eval loss 1.6219995021820068
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:46:49,695] Trial 23 finished with value: 1.6219995021820068 and parameters: {&#39;hidden_layers_size&#39;: 65, &#39;dropout_p&#39;: 0.4748843483501442, &#39;learning_rate&#39;: 2.9979960530676105e-06, &#39;batch_size&#39;: 218, &#39;l2_reg&#39;: 1.6027807222253194e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 1.0009, eval loss 1.6235897541046143
Epoch 0 train loss: 1.6496, eval loss 1.8034542798995972
Epoch 1 train loss: 1.6724, eval loss 1.7963709831237793
Epoch 2 train loss: 1.5607, eval loss 1.7871358394622803
Epoch 3 train loss: 1.5602, eval loss 1.7805551290512085
Epoch 4 train loss: 1.6096, eval loss 1.7757809162139893
Epoch 5 train loss: 1.5294, eval loss 1.7659406661987305
Epoch 6 train loss: 1.4712, eval loss 1.759475827217102
Epoch 7 train loss: 1.5088, eval loss 1.7517280578613281
Epoch 8 train loss: 1.4498, eval loss 1.7465214729309082
Epoch 9 train loss: 1.4121, eval loss 1.7404727935791016
Epoch 10 train loss: 1.3451, eval loss 1.734407663345337
Epoch 11 train loss: 1.3423, eval loss 1.7313398122787476
Epoch 12 train loss: 1.3664, eval loss 1.7253390550613403
Epoch 13 train loss: 1.3494, eval loss 1.717074990272522
Epoch 14 train loss: 1.3497, eval loss 1.7133262157440186
Epoch 15 train loss: 1.3323, eval loss 1.7084074020385742
Epoch 16 train loss: 1.3513, eval loss 1.7037036418914795
Epoch 17 train loss: 1.3154, eval loss 1.6987557411193848
Epoch 18 train loss: 1.3093, eval loss 1.6953374147415161
Epoch 19 train loss: 1.2908, eval loss 1.6897698640823364
Epoch 20 train loss: 1.2719, eval loss 1.6855865716934204
Epoch 21 train loss: 1.2514, eval loss 1.6815623044967651
Epoch 22 train loss: 1.2022, eval loss 1.676567554473877
Epoch 23 train loss: 1.2714, eval loss 1.674761414527893
Epoch 24 train loss: 1.1836, eval loss 1.6686277389526367
Epoch 25 train loss: 1.1448, eval loss 1.6655293703079224
Epoch 26 train loss: 1.2113, eval loss 1.6615965366363525
Epoch 27 train loss: 1.1585, eval loss 1.6584794521331787
Epoch 28 train loss: 1.1496, eval loss 1.6541439294815063
Epoch 29 train loss: 1.1756, eval loss 1.6512633562088013
Epoch 30 train loss: 1.1071, eval loss 1.6481274366378784
Epoch 31 train loss: 1.0782, eval loss 1.6454874277114868
Epoch 32 train loss: 1.1517, eval loss 1.6442080736160278
Epoch 33 train loss: 1.0808, eval loss 1.6392790079116821
Epoch 34 train loss: 1.1980, eval loss 1.6359230279922485
Epoch 35 train loss: 1.1123, eval loss 1.6345115900039673
Epoch 36 train loss: 1.1180, eval loss 1.6302621364593506
Epoch 37 train loss: 1.0289, eval loss 1.6263699531555176
Epoch 38 train loss: 1.0187, eval loss 1.6245392560958862
Epoch 39 train loss: 1.0435, eval loss 1.6230089664459229
Epoch 40 train loss: 1.0489, eval loss 1.6187388896942139
Epoch 41 train loss: 0.9943, eval loss 1.6155991554260254
Epoch 42 train loss: 1.0363, eval loss 1.6135976314544678
Epoch 43 train loss: 1.0084, eval loss 1.6117208003997803
Epoch 44 train loss: 1.0021, eval loss 1.6082932949066162
Epoch 45 train loss: 1.0038, eval loss 1.6063791513442993
Epoch 46 train loss: 0.9544, eval loss 1.60380220413208
Epoch 47 train loss: 0.9923, eval loss 1.60105562210083
Epoch 48 train loss: 1.0232, eval loss 1.6003341674804688
Epoch 49 train loss: 0.9921, eval loss 1.595794439315796
Epoch 50 train loss: 0.9938, eval loss 1.5958399772644043
Epoch 51 train loss: 0.9800, eval loss 1.5914700031280518
Epoch 52 train loss: 0.9893, eval loss 1.5899049043655396
Epoch 53 train loss: 1.0089, eval loss 1.588496208190918
Epoch 54 train loss: 0.9727, eval loss 1.585402011871338
Epoch 55 train loss: 0.9953, eval loss 1.5835225582122803
Epoch 56 train loss: 0.9724, eval loss 1.5804996490478516
Epoch 57 train loss: 0.9418, eval loss 1.5799806118011475
Epoch 58 train loss: 0.9553, eval loss 1.5786678791046143
Epoch 59 train loss: 0.9413, eval loss 1.5749313831329346
Epoch 60 train loss: 0.9190, eval loss 1.5735867023468018
Epoch 61 train loss: 0.9604, eval loss 1.5700324773788452
Epoch 62 train loss: 0.9510, eval loss 1.5705138444900513
Epoch 63 train loss: 0.9352, eval loss 1.5685774087905884
Epoch 64 train loss: 0.9651, eval loss 1.565674066543579
Epoch 65 train loss: 0.9386, eval loss 1.5637879371643066
Epoch 66 train loss: 0.9006, eval loss 1.5623047351837158
Epoch 67 train loss: 0.9153, eval loss 1.5607095956802368
Epoch 68 train loss: 0.8739, eval loss 1.558519721031189
Epoch 69 train loss: 0.8824, eval loss 1.5570112466812134
Epoch 70 train loss: 0.9177, eval loss 1.5546101331710815
Epoch 71 train loss: 0.8269, eval loss 1.5529975891113281
Epoch 72 train loss: 0.8835, eval loss 1.5523186922073364
Epoch 73 train loss: 0.9095, eval loss 1.550399661064148
Epoch 74 train loss: 0.8410, eval loss 1.549817681312561
Epoch 75 train loss: 0.8117, eval loss 1.5481901168823242
Epoch 76 train loss: 0.8877, eval loss 1.5443452596664429
Epoch 77 train loss: 0.8138, eval loss 1.5432486534118652
Epoch 78 train loss: 0.7864, eval loss 1.541451334953308
Epoch 79 train loss: 0.8748, eval loss 1.539109706878662
Epoch 80 train loss: 0.8310, eval loss 1.5394736528396606
Epoch 81 train loss: 0.8942, eval loss 1.536368727684021
Epoch 82 train loss: 0.8509, eval loss 1.5361523628234863
Epoch 83 train loss: 0.8474, eval loss 1.5346862077713013
Epoch 84 train loss: 0.8334, eval loss 1.5332255363464355
Epoch 85 train loss: 0.8478, eval loss 1.5314387083053589
Epoch 86 train loss: 0.8336, eval loss 1.5309251546859741
Epoch 87 train loss: 0.8543, eval loss 1.529951810836792
Epoch 88 train loss: 0.8369, eval loss 1.5279960632324219
Epoch 89 train loss: 0.8407, eval loss 1.527328372001648
Epoch 90 train loss: 0.7975, eval loss 1.5244296789169312
Epoch 91 train loss: 0.7930, eval loss 1.5241457223892212
Epoch 92 train loss: 0.8569, eval loss 1.5228502750396729
Epoch 93 train loss: 0.8611, eval loss 1.5203063488006592
Epoch 94 train loss: 0.8270, eval loss 1.5190072059631348
Epoch 95 train loss: 0.8588, eval loss 1.5187792778015137
Epoch 96 train loss: 0.8251, eval loss 1.5175349712371826
Epoch 97 train loss: 0.8046, eval loss 1.515991449356079
Epoch 98 train loss: 0.8007, eval loss 1.5141985416412354
Epoch 99 train loss: 0.7711, eval loss 1.5130815505981445
Epoch 100 train loss: 0.8046, eval loss 1.5121841430664062
Epoch 101 train loss: 0.8043, eval loss 1.512342095375061
Epoch 102 train loss: 0.8008, eval loss 1.5096650123596191
Epoch 103 train loss: 0.8185, eval loss 1.5092988014221191
Epoch 104 train loss: 0.7879, eval loss 1.5075502395629883
Epoch 105 train loss: 0.8025, eval loss 1.5070061683654785
Epoch 106 train loss: 0.7548, eval loss 1.505195140838623
Epoch 107 train loss: 0.7762, eval loss 1.5050640106201172
Epoch 108 train loss: 0.7786, eval loss 1.503246545791626
Epoch 109 train loss: 0.7832, eval loss 1.5017298460006714
Epoch 110 train loss: 0.7981, eval loss 1.50144362449646
Epoch 111 train loss: 0.7717, eval loss 1.5007941722869873
Epoch 112 train loss: 0.8061, eval loss 1.4994536638259888
Epoch 113 train loss: 0.7951, eval loss 1.498060703277588
Epoch 114 train loss: 0.7183, eval loss 1.4966471195220947
Epoch 115 train loss: 0.7770, eval loss 1.4961724281311035
Epoch 116 train loss: 0.8039, eval loss 1.4954696893692017
Epoch 117 train loss: 0.7756, eval loss 1.4945805072784424
Epoch 118 train loss: 0.8058, eval loss 1.4934417009353638
Epoch 119 train loss: 0.7827, eval loss 1.4931905269622803
Epoch 120 train loss: 0.7621, eval loss 1.492629051208496
Epoch 121 train loss: 0.7552, eval loss 1.4907400608062744
Epoch 122 train loss: 0.7848, eval loss 1.489794135093689
Epoch 123 train loss: 0.7199, eval loss 1.48883056640625
Epoch 124 train loss: 0.7649, eval loss 1.4881139993667603
Epoch 125 train loss: 0.7286, eval loss 1.487944483757019
Epoch 126 train loss: 0.7660, eval loss 1.4861446619033813
Epoch 127 train loss: 0.7416, eval loss 1.4869012832641602
Epoch 128 train loss: 0.6946, eval loss 1.4846513271331787
Epoch 129 train loss: 0.7334, eval loss 1.4847633838653564
Epoch 130 train loss: 0.7670, eval loss 1.484062671661377
Epoch 131 train loss: 0.7638, eval loss 1.4830361604690552
Epoch 132 train loss: 0.7822, eval loss 1.4829961061477661
Epoch 133 train loss: 0.7702, eval loss 1.4822185039520264
Epoch 134 train loss: 0.7958, eval loss 1.4807275533676147
Epoch 135 train loss: 0.7084, eval loss 1.4794721603393555
Epoch 136 train loss: 0.7542, eval loss 1.47948157787323
Epoch 137 train loss: 0.7608, eval loss 1.4795629978179932
Epoch 138 train loss: 0.7232, eval loss 1.4786512851715088
Epoch 139 train loss: 0.7572, eval loss 1.4783658981323242
Epoch 140 train loss: 0.6955, eval loss 1.477036952972412
Epoch 141 train loss: 0.7326, eval loss 1.476219892501831
Epoch 142 train loss: 0.6840, eval loss 1.4766144752502441
Epoch 143 train loss: 0.7260, eval loss 1.475031852722168
Epoch 144 train loss: 0.7443, eval loss 1.4738037586212158
Epoch 145 train loss: 0.7355, eval loss 1.4735723733901978
Epoch 146 train loss: 0.7462, eval loss 1.4721843004226685
Epoch 147 train loss: 0.7106, eval loss 1.472124695777893
Epoch 148 train loss: 0.7503, eval loss 1.4710332155227661
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:48:17,888] Trial 24 finished with value: 1.4707778692245483 and parameters: {&#39;hidden_layers_size&#39;: 96, &#39;dropout_p&#39;: 0.4317841855591858, &#39;learning_rate&#39;: 6.154684650866806e-06, &#39;batch_size&#39;: 151, &#39;l2_reg&#39;: 3.686034660496669e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7528, eval loss 1.4707778692245483
Epoch 0 train loss: 1.2679, eval loss 1.770382285118103
Epoch 1 train loss: 1.2088, eval loss 1.7655798196792603
Epoch 2 train loss: 1.3492, eval loss 1.7646434307098389
Epoch 3 train loss: 1.3397, eval loss 1.7632484436035156
Epoch 4 train loss: 1.3373, eval loss 1.7616194486618042
Epoch 5 train loss: 1.1794, eval loss 1.7616240978240967
Epoch 6 train loss: 1.4206, eval loss 1.7612793445587158
Epoch 7 train loss: 1.4506, eval loss 1.7612364292144775
Epoch 8 train loss: 1.4705, eval loss 1.754624366760254
Epoch 9 train loss: 1.1209, eval loss 1.756594181060791
Epoch 10 train loss: 1.5553, eval loss 1.7512987852096558
Epoch 11 train loss: 1.3383, eval loss 1.7509173154830933
Epoch 12 train loss: 1.1843, eval loss 1.7521178722381592
Epoch 13 train loss: 1.1302, eval loss 1.7495754957199097
Epoch 14 train loss: 1.2286, eval loss 1.7470674514770508
Epoch 15 train loss: 1.0775, eval loss 1.7458668947219849
Epoch 16 train loss: 1.3368, eval loss 1.7423315048217773
Epoch 17 train loss: 1.2931, eval loss 1.7440698146820068
Epoch 18 train loss: 1.2134, eval loss 1.7426668405532837
Epoch 19 train loss: 0.9862, eval loss 1.7421095371246338
Epoch 20 train loss: 1.2770, eval loss 1.7387545108795166
Epoch 21 train loss: 1.1398, eval loss 1.7389672994613647
Epoch 22 train loss: 1.0871, eval loss 1.739350438117981
Epoch 23 train loss: 1.4149, eval loss 1.734492540359497
Epoch 24 train loss: 1.5911, eval loss 1.7359423637390137
Epoch 25 train loss: 1.1840, eval loss 1.7326701879501343
Epoch 26 train loss: 1.1379, eval loss 1.7299749851226807
Epoch 27 train loss: 1.0629, eval loss 1.7285325527191162
Epoch 28 train loss: 1.2418, eval loss 1.7271754741668701
Epoch 29 train loss: 1.1328, eval loss 1.7291523218154907
Epoch 30 train loss: 1.1152, eval loss 1.724206805229187
Epoch 31 train loss: 1.0207, eval loss 1.7231451272964478
Epoch 32 train loss: 1.1585, eval loss 1.7254709005355835
Epoch 33 train loss: 1.1226, eval loss 1.7234179973602295
Epoch 34 train loss: 1.1307, eval loss 1.7223273515701294
Epoch 35 train loss: 1.2857, eval loss 1.7196789979934692
Epoch 36 train loss: 1.0500, eval loss 1.71662437915802
Epoch 37 train loss: 1.0403, eval loss 1.7186734676361084
Epoch 38 train loss: 1.1527, eval loss 1.7144511938095093
Epoch 39 train loss: 1.2129, eval loss 1.7154626846313477
Epoch 40 train loss: 1.1280, eval loss 1.7125434875488281
Epoch 41 train loss: 1.0968, eval loss 1.7099602222442627
Epoch 42 train loss: 1.0520, eval loss 1.7124450206756592
Epoch 43 train loss: 1.0269, eval loss 1.7073609828948975
Epoch 44 train loss: 1.2377, eval loss 1.7061924934387207
Epoch 45 train loss: 1.1683, eval loss 1.7093734741210938
Epoch 46 train loss: 1.0499, eval loss 1.7055984735488892
Epoch 47 train loss: 1.0453, eval loss 1.7035999298095703
Epoch 48 train loss: 1.3200, eval loss 1.706383466720581
Epoch 49 train loss: 1.1536, eval loss 1.6982091665267944
Epoch 50 train loss: 1.2094, eval loss 1.703837513923645
Epoch 51 train loss: 0.9567, eval loss 1.6981000900268555
Epoch 52 train loss: 1.0988, eval loss 1.7017028331756592
Epoch 53 train loss: 1.7033, eval loss 1.6993179321289062
Epoch 54 train loss: 1.0674, eval loss 1.6976091861724854
Epoch 55 train loss: 1.0435, eval loss 1.6979310512542725
Epoch 56 train loss: 1.1161, eval loss 1.6964517831802368
Epoch 57 train loss: 1.0529, eval loss 1.6934183835983276
Epoch 58 train loss: 1.0443, eval loss 1.693878173828125
Epoch 59 train loss: 1.1267, eval loss 1.6909087896347046
Epoch 60 train loss: 0.9813, eval loss 1.691400408744812
Epoch 61 train loss: 1.1217, eval loss 1.6875416040420532
Epoch 62 train loss: 0.8008, eval loss 1.6873582601547241
Epoch 63 train loss: 1.0999, eval loss 1.6900724172592163
Epoch 64 train loss: 0.9853, eval loss 1.688281774520874
Epoch 65 train loss: 0.9149, eval loss 1.683087706565857
Epoch 66 train loss: 1.0498, eval loss 1.685681700706482
Epoch 67 train loss: 1.3238, eval loss 1.6844269037246704
Epoch 68 train loss: 0.9091, eval loss 1.6801937818527222
Epoch 69 train loss: 1.1808, eval loss 1.679755687713623
Epoch 70 train loss: 0.9711, eval loss 1.6805928945541382
Epoch 71 train loss: 1.0412, eval loss 1.678232192993164
Epoch 72 train loss: 1.0664, eval loss 1.6782078742980957
Epoch 73 train loss: 1.0166, eval loss 1.6770384311676025
Epoch 74 train loss: 0.8901, eval loss 1.6761045455932617
Epoch 75 train loss: 0.9562, eval loss 1.6769981384277344
Epoch 76 train loss: 1.1029, eval loss 1.6739836931228638
Epoch 77 train loss: 0.9130, eval loss 1.6719071865081787
Epoch 78 train loss: 0.9908, eval loss 1.6721700429916382
Epoch 79 train loss: 0.7605, eval loss 1.6708885431289673
Epoch 80 train loss: 1.1390, eval loss 1.6715192794799805
Epoch 81 train loss: 0.8574, eval loss 1.6678253412246704
Epoch 82 train loss: 0.9154, eval loss 1.6673029661178589
Epoch 83 train loss: 0.8798, eval loss 1.669440746307373
Epoch 84 train loss: 0.9329, eval loss 1.6678125858306885
Epoch 85 train loss: 1.0992, eval loss 1.6705539226531982
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:49:02,380] Trial 25 finished with value: 1.6673029661178589 and parameters: {&#39;hidden_layers_size&#39;: 79, &#39;dropout_p&#39;: 0.47541602771403274, &#39;learning_rate&#39;: 1.638060456814591e-06, &#39;batch_size&#39;: 178, &#39;l2_reg&#39;: 1.1879550697796984e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4276, eval loss 1.760650873184204
Epoch 1 train loss: 1.4243, eval loss 1.7473496198654175
Epoch 2 train loss: 1.4075, eval loss 1.7382439374923706
Epoch 3 train loss: 1.3131, eval loss 1.7317560911178589
Epoch 4 train loss: 1.3350, eval loss 1.7215149402618408
Epoch 5 train loss: 1.2760, eval loss 1.711403489112854
Epoch 6 train loss: 1.3024, eval loss 1.703236699104309
Epoch 7 train loss: 1.2752, eval loss 1.69441819190979
Epoch 8 train loss: 1.2684, eval loss 1.6880757808685303
Epoch 9 train loss: 1.2750, eval loss 1.6802438497543335
Epoch 10 train loss: 1.1779, eval loss 1.6739473342895508
Epoch 11 train loss: 1.1015, eval loss 1.6680017709732056
Epoch 12 train loss: 1.1309, eval loss 1.6602672338485718
Epoch 13 train loss: 1.1185, eval loss 1.653985857963562
Epoch 14 train loss: 1.0809, eval loss 1.6494412422180176
Epoch 15 train loss: 1.0625, eval loss 1.6443842649459839
Epoch 16 train loss: 1.0799, eval loss 1.6403449773788452
Epoch 17 train loss: 1.0327, eval loss 1.6337041854858398
Epoch 18 train loss: 1.0769, eval loss 1.6295416355133057
Epoch 19 train loss: 1.0617, eval loss 1.624611258506775
Epoch 20 train loss: 1.0872, eval loss 1.6210397481918335
Epoch 21 train loss: 1.0784, eval loss 1.616349458694458
Epoch 22 train loss: 1.0127, eval loss 1.6119332313537598
Epoch 23 train loss: 1.0216, eval loss 1.609316110610962
Epoch 24 train loss: 1.0774, eval loss 1.6050305366516113
Epoch 25 train loss: 0.9963, eval loss 1.599855661392212
Epoch 26 train loss: 1.0786, eval loss 1.5972609519958496
Epoch 27 train loss: 0.9632, eval loss 1.5945966243743896
Epoch 28 train loss: 0.9841, eval loss 1.5895496606826782
Epoch 29 train loss: 0.9645, eval loss 1.5873748064041138
Epoch 30 train loss: 1.0080, eval loss 1.5845110416412354
Epoch 31 train loss: 0.9625, eval loss 1.5800702571868896
Epoch 32 train loss: 0.9140, eval loss 1.5776164531707764
Epoch 33 train loss: 0.9204, eval loss 1.573986530303955
Epoch 34 train loss: 0.9128, eval loss 1.5721116065979004
Epoch 35 train loss: 0.9456, eval loss 1.5689743757247925
Epoch 36 train loss: 0.9044, eval loss 1.5658036470413208
Epoch 37 train loss: 0.9307, eval loss 1.564959168434143
Epoch 38 train loss: 0.9439, eval loss 1.5606940984725952
Epoch 39 train loss: 0.9128, eval loss 1.5578325986862183
Epoch 40 train loss: 0.9151, eval loss 1.556566596031189
Epoch 41 train loss: 0.9255, eval loss 1.5544508695602417
Epoch 42 train loss: 0.9105, eval loss 1.5523574352264404
Epoch 43 train loss: 0.9015, eval loss 1.5496559143066406
Epoch 44 train loss: 0.8918, eval loss 1.5481672286987305
Epoch 45 train loss: 0.8751, eval loss 1.5453779697418213
Epoch 46 train loss: 0.8800, eval loss 1.5423974990844727
Epoch 47 train loss: 0.8795, eval loss 1.5398794412612915
Epoch 48 train loss: 0.9073, eval loss 1.538259744644165
Epoch 49 train loss: 0.8994, eval loss 1.5365524291992188
Epoch 50 train loss: 0.8630, eval loss 1.533186674118042
Epoch 51 train loss: 0.8580, eval loss 1.5319180488586426
Epoch 52 train loss: 0.9626, eval loss 1.5308623313903809
Epoch 53 train loss: 0.8573, eval loss 1.5291664600372314
Epoch 54 train loss: 0.8906, eval loss 1.5255155563354492
Epoch 55 train loss: 0.8112, eval loss 1.525126576423645
Epoch 56 train loss: 0.8613, eval loss 1.5218654870986938
Epoch 57 train loss: 0.7885, eval loss 1.5210117101669312
Epoch 58 train loss: 0.8098, eval loss 1.5194566249847412
Epoch 59 train loss: 0.8743, eval loss 1.5174835920333862
Epoch 60 train loss: 0.8572, eval loss 1.5164763927459717
Epoch 61 train loss: 0.8133, eval loss 1.513860821723938
Epoch 62 train loss: 0.8349, eval loss 1.512378215789795
Epoch 63 train loss: 0.8212, eval loss 1.5115125179290771
Epoch 64 train loss: 0.8924, eval loss 1.5092010498046875
Epoch 65 train loss: 0.7594, eval loss 1.507811427116394
Epoch 66 train loss: 0.8583, eval loss 1.5067458152770996
Epoch 67 train loss: 0.8451, eval loss 1.504640817642212
Epoch 68 train loss: 0.7743, eval loss 1.5024104118347168
Epoch 69 train loss: 0.8280, eval loss 1.501865267753601
Epoch 70 train loss: 0.8009, eval loss 1.5019536018371582
Epoch 71 train loss: 0.7806, eval loss 1.499906301498413
Epoch 72 train loss: 0.8117, eval loss 1.4979299306869507
Epoch 73 train loss: 0.8337, eval loss 1.497624158859253
Epoch 74 train loss: 0.7572, eval loss 1.4954668283462524
Epoch 75 train loss: 0.8310, eval loss 1.4950309991836548
Epoch 76 train loss: 0.7768, eval loss 1.4935851097106934
Epoch 77 train loss: 0.8196, eval loss 1.4915530681610107
Epoch 78 train loss: 0.8131, eval loss 1.4899450540542603
Epoch 79 train loss: 0.8223, eval loss 1.4894345998764038
Epoch 80 train loss: 0.8116, eval loss 1.4883416891098022
Epoch 81 train loss: 0.8424, eval loss 1.4874294996261597
Epoch 82 train loss: 0.8480, eval loss 1.4874602556228638
Epoch 83 train loss: 0.8075, eval loss 1.4867440462112427
Epoch 84 train loss: 0.7502, eval loss 1.4845556020736694
Epoch 85 train loss: 0.7940, eval loss 1.483200192451477
Epoch 86 train loss: 0.7639, eval loss 1.48388671875
Epoch 87 train loss: 0.8217, eval loss 1.4814565181732178
Epoch 88 train loss: 0.7009, eval loss 1.480507493019104
Epoch 89 train loss: 0.8209, eval loss 1.479318380355835
Epoch 90 train loss: 0.6732, eval loss 1.4777313470840454
Epoch 91 train loss: 0.7583, eval loss 1.4778268337249756
Epoch 92 train loss: 0.8192, eval loss 1.4775596857070923
Epoch 93 train loss: 0.8224, eval loss 1.4763755798339844
Epoch 94 train loss: 0.8078, eval loss 1.4750958681106567
Epoch 95 train loss: 0.7671, eval loss 1.474909782409668
Epoch 96 train loss: 0.7166, eval loss 1.4740639925003052
Epoch 97 train loss: 0.7820, eval loss 1.4729282855987549
Epoch 98 train loss: 0.7783, eval loss 1.4722797870635986
Epoch 99 train loss: 0.7420, eval loss 1.4715913534164429
Epoch 100 train loss: 0.7429, eval loss 1.4709047079086304
Epoch 101 train loss: 0.7298, eval loss 1.4707202911376953
Epoch 102 train loss: 0.7774, eval loss 1.4690487384796143
Epoch 103 train loss: 0.7205, eval loss 1.4688200950622559
Epoch 104 train loss: 0.7535, eval loss 1.4675041437149048
Epoch 105 train loss: 0.7385, eval loss 1.4682693481445312
Epoch 106 train loss: 0.7233, eval loss 1.4663479328155518
Epoch 107 train loss: 0.7047, eval loss 1.4658589363098145
Epoch 108 train loss: 0.6964, eval loss 1.4655998945236206
Epoch 109 train loss: 0.7396, eval loss 1.4649102687835693
Epoch 110 train loss: 0.7700, eval loss 1.464913010597229
Epoch 111 train loss: 0.7587, eval loss 1.4644416570663452
Epoch 112 train loss: 0.8030, eval loss 1.4640077352523804
Epoch 113 train loss: 0.7320, eval loss 1.4623990058898926
Epoch 114 train loss: 0.7776, eval loss 1.4618926048278809
Epoch 115 train loss: 0.7581, eval loss 1.4620592594146729
Epoch 116 train loss: 0.7337, eval loss 1.4618126153945923
Epoch 117 train loss: 0.7974, eval loss 1.4609804153442383
Epoch 118 train loss: 0.7718, eval loss 1.4605525732040405
Epoch 119 train loss: 0.7774, eval loss 1.4597796201705933
Epoch 120 train loss: 0.7634, eval loss 1.4599337577819824
Epoch 121 train loss: 0.8023, eval loss 1.458981990814209
Epoch 122 train loss: 0.7691, eval loss 1.458969235420227
Epoch 123 train loss: 0.7929, eval loss 1.458040475845337
Epoch 124 train loss: 0.7418, eval loss 1.4580806493759155
Epoch 125 train loss: 0.7363, eval loss 1.4584780931472778
Epoch 126 train loss: 0.8135, eval loss 1.457403302192688
Epoch 127 train loss: 0.7631, eval loss 1.4575867652893066
Epoch 128 train loss: 0.7879, eval loss 1.4568244218826294
Epoch 129 train loss: 0.8106, eval loss 1.4560903310775757
Epoch 130 train loss: 0.7520, eval loss 1.4564034938812256
Epoch 131 train loss: 0.7963, eval loss 1.4553470611572266
Epoch 132 train loss: 0.7270, eval loss 1.455986738204956
Epoch 133 train loss: 0.7719, eval loss 1.4545923471450806
Epoch 134 train loss: 0.7833, eval loss 1.454858660697937
Epoch 135 train loss: 0.7916, eval loss 1.4540908336639404
Epoch 136 train loss: 0.7396, eval loss 1.4543683528900146
Epoch 137 train loss: 0.8346, eval loss 1.4542196989059448
Epoch 138 train loss: 0.7001, eval loss 1.4527662992477417
Epoch 139 train loss: 0.7641, eval loss 1.4535391330718994
Epoch 140 train loss: 0.6907, eval loss 1.4530161619186401
Epoch 141 train loss: 0.7354, eval loss 1.4521688222885132
Epoch 142 train loss: 0.7159, eval loss 1.4522861242294312
Epoch 143 train loss: 0.7557, eval loss 1.452348232269287
Epoch 144 train loss: 0.7192, eval loss 1.4519410133361816
Epoch 145 train loss: 0.7089, eval loss 1.4521061182022095
Epoch 146 train loss: 0.7198, eval loss 1.4519469738006592
Epoch 147 train loss: 0.7803, eval loss 1.4517778158187866
Epoch 148 train loss: 0.7003, eval loss 1.4510561227798462
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:50:13,017] Trial 26 finished with value: 1.4506356716156006 and parameters: {&#39;hidden_layers_size&#39;: 70, &#39;dropout_p&#39;: 0.42804938275340926, &#39;learning_rate&#39;: 1.3969789722062875e-05, &#39;batch_size&#39;: 205, &#39;l2_reg&#39;: 2.5361931652833666e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.8825, eval loss 1.4506356716156006
Epoch 0 train loss: 1.4238, eval loss 1.7925430536270142
Epoch 1 train loss: 1.6231, eval loss 1.7941477298736572
Epoch 2 train loss: 1.5431, eval loss 1.7907640933990479
Epoch 3 train loss: 1.5265, eval loss 1.7889207601547241
Epoch 4 train loss: 1.5184, eval loss 1.7869890928268433
Epoch 5 train loss: 1.3531, eval loss 1.787232756614685
Epoch 6 train loss: 1.2907, eval loss 1.7830820083618164
Epoch 7 train loss: 1.5182, eval loss 1.7821002006530762
Epoch 8 train loss: 1.7434, eval loss 1.7828713655471802
Epoch 9 train loss: 1.3894, eval loss 1.7801830768585205
Epoch 10 train loss: 1.4357, eval loss 1.7767705917358398
Epoch 11 train loss: 1.3385, eval loss 1.7765315771102905
Epoch 12 train loss: 1.4539, eval loss 1.7717212438583374
Epoch 13 train loss: 1.4663, eval loss 1.7755857706069946
Epoch 14 train loss: 1.5224, eval loss 1.7728086709976196
Epoch 15 train loss: 1.5189, eval loss 1.7702667713165283
Epoch 16 train loss: 1.3087, eval loss 1.7658336162567139
Epoch 17 train loss: 1.7367, eval loss 1.767400860786438
Epoch 18 train loss: 1.3278, eval loss 1.7651370763778687
Epoch 19 train loss: 1.2595, eval loss 1.7632144689559937
Epoch 20 train loss: 1.2052, eval loss 1.7627888917922974
Epoch 21 train loss: 1.3822, eval loss 1.760340929031372
Epoch 22 train loss: 1.3325, eval loss 1.7556962966918945
Epoch 23 train loss: 1.3659, eval loss 1.7567975521087646
Epoch 24 train loss: 1.5168, eval loss 1.7556074857711792
Epoch 25 train loss: 1.4017, eval loss 1.7552751302719116
Epoch 26 train loss: 1.3453, eval loss 1.7476656436920166
Epoch 27 train loss: 1.3693, eval loss 1.7510406970977783
Epoch 28 train loss: 1.3084, eval loss 1.7506440877914429
Epoch 29 train loss: 1.3479, eval loss 1.747901201248169
Epoch 30 train loss: 1.2098, eval loss 1.746457576751709
Epoch 31 train loss: 1.2526, eval loss 1.7445436716079712
Epoch 32 train loss: 1.2949, eval loss 1.7418891191482544
Epoch 33 train loss: 1.4211, eval loss 1.742099642753601
Epoch 34 train loss: 1.3385, eval loss 1.7368946075439453
Epoch 35 train loss: 1.3955, eval loss 1.739033579826355
Epoch 36 train loss: 1.5235, eval loss 1.7394484281539917
Epoch 37 train loss: 1.6306, eval loss 1.7371959686279297
Epoch 38 train loss: 1.0037, eval loss 1.7335045337677002
Epoch 39 train loss: 1.2155, eval loss 1.7324401140213013
Epoch 40 train loss: 1.2647, eval loss 1.7308237552642822
Epoch 41 train loss: 1.2536, eval loss 1.7293285131454468
Epoch 42 train loss: 1.1234, eval loss 1.725339412689209
Epoch 43 train loss: 1.0754, eval loss 1.7296597957611084
Epoch 44 train loss: 1.0532, eval loss 1.7256782054901123
Epoch 45 train loss: 1.1352, eval loss 1.7237306833267212
Epoch 46 train loss: 1.0726, eval loss 1.723077416419983
Epoch 47 train loss: 1.0636, eval loss 1.7216877937316895
Epoch 48 train loss: 1.1499, eval loss 1.7190266847610474
Epoch 49 train loss: 1.0550, eval loss 1.7214854955673218
Epoch 50 train loss: 1.0914, eval loss 1.7180616855621338
Epoch 51 train loss: 1.2194, eval loss 1.715587854385376
Epoch 52 train loss: 1.0116, eval loss 1.713850498199463
Epoch 53 train loss: 1.3455, eval loss 1.7144118547439575
Epoch 54 train loss: 1.0371, eval loss 1.712223768234253
Epoch 55 train loss: 1.0797, eval loss 1.7098263502120972
Epoch 56 train loss: 1.3096, eval loss 1.7128369808197021
Epoch 57 train loss: 1.1691, eval loss 1.7116947174072266
Epoch 58 train loss: 1.2424, eval loss 1.7094162702560425
Epoch 59 train loss: 0.9709, eval loss 1.7075166702270508
Epoch 60 train loss: 1.2234, eval loss 1.7094801664352417
Epoch 61 train loss: 0.8534, eval loss 1.705705165863037
Epoch 62 train loss: 0.9874, eval loss 1.7008819580078125
Epoch 63 train loss: 1.0143, eval loss 1.702789068222046
Epoch 64 train loss: 0.9594, eval loss 1.7010200023651123
Epoch 65 train loss: 1.2975, eval loss 1.6988290548324585
Epoch 66 train loss: 1.1602, eval loss 1.6995986700057983
Epoch 67 train loss: 1.0784, eval loss 1.6947722434997559
Epoch 68 train loss: 1.1572, eval loss 1.696531057357788
Epoch 69 train loss: 1.0795, eval loss 1.6976978778839111
Epoch 70 train loss: 1.0304, eval loss 1.6936553716659546
Epoch 71 train loss: 0.9637, eval loss 1.691908597946167
Epoch 72 train loss: 1.3529, eval loss 1.6940281391143799
Epoch 73 train loss: 1.0379, eval loss 1.6879061460494995
Epoch 74 train loss: 1.0423, eval loss 1.6877057552337646
Epoch 75 train loss: 1.0047, eval loss 1.686481237411499
Epoch 76 train loss: 1.2064, eval loss 1.684445858001709
Epoch 77 train loss: 1.0681, eval loss 1.684767484664917
Epoch 78 train loss: 1.0374, eval loss 1.6853569746017456
Epoch 79 train loss: 1.0572, eval loss 1.6820309162139893
Epoch 80 train loss: 1.0072, eval loss 1.6822019815444946
Epoch 81 train loss: 0.9545, eval loss 1.681026816368103
Epoch 82 train loss: 0.8899, eval loss 1.6807941198349
Epoch 83 train loss: 1.0378, eval loss 1.680550456047058
Epoch 84 train loss: 0.9987, eval loss 1.6769198179244995
Epoch 85 train loss: 0.9613, eval loss 1.675295352935791
Epoch 86 train loss: 0.9952, eval loss 1.675821304321289
Epoch 87 train loss: 0.9709, eval loss 1.6764569282531738
Epoch 88 train loss: 1.1050, eval loss 1.6726864576339722
Epoch 89 train loss: 0.8423, eval loss 1.6694382429122925
Epoch 90 train loss: 0.9571, eval loss 1.6704336404800415
Epoch 91 train loss: 0.9852, eval loss 1.6704747676849365
Epoch 92 train loss: 1.1214, eval loss 1.6687320470809937
Epoch 93 train loss: 0.8842, eval loss 1.6656135320663452
Epoch 94 train loss: 1.0055, eval loss 1.6700767278671265
Epoch 95 train loss: 0.8262, eval loss 1.6628854274749756
Epoch 96 train loss: 0.8806, eval loss 1.6665871143341064
Epoch 97 train loss: 1.1685, eval loss 1.6636501550674438
Epoch 98 train loss: 0.8681, eval loss 1.661995768547058
Epoch 99 train loss: 0.9376, eval loss 1.66042959690094
Epoch 100 train loss: 1.0714, eval loss 1.6595720052719116
Epoch 101 train loss: 0.9268, eval loss 1.664055347442627
Epoch 102 train loss: 1.2701, eval loss 1.6570336818695068
Epoch 103 train loss: 0.8087, eval loss 1.6559841632843018
Epoch 104 train loss: 1.0890, eval loss 1.653850793838501
Epoch 105 train loss: 0.9001, eval loss 1.6585030555725098
Epoch 106 train loss: 0.9351, eval loss 1.6568119525909424
Epoch 107 train loss: 0.9202, eval loss 1.6509578227996826
Epoch 108 train loss: 0.8804, eval loss 1.6497172117233276
Epoch 109 train loss: 0.9663, eval loss 1.6500909328460693
Epoch 110 train loss: 1.0451, eval loss 1.6490586996078491
Epoch 111 train loss: 1.1574, eval loss 1.6485852003097534
Epoch 112 train loss: 0.9106, eval loss 1.6507855653762817
Epoch 113 train loss: 0.8148, eval loss 1.647566318511963
Epoch 114 train loss: 1.0575, eval loss 1.650091290473938
Epoch 115 train loss: 0.8042, eval loss 1.647019863128662
Epoch 116 train loss: 0.8228, eval loss 1.647443175315857
Epoch 117 train loss: 0.8086, eval loss 1.642776608467102
Epoch 118 train loss: 0.9587, eval loss 1.6401976346969604
Epoch 119 train loss: 0.8008, eval loss 1.644758939743042
Epoch 120 train loss: 0.5873, eval loss 1.6412291526794434
Epoch 121 train loss: 0.9439, eval loss 1.6396543979644775
Epoch 122 train loss: 0.8439, eval loss 1.6393667459487915
Epoch 123 train loss: 0.8527, eval loss 1.6350082159042358
Epoch 124 train loss: 0.9510, eval loss 1.6387916803359985
Epoch 125 train loss: 0.9285, eval loss 1.6362468004226685
Epoch 126 train loss: 0.9336, eval loss 1.6358397006988525
Epoch 127 train loss: 0.9024, eval loss 1.6344331502914429
Epoch 128 train loss: 0.7868, eval loss 1.632407784461975
Epoch 129 train loss: 0.6697, eval loss 1.6305371522903442
Epoch 130 train loss: 0.9122, eval loss 1.6325184106826782
Epoch 131 train loss: 1.0275, eval loss 1.63124418258667
Epoch 132 train loss: 0.9416, eval loss 1.63263738155365
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:51:14,398] Trial 27 finished with value: 1.6305371522903442 and parameters: {&#39;hidden_layers_size&#39;: 60, &#39;dropout_p&#39;: 0.47982771184794165, &#39;learning_rate&#39;: 3.577955374815888e-06, &#39;batch_size&#39;: 234, &#39;l2_reg&#39;: 5.919527564908214e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.2771, eval loss 1.7177616357803345
Epoch 1 train loss: 1.2727, eval loss 1.7166469097137451
Epoch 2 train loss: 1.3116, eval loss 1.7170028686523438
Epoch 3 train loss: 1.2433, eval loss 1.7163504362106323
Epoch 4 train loss: 1.3255, eval loss 1.7139432430267334
Epoch 5 train loss: 1.2617, eval loss 1.7126247882843018
Epoch 6 train loss: 1.2948, eval loss 1.712152123451233
Epoch 7 train loss: 1.2256, eval loss 1.7103025913238525
Epoch 8 train loss: 1.3471, eval loss 1.710056185722351
Epoch 9 train loss: 1.2161, eval loss 1.7073607444763184
Epoch 10 train loss: 1.2790, eval loss 1.706572413444519
Epoch 11 train loss: 1.2451, eval loss 1.7064988613128662
Epoch 12 train loss: 1.2516, eval loss 1.7061971426010132
Epoch 13 train loss: 1.2541, eval loss 1.70404851436615
Epoch 14 train loss: 1.2387, eval loss 1.7046082019805908
Epoch 15 train loss: 1.3183, eval loss 1.702425479888916
Epoch 16 train loss: 1.1571, eval loss 1.7015222311019897
Epoch 17 train loss: 1.2398, eval loss 1.700684666633606
Epoch 18 train loss: 1.2280, eval loss 1.6998952627182007
Epoch 19 train loss: 1.2629, eval loss 1.6990891695022583
Epoch 20 train loss: 1.2060, eval loss 1.6983211040496826
Epoch 21 train loss: 1.2388, eval loss 1.6983401775360107
Epoch 22 train loss: 1.2733, eval loss 1.6957361698150635
Epoch 23 train loss: 1.1591, eval loss 1.6958260536193848
Epoch 24 train loss: 1.1742, eval loss 1.6941192150115967
Epoch 25 train loss: 1.2390, eval loss 1.6929612159729004
Epoch 26 train loss: 1.2159, eval loss 1.6924934387207031
Epoch 27 train loss: 1.2082, eval loss 1.6918725967407227
Epoch 28 train loss: 1.2104, eval loss 1.689263105392456
Epoch 29 train loss: 1.1811, eval loss 1.6894217729568481
Epoch 30 train loss: 1.1906, eval loss 1.6880894899368286
Epoch 31 train loss: 1.1780, eval loss 1.6877148151397705
Epoch 32 train loss: 1.1377, eval loss 1.687106966972351
Epoch 33 train loss: 1.2287, eval loss 1.6866148710250854
Epoch 34 train loss: 1.1846, eval loss 1.6853336095809937
Epoch 35 train loss: 1.2078, eval loss 1.6832643747329712
Epoch 36 train loss: 1.1729, eval loss 1.6835172176361084
Epoch 37 train loss: 1.1940, eval loss 1.6811635494232178
Epoch 38 train loss: 1.1998, eval loss 1.681318759918213
Epoch 39 train loss: 1.1896, eval loss 1.6808075904846191
Epoch 40 train loss: 1.2467, eval loss 1.6807448863983154
Epoch 41 train loss: 1.1099, eval loss 1.6778382062911987
Epoch 42 train loss: 1.2199, eval loss 1.6794670820236206
Epoch 43 train loss: 1.1164, eval loss 1.6775798797607422
Epoch 44 train loss: 1.1155, eval loss 1.6743510961532593
Epoch 45 train loss: 1.1643, eval loss 1.6758546829223633
Epoch 46 train loss: 1.1153, eval loss 1.6739859580993652
Epoch 47 train loss: 1.1499, eval loss 1.6734652519226074
Epoch 48 train loss: 1.1596, eval loss 1.67233145236969
Epoch 49 train loss: 1.1586, eval loss 1.6692924499511719
Epoch 50 train loss: 1.1515, eval loss 1.6710624694824219
Epoch 51 train loss: 1.0702, eval loss 1.6706926822662354
Epoch 52 train loss: 1.1945, eval loss 1.6685824394226074
Epoch 53 train loss: 1.0958, eval loss 1.6692296266555786
Epoch 54 train loss: 1.1125, eval loss 1.6666330099105835
Epoch 55 train loss: 1.1139, eval loss 1.667123794555664
Epoch 56 train loss: 1.1637, eval loss 1.666227102279663
Epoch 57 train loss: 1.1423, eval loss 1.6661243438720703
Epoch 58 train loss: 1.1571, eval loss 1.6645396947860718
Epoch 59 train loss: 1.1024, eval loss 1.6638243198394775
Epoch 60 train loss: 1.0895, eval loss 1.6610870361328125
Epoch 61 train loss: 1.1144, eval loss 1.6612457036972046
Epoch 62 train loss: 1.1357, eval loss 1.6598668098449707
Epoch 63 train loss: 1.1237, eval loss 1.6580595970153809
Epoch 64 train loss: 1.0939, eval loss 1.6568692922592163
Epoch 65 train loss: 1.1253, eval loss 1.6585850715637207
Epoch 66 train loss: 1.1360, eval loss 1.6561980247497559
Epoch 67 train loss: 1.1841, eval loss 1.6556106805801392
Epoch 68 train loss: 1.1643, eval loss 1.6553759574890137
Epoch 69 train loss: 1.0860, eval loss 1.654436707496643
Epoch 70 train loss: 1.1021, eval loss 1.6535718441009521
Epoch 71 train loss: 1.1479, eval loss 1.6535155773162842
Epoch 72 train loss: 1.1760, eval loss 1.6522347927093506
Epoch 73 train loss: 1.0649, eval loss 1.6505930423736572
Epoch 74 train loss: 1.1152, eval loss 1.651138186454773
Epoch 75 train loss: 1.0959, eval loss 1.6494007110595703
Epoch 76 train loss: 1.0789, eval loss 1.6503111124038696
Epoch 77 train loss: 1.0929, eval loss 1.6485505104064941
Epoch 78 train loss: 1.1176, eval loss 1.6467878818511963
Epoch 79 train loss: 1.1106, eval loss 1.6457704305648804
Epoch 80 train loss: 1.1978, eval loss 1.644677996635437
Epoch 81 train loss: 1.0446, eval loss 1.6457128524780273
Epoch 82 train loss: 1.1154, eval loss 1.6454312801361084
Epoch 83 train loss: 1.0766, eval loss 1.6441494226455688
Epoch 84 train loss: 1.0957, eval loss 1.6423832178115845
Epoch 85 train loss: 1.0130, eval loss 1.6425695419311523
Epoch 86 train loss: 1.1023, eval loss 1.6410926580429077
Epoch 87 train loss: 1.0817, eval loss 1.6404743194580078
Epoch 88 train loss: 1.0734, eval loss 1.6396223306655884
Epoch 89 train loss: 1.0540, eval loss 1.637776494026184
Epoch 90 train loss: 1.0898, eval loss 1.638036847114563
Epoch 91 train loss: 1.0651, eval loss 1.6386263370513916
Epoch 92 train loss: 1.0394, eval loss 1.6384366750717163
Epoch 93 train loss: 1.0342, eval loss 1.63717782497406
Epoch 94 train loss: 1.0002, eval loss 1.6360244750976562
Epoch 95 train loss: 1.0154, eval loss 1.6348812580108643
Epoch 96 train loss: 1.0887, eval loss 1.6344292163848877
Epoch 97 train loss: 1.0722, eval loss 1.6338304281234741
Epoch 98 train loss: 1.0575, eval loss 1.632643461227417
Epoch 99 train loss: 1.0414, eval loss 1.6325324773788452
Epoch 100 train loss: 1.0686, eval loss 1.6321684122085571
Epoch 101 train loss: 1.0722, eval loss 1.6289376020431519
Epoch 102 train loss: 1.0574, eval loss 1.6302021741867065
Epoch 103 train loss: 1.0901, eval loss 1.6288012266159058
Epoch 104 train loss: 1.0217, eval loss 1.628291130065918
Epoch 105 train loss: 1.0469, eval loss 1.6270766258239746
Epoch 106 train loss: 0.9753, eval loss 1.6274539232254028
Epoch 107 train loss: 1.0824, eval loss 1.6255700588226318
Epoch 108 train loss: 1.0050, eval loss 1.6256121397018433
Epoch 109 train loss: 1.0235, eval loss 1.624563217163086
Epoch 110 train loss: 1.0282, eval loss 1.624458909034729
Epoch 111 train loss: 1.0171, eval loss 1.6232131719589233
Epoch 112 train loss: 1.0827, eval loss 1.6236169338226318
Epoch 113 train loss: 1.0147, eval loss 1.6225343942642212
Epoch 114 train loss: 1.0164, eval loss 1.6223978996276855
Epoch 115 train loss: 1.0684, eval loss 1.6211540699005127
Epoch 116 train loss: 1.0513, eval loss 1.621181607246399
Epoch 117 train loss: 0.9563, eval loss 1.6189309358596802
Epoch 118 train loss: 1.0013, eval loss 1.6193069219589233
Epoch 119 train loss: 1.0530, eval loss 1.61900794506073
Epoch 120 train loss: 1.0331, eval loss 1.617369532585144
Epoch 121 train loss: 1.0075, eval loss 1.616456151008606
Epoch 122 train loss: 0.9864, eval loss 1.6159371137619019
Epoch 123 train loss: 0.9527, eval loss 1.6169320344924927
Epoch 124 train loss: 1.1092, eval loss 1.6142083406448364
Epoch 125 train loss: 1.0263, eval loss 1.6160914897918701
Epoch 126 train loss: 0.9598, eval loss 1.6136500835418701
Epoch 127 train loss: 0.9646, eval loss 1.6139463186264038
Epoch 128 train loss: 0.9702, eval loss 1.6133766174316406
Epoch 129 train loss: 0.9578, eval loss 1.6140315532684326
Epoch 130 train loss: 0.9898, eval loss 1.6126761436462402
Epoch 131 train loss: 0.9284, eval loss 1.6108558177947998
Epoch 132 train loss: 0.9843, eval loss 1.6111011505126953
Epoch 133 train loss: 1.0138, eval loss 1.6105473041534424
Epoch 134 train loss: 1.0091, eval loss 1.6108837127685547
Epoch 135 train loss: 0.9681, eval loss 1.6099026203155518
Epoch 136 train loss: 0.9550, eval loss 1.608352541923523
Epoch 137 train loss: 0.9962, eval loss 1.606992244720459
Epoch 138 train loss: 0.9900, eval loss 1.6064426898956299
Epoch 139 train loss: 0.9941, eval loss 1.6057251691818237
Epoch 140 train loss: 1.0032, eval loss 1.6059894561767578
Epoch 141 train loss: 1.0591, eval loss 1.6057674884796143
Epoch 142 train loss: 0.9538, eval loss 1.6053776741027832
Epoch 143 train loss: 0.9288, eval loss 1.6029366254806519
Epoch 144 train loss: 1.0253, eval loss 1.6035431623458862
Epoch 145 train loss: 0.9734, eval loss 1.6028828620910645
Epoch 146 train loss: 0.9913, eval loss 1.603346586227417
Epoch 147 train loss: 0.9742, eval loss 1.6015342473983765
Epoch 148 train loss: 0.9591, eval loss 1.600983738899231
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:52:36,359] Trial 28 finished with value: 1.6001883745193481 and parameters: {&#39;hidden_layers_size&#39;: 79, &#39;dropout_p&#39;: 0.4463536527276778, &#39;learning_rate&#39;: 1.4766328684709177e-06, &#39;batch_size&#39;: 170, &#39;l2_reg&#39;: 1.842529501485208e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.9733, eval loss 1.6001883745193481
Epoch 0 train loss: 1.5046, eval loss 1.757185459136963
Epoch 1 train loss: 1.4353, eval loss 1.7334235906600952
Epoch 2 train loss: 1.2461, eval loss 1.713902473449707
Epoch 3 train loss: 1.3236, eval loss 1.6958099603652954
Epoch 4 train loss: 1.3059, eval loss 1.6798927783966064
Epoch 5 train loss: 1.2648, eval loss 1.6658111810684204
Epoch 6 train loss: 1.1690, eval loss 1.654659628868103
Epoch 7 train loss: 1.1958, eval loss 1.643080472946167
Epoch 8 train loss: 1.1282, eval loss 1.6330649852752686
Epoch 9 train loss: 1.1166, eval loss 1.6222590208053589
Epoch 10 train loss: 1.0446, eval loss 1.6160861253738403
Epoch 11 train loss: 1.0212, eval loss 1.6068029403686523
Epoch 12 train loss: 1.0978, eval loss 1.6002264022827148
Epoch 13 train loss: 1.1367, eval loss 1.5936744213104248
Epoch 14 train loss: 0.9698, eval loss 1.5877196788787842
Epoch 15 train loss: 0.9761, eval loss 1.5817508697509766
Epoch 16 train loss: 1.0350, eval loss 1.5782742500305176
Epoch 17 train loss: 0.9178, eval loss 1.569973111152649
Epoch 18 train loss: 0.8807, eval loss 1.565456509590149
Epoch 19 train loss: 0.9856, eval loss 1.5605010986328125
Epoch 20 train loss: 0.9145, eval loss 1.5571011304855347
Epoch 21 train loss: 0.8481, eval loss 1.5519641637802124
Epoch 22 train loss: 0.9150, eval loss 1.5463058948516846
Epoch 23 train loss: 0.7977, eval loss 1.5431954860687256
Epoch 24 train loss: 0.8868, eval loss 1.541045069694519
Epoch 25 train loss: 0.8199, eval loss 1.5372790098190308
Epoch 26 train loss: 0.8664, eval loss 1.5336061716079712
Epoch 27 train loss: 0.8720, eval loss 1.530259609222412
Epoch 28 train loss: 0.7905, eval loss 1.5285718441009521
Epoch 29 train loss: 0.7954, eval loss 1.5253220796585083
Epoch 30 train loss: 0.7846, eval loss 1.5229911804199219
Epoch 31 train loss: 0.7456, eval loss 1.5190081596374512
Epoch 32 train loss: 0.8070, eval loss 1.5173453092575073
Epoch 33 train loss: 0.8734, eval loss 1.5127009153366089
Epoch 34 train loss: 0.7980, eval loss 1.5116593837738037
Epoch 35 train loss: 0.7366, eval loss 1.5084631443023682
Epoch 36 train loss: 0.8237, eval loss 1.5063809156417847
Epoch 37 train loss: 0.7160, eval loss 1.5045385360717773
Epoch 38 train loss: 0.7513, eval loss 1.5012791156768799
Epoch 39 train loss: 0.7343, eval loss 1.4994232654571533
Epoch 40 train loss: 0.7310, eval loss 1.4973585605621338
Epoch 41 train loss: 0.6313, eval loss 1.4954421520233154
Epoch 42 train loss: 0.7952, eval loss 1.4939321279525757
Epoch 43 train loss: 0.8009, eval loss 1.4916634559631348
Epoch 44 train loss: 0.7178, eval loss 1.4893840551376343
Epoch 45 train loss: 0.7128, eval loss 1.4893406629562378
Epoch 46 train loss: 0.7524, eval loss 1.487283706665039
Epoch 47 train loss: 0.6829, eval loss 1.4854373931884766
Epoch 48 train loss: 0.7493, eval loss 1.4827449321746826
Epoch 49 train loss: 0.6781, eval loss 1.4826207160949707
Epoch 50 train loss: 0.7652, eval loss 1.4805214405059814
Epoch 51 train loss: 0.6069, eval loss 1.4788453578948975
Epoch 52 train loss: 0.7393, eval loss 1.4781004190444946
Epoch 53 train loss: 0.6154, eval loss 1.476700782775879
Epoch 54 train loss: 0.6576, eval loss 1.4750688076019287
Epoch 55 train loss: 0.7518, eval loss 1.4739340543746948
Epoch 56 train loss: 0.7647, eval loss 1.4726130962371826
Epoch 57 train loss: 0.7259, eval loss 1.4723575115203857
Epoch 58 train loss: 0.5769, eval loss 1.4709956645965576
Epoch 59 train loss: 0.6968, eval loss 1.4692610502243042
Epoch 60 train loss: 0.6397, eval loss 1.4677175283432007
Epoch 61 train loss: 0.6731, eval loss 1.4684311151504517
Epoch 62 train loss: 0.6247, eval loss 1.466898798942566
Epoch 63 train loss: 0.6862, eval loss 1.4649732112884521
Epoch 64 train loss: 0.6638, eval loss 1.465075135231018
Epoch 65 train loss: 0.6404, eval loss 1.4633049964904785
Epoch 66 train loss: 0.6727, eval loss 1.4633158445358276
Epoch 67 train loss: 0.6189, eval loss 1.46257483959198
Epoch 68 train loss: 0.7569, eval loss 1.4618885517120361
Epoch 69 train loss: 0.6690, eval loss 1.4604119062423706
Epoch 70 train loss: 0.6602, eval loss 1.4597938060760498
Epoch 71 train loss: 0.6291, eval loss 1.459557056427002
Epoch 72 train loss: 0.5797, eval loss 1.4584910869598389
Epoch 73 train loss: 0.5734, eval loss 1.4583011865615845
Epoch 74 train loss: 0.6882, eval loss 1.4577932357788086
Epoch 75 train loss: 0.7203, eval loss 1.4564979076385498
Epoch 76 train loss: 0.5782, eval loss 1.455932378768921
Epoch 77 train loss: 0.5625, eval loss 1.4556807279586792
Epoch 78 train loss: 0.7000, eval loss 1.454479455947876
Epoch 79 train loss: 0.6484, eval loss 1.454861044883728
Epoch 80 train loss: 0.5771, eval loss 1.4536213874816895
Epoch 81 train loss: 0.7419, eval loss 1.4534566402435303
Epoch 82 train loss: 0.6608, eval loss 1.4532020092010498
Epoch 83 train loss: 0.7770, eval loss 1.4523124694824219
Epoch 84 train loss: 0.7116, eval loss 1.4512866735458374
Epoch 85 train loss: 0.6341, eval loss 1.4514683485031128
Epoch 86 train loss: 0.5333, eval loss 1.451780915260315
Epoch 87 train loss: 0.6819, eval loss 1.4498957395553589
Epoch 88 train loss: 0.6400, eval loss 1.4503581523895264
Epoch 89 train loss: 0.6702, eval loss 1.4494134187698364
Epoch 90 train loss: 0.5546, eval loss 1.4493716955184937
Epoch 91 train loss: 0.5973, eval loss 1.4492030143737793
Epoch 92 train loss: 0.6372, eval loss 1.4482121467590332
Epoch 93 train loss: 0.6856, eval loss 1.4479413032531738
Epoch 94 train loss: 0.5734, eval loss 1.4476685523986816
Epoch 95 train loss: 0.6388, eval loss 1.4472436904907227
Epoch 96 train loss: 0.5603, eval loss 1.4478610754013062
Epoch 97 train loss: 0.7282, eval loss 1.4460885524749756
Epoch 98 train loss: 0.6021, eval loss 1.4458329677581787
Epoch 99 train loss: 0.7133, eval loss 1.4455492496490479
Epoch 100 train loss: 0.5221, eval loss 1.4453943967819214
Epoch 101 train loss: 0.6059, eval loss 1.444701910018921
Epoch 102 train loss: 0.5647, eval loss 1.4446789026260376
Epoch 103 train loss: 0.5873, eval loss 1.4450608491897583
Epoch 104 train loss: 0.6323, eval loss 1.444161057472229
Epoch 105 train loss: 0.6590, eval loss 1.4445639848709106
Epoch 106 train loss: 0.5841, eval loss 1.4447877407073975
Epoch 107 train loss: 0.5677, eval loss 1.4438536167144775
Epoch 108 train loss: 0.6581, eval loss 1.4445891380310059
Epoch 109 train loss: 0.6711, eval loss 1.4437711238861084
Epoch 110 train loss: 0.6398, eval loss 1.443689227104187
Epoch 111 train loss: 0.7011, eval loss 1.4432127475738525
Epoch 112 train loss: 0.5778, eval loss 1.4422134160995483
Epoch 113 train loss: 0.5436, eval loss 1.4419505596160889
Epoch 114 train loss: 0.5903, eval loss 1.442033052444458
Epoch 115 train loss: 0.5682, eval loss 1.442536473274231
Epoch 116 train loss: 0.5565, eval loss 1.4421452283859253
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:53:37,256] Trial 29 finished with value: 1.4419505596160889 and parameters: {&#39;hidden_layers_size&#39;: 162, &#39;dropout_p&#39;: 0.38057582115731, &#39;learning_rate&#39;: 1.806728087577791e-05, &#39;batch_size&#39;: 281, &#39;l2_reg&#39;: 1.0012225147470624e-05}. Best is trial 1 with value: 1.803401231765747.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[165]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trial_normal</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span>

<span class="n">trial_normal</span><span class="o">.</span><span class="n">params</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[165]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;hidden_layers_size&#39;: 87,
 &#39;dropout_p&#39;: 0.489907983890005,
 &#39;learning_rate&#39;: 1.5461728272636294e-06,
 &#39;batch_size&#39;: 217,
 &#39;l2_reg&#39;: 3.202440992612983e-05}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[166]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_model_stats</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">OptimizedMLP</span><span class="p">(</span>
        <span class="n">input_size</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
        <span class="n">dropout_p</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">'dropout_p'</span><span class="p">],</span>
        <span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">'hidden_layers_size'</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">'learning_rate'</span><span class="p">]</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span>

    <span class="n">l2_reg</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">'l2_reg'</span><span class="p">]</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
        <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> 
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">l2_reg</span>
    <span class="p">)</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="n">compute_class_weight</span><span class="p">(</span>
        <span class="s2">"balanced"</span><span class="p">,</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
    <span class="p">)</span>

    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weights</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">best_model</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">best_threshold</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[167]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_normal</span><span class="p">,</span> <span class="n">test_metrics</span> <span class="o">=</span> <span class="n">get_model_stats</span><span class="p">(</span><span class="n">trial_normal</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"===================================="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'AUROC'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"F1: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'precision'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Recall: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'recall'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4518, eval loss 1.7525720596313477
Epoch 1 train loss: 1.7764, eval loss 1.7541908025741577
Epoch 2 train loss: 1.7850, eval loss 1.749670147895813
Epoch 3 train loss: 1.4623, eval loss 1.7484052181243896
Epoch 4 train loss: 1.8020, eval loss 1.748795509338379
Epoch 5 train loss: 1.6802, eval loss 1.7490952014923096
Epoch 6 train loss: 1.6459, eval loss 1.7474589347839355
Epoch 7 train loss: 1.2107, eval loss 1.7454420328140259
Epoch 8 train loss: 1.3921, eval loss 1.746488332748413
Epoch 9 train loss: 1.3181, eval loss 1.742182970046997
Epoch 10 train loss: 1.9769, eval loss 1.743636965751648
Epoch 11 train loss: 1.6915, eval loss 1.7435826063156128
Epoch 12 train loss: 1.1238, eval loss 1.7427477836608887
Epoch 13 train loss: 1.2819, eval loss 1.7392184734344482
Epoch 14 train loss: 1.5363, eval loss 1.7394280433654785
Epoch 15 train loss: 1.3040, eval loss 1.7377707958221436
Epoch 16 train loss: 1.2825, eval loss 1.737252950668335
Epoch 17 train loss: 1.4492, eval loss 1.7370936870574951
Epoch 18 train loss: 1.3899, eval loss 1.733497977256775
Epoch 19 train loss: 1.9849, eval loss 1.7353686094284058
Epoch 20 train loss: 1.2020, eval loss 1.731025218963623
Epoch 21 train loss: 1.7230, eval loss 1.7328964471817017
Epoch 22 train loss: 1.1396, eval loss 1.72922682762146
Epoch 23 train loss: 1.4251, eval loss 1.7294230461120605
Epoch 24 train loss: 1.5417, eval loss 1.729026198387146
Epoch 25 train loss: 1.6641, eval loss 1.7306809425354004
Epoch 26 train loss: 1.4716, eval loss 1.7270632982254028
Epoch 27 train loss: 1.4822, eval loss 1.7261439561843872
Epoch 28 train loss: 1.2754, eval loss 1.7261217832565308
Epoch 29 train loss: 1.0223, eval loss 1.7239199876785278
Epoch 30 train loss: 1.3383, eval loss 1.7220888137817383
Epoch 31 train loss: 1.3297, eval loss 1.7238153219223022
Epoch 32 train loss: 1.3872, eval loss 1.7221040725708008
Epoch 33 train loss: 1.3038, eval loss 1.7226862907409668
Epoch 34 train loss: 1.1561, eval loss 1.7199751138687134
Epoch 35 train loss: 1.3917, eval loss 1.7205065488815308
Epoch 36 train loss: 1.3307, eval loss 1.7149733304977417
Epoch 37 train loss: 1.3505, eval loss 1.7150206565856934
Epoch 38 train loss: 1.0456, eval loss 1.7164850234985352
Epoch 39 train loss: 1.4653, eval loss 1.7165918350219727
Epoch 40 train loss: 1.4769, eval loss 1.7136257886886597
Epoch 41 train loss: 1.1117, eval loss 1.7120558023452759
Epoch 42 train loss: 1.1483, eval loss 1.7106578350067139
Epoch 43 train loss: 1.5297, eval loss 1.7128909826278687
Epoch 44 train loss: 1.5493, eval loss 1.7093160152435303
Epoch 45 train loss: 1.4395, eval loss 1.7085580825805664
Epoch 46 train loss: 1.4953, eval loss 1.706663727760315
Epoch 47 train loss: 1.3664, eval loss 1.7076698541641235
Epoch 48 train loss: 1.2506, eval loss 1.7024974822998047
Epoch 49 train loss: 1.3923, eval loss 1.7047394514083862
Epoch 50 train loss: 1.1503, eval loss 1.7011361122131348
Epoch 51 train loss: 1.3671, eval loss 1.703773021697998
Epoch 52 train loss: 1.3680, eval loss 1.70265793800354
Epoch 53 train loss: 1.3439, eval loss 1.7006916999816895
Epoch 54 train loss: 1.4803, eval loss 1.7009795904159546
Epoch 55 train loss: 1.5888, eval loss 1.7008227109909058
Epoch 56 train loss: 1.1162, eval loss 1.69718337059021
Epoch 57 train loss: 1.3897, eval loss 1.7006639242172241
Epoch 58 train loss: 1.1762, eval loss 1.6981000900268555
Epoch 59 train loss: 1.0789, eval loss 1.6963807344436646
Epoch 60 train loss: 1.2754, eval loss 1.6940255165100098
Epoch 61 train loss: 1.5972, eval loss 1.6935408115386963
Epoch 62 train loss: 1.5478, eval loss 1.690911054611206
Epoch 63 train loss: 0.9506, eval loss 1.6883314847946167
Epoch 64 train loss: 1.4651, eval loss 1.6949313879013062
Epoch 65 train loss: 1.1997, eval loss 1.6894668340682983
Epoch 66 train loss: 1.0516, eval loss 1.690386176109314
====================================
AUROC: 80.45%
F1: 56.22%
Precision: 44.62%
Recall: 75.96%
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[168]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">study_random</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s2">"maximize"</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">())</span>
<span class="n">study_random</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:54:08,564] A new study created in memory with name: no-name-8169d178-11fd-44d6-860e-2f7e6143765b
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.8483, eval loss 1.4294427633285522
Epoch 1 train loss: 0.7080, eval loss 1.4293476343154907
Epoch 2 train loss: 0.7429, eval loss 1.428944706916809
Epoch 3 train loss: 0.6840, eval loss 1.4253966808319092
Epoch 4 train loss: 0.8044, eval loss 1.4266140460968018
Epoch 5 train loss: 0.7936, eval loss 1.426932454109192
Epoch 6 train loss: 0.7518, eval loss 1.4290273189544678
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:54:14,342] Trial 0 finished with value: 1.4253966808319092 and parameters: {&#39;hidden_layers_size&#39;: 150, &#39;dropout_p&#39;: 0.3628296173006377, &#39;learning_rate&#39;: 0.006425345715231554, &#39;batch_size&#39;: 128, &#39;l2_reg&#39;: 0.00010462337567426411}. Best is trial 0 with value: 1.4253966808319092.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.0986, eval loss 1.6443737745285034
Epoch 1 train loss: 0.9132, eval loss 1.5810939073562622
Epoch 2 train loss: 0.8471, eval loss 1.5462111234664917
Epoch 3 train loss: 0.7430, eval loss 1.5210002660751343
Epoch 4 train loss: 0.7164, eval loss 1.5024244785308838
Epoch 5 train loss: 0.6614, eval loss 1.4885109663009644
Epoch 6 train loss: 0.7938, eval loss 1.478353500366211
Epoch 7 train loss: 0.6661, eval loss 1.4710912704467773
Epoch 8 train loss: 0.5395, eval loss 1.4644955396652222
Epoch 9 train loss: 0.5444, eval loss 1.4594765901565552
Epoch 10 train loss: 0.5207, eval loss 1.455345630645752
Epoch 11 train loss: 0.6399, eval loss 1.451279878616333
Epoch 12 train loss: 0.5078, eval loss 1.4484246969223022
Epoch 13 train loss: 0.3864, eval loss 1.447231650352478
Epoch 14 train loss: 0.4575, eval loss 1.444014072418213
Epoch 15 train loss: 0.4260, eval loss 1.4437662363052368
Epoch 16 train loss: 0.4313, eval loss 1.4409680366516113
Epoch 17 train loss: 0.4543, eval loss 1.4395335912704468
Epoch 18 train loss: 0.3838, eval loss 1.43954336643219
Epoch 19 train loss: 0.3797, eval loss 1.4376556873321533
Epoch 20 train loss: 0.4016, eval loss 1.4363725185394287
Epoch 21 train loss: 0.3438, eval loss 1.4360504150390625
Epoch 22 train loss: 0.2681, eval loss 1.435094952583313
Epoch 23 train loss: 0.3685, eval loss 1.4342303276062012
Epoch 24 train loss: 0.2895, eval loss 1.4341962337493896
Epoch 25 train loss: 0.2762, eval loss 1.4327619075775146
Epoch 26 train loss: 0.2687, eval loss 1.4330371618270874
Epoch 27 train loss: 0.3272, eval loss 1.4322603940963745
Epoch 28 train loss: 0.3341, eval loss 1.4318886995315552
Epoch 29 train loss: 0.2475, eval loss 1.4322844743728638
Epoch 30 train loss: 0.2861, eval loss 1.4314477443695068
Epoch 31 train loss: 0.2646, eval loss 1.4318957328796387
Epoch 32 train loss: 0.2768, eval loss 1.4315171241760254
Epoch 33 train loss: 0.2821, eval loss 1.4295685291290283
Epoch 34 train loss: 0.2523, eval loss 1.4301154613494873
Epoch 35 train loss: 0.2095, eval loss 1.4304709434509277
Epoch 36 train loss: 0.3007, eval loss 1.4299983978271484
Epoch 37 train loss: 0.2919, eval loss 1.4287505149841309
Epoch 38 train loss: 0.2656, eval loss 1.4285881519317627
Epoch 39 train loss: 0.2096, eval loss 1.4284683465957642
Epoch 40 train loss: 0.2311, eval loss 1.4281625747680664
Epoch 41 train loss: 0.2161, eval loss 1.4285694360733032
Epoch 42 train loss: 0.2237, eval loss 1.4280891418457031
Epoch 43 train loss: 0.1916, eval loss 1.4275962114334106
Epoch 44 train loss: 0.2943, eval loss 1.4279855489730835
Epoch 45 train loss: 0.2258, eval loss 1.4281518459320068
Epoch 46 train loss: 0.1740, eval loss 1.4271790981292725
Epoch 47 train loss: 0.2333, eval loss 1.4270048141479492
Epoch 48 train loss: 0.1832, eval loss 1.4275346994400024
Epoch 49 train loss: 0.2300, eval loss 1.427873969078064
Epoch 50 train loss: 0.2279, eval loss 1.4270555973052979
Epoch 51 train loss: 0.1486, eval loss 1.426522135734558
Epoch 52 train loss: 0.1702, eval loss 1.4256455898284912
Epoch 53 train loss: 0.1438, eval loss 1.4264591932296753
Epoch 54 train loss: 0.1655, eval loss 1.4269726276397705
Epoch 55 train loss: 0.1944, eval loss 1.4255282878875732
Epoch 56 train loss: 0.2177, eval loss 1.4265128374099731
Epoch 57 train loss: 0.1733, eval loss 1.4263728857040405
Epoch 58 train loss: 0.2087, eval loss 1.4257477521896362
Epoch 59 train loss: 0.1793, eval loss 1.4254721403121948
Epoch 60 train loss: 0.2025, eval loss 1.4257327318191528
Epoch 61 train loss: 0.1235, eval loss 1.4251850843429565
Epoch 62 train loss: 0.1716, eval loss 1.4256469011306763
Epoch 63 train loss: 0.1915, eval loss 1.424390196800232
Epoch 64 train loss: 0.1908, eval loss 1.426061987876892
Epoch 65 train loss: 0.1588, eval loss 1.425337791442871
Epoch 66 train loss: 0.1713, eval loss 1.4250048398971558
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:54:39,619] Trial 1 finished with value: 1.424390196800232 and parameters: {&#39;hidden_layers_size&#39;: 137, &#39;dropout_p&#39;: 0.3027271806643279, &#39;learning_rate&#39;: 0.00023935513600678034, &#39;batch_size&#39;: 473, &#39;l2_reg&#39;: 0.00039569760858591824}. Best is trial 0 with value: 1.4253966808319092.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.8268, eval loss 1.560943365097046
Epoch 1 train loss: 0.7713, eval loss 1.4803935289382935
Epoch 2 train loss: 0.7145, eval loss 1.4602059125900269
Epoch 3 train loss: 0.6996, eval loss 1.4514232873916626
Epoch 4 train loss: 0.6841, eval loss 1.4453935623168945
Epoch 5 train loss: 0.6674, eval loss 1.442694067955017
Epoch 6 train loss: 0.6668, eval loss 1.4393765926361084
Epoch 7 train loss: 0.6597, eval loss 1.438163161277771
Epoch 8 train loss: 0.6514, eval loss 1.4371010065078735
Epoch 9 train loss: 0.6369, eval loss 1.4360684156417847
Epoch 10 train loss: 0.6592, eval loss 1.435540795326233
Epoch 11 train loss: 0.6417, eval loss 1.4341555833816528
Epoch 12 train loss: 0.6659, eval loss 1.4337536096572876
Epoch 13 train loss: 0.6272, eval loss 1.432093620300293
Epoch 14 train loss: 0.6166, eval loss 1.4330215454101562
Epoch 15 train loss: 0.6370, eval loss 1.4315185546875
Epoch 16 train loss: 0.6157, eval loss 1.4313441514968872
Epoch 17 train loss: 0.6402, eval loss 1.4323139190673828
Epoch 18 train loss: 0.6153, eval loss 1.432389259338379
Epoch 19 train loss: 0.6220, eval loss 1.431091547012329
Epoch 20 train loss: 0.6321, eval loss 1.430795669555664
Epoch 21 train loss: 0.6243, eval loss 1.4310417175292969
Epoch 22 train loss: 0.6163, eval loss 1.4310872554779053
Epoch 23 train loss: 0.6500, eval loss 1.4305078983306885
Epoch 24 train loss: 0.6132, eval loss 1.431584358215332
Epoch 25 train loss: 0.6047, eval loss 1.4306786060333252
Epoch 26 train loss: 0.6057, eval loss 1.4295368194580078
Epoch 27 train loss: 0.6318, eval loss 1.430100679397583
Epoch 28 train loss: 0.6391, eval loss 1.4303549528121948
Epoch 29 train loss: 0.6077, eval loss 1.4292223453521729
Epoch 30 train loss: 0.6174, eval loss 1.4289270639419556
Epoch 31 train loss: 0.5935, eval loss 1.429765224456787
Epoch 32 train loss: 0.6255, eval loss 1.4295248985290527
Epoch 33 train loss: 0.6177, eval loss 1.428704857826233
Epoch 34 train loss: 0.6105, eval loss 1.4297442436218262
Epoch 35 train loss: 0.6055, eval loss 1.428587555885315
Epoch 36 train loss: 0.6217, eval loss 1.4266722202301025
Epoch 37 train loss: 0.6171, eval loss 1.4282159805297852
Epoch 38 train loss: 0.5999, eval loss 1.4280296564102173
Epoch 39 train loss: 0.6183, eval loss 1.4297757148742676
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:54:54,521] Trial 2 finished with value: 1.4266722202301025 and parameters: {&#39;hidden_layers_size&#39;: 167, &#39;dropout_p&#39;: 0.3983427779942578, &#39;learning_rate&#39;: 0.0007384995504551768, &#39;batch_size&#39;: 498, &#39;l2_reg&#39;: 2.3695382664317218e-05}. Best is trial 2 with value: 1.4266722202301025.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7413, eval loss 1.4468261003494263
Epoch 1 train loss: 0.6681, eval loss 1.4434963464736938
Epoch 2 train loss: 0.6706, eval loss 1.441253900527954
Epoch 3 train loss: 0.6742, eval loss 1.4411455392837524
Epoch 4 train loss: 0.6564, eval loss 1.438961148262024
Epoch 5 train loss: 0.6533, eval loss 1.4368897676467896
Epoch 6 train loss: 0.6650, eval loss 1.4372481107711792
Epoch 7 train loss: 0.6563, eval loss 1.435738444328308
Epoch 8 train loss: 0.6441, eval loss 1.4371559619903564
Epoch 9 train loss: 0.6357, eval loss 1.4343631267547607
Epoch 10 train loss: 0.6774, eval loss 1.4370343685150146
Epoch 11 train loss: 0.6407, eval loss 1.4342138767242432
Epoch 12 train loss: 0.6522, eval loss 1.4328484535217285
Epoch 13 train loss: 0.6621, eval loss 1.432303547859192
Epoch 14 train loss: 0.6529, eval loss 1.4363073110580444
Epoch 15 train loss: 0.6252, eval loss 1.430784821510315
Epoch 16 train loss: 0.6355, eval loss 1.43209707736969
Epoch 17 train loss: 0.6403, eval loss 1.4341334104537964
Epoch 18 train loss: 0.6221, eval loss 1.4331467151641846
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:55:01,418] Trial 3 finished with value: 1.430784821510315 and parameters: {&#39;hidden_layers_size&#39;: 88, &#39;dropout_p&#39;: 0.3666127723839712, &#39;learning_rate&#39;: 0.004845359548126126, &#39;batch_size&#39;: 509, &#39;l2_reg&#39;: 0.0008661869185245984}. Best is trial 3 with value: 1.430784821510315.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4560, eval loss 1.7419003248214722
Epoch 1 train loss: 1.3338, eval loss 1.7187784910202026
Epoch 2 train loss: 1.2677, eval loss 1.6996768712997437
Epoch 3 train loss: 1.2751, eval loss 1.6833022832870483
Epoch 4 train loss: 1.2461, eval loss 1.668806552886963
Epoch 5 train loss: 1.1946, eval loss 1.6555845737457275
Epoch 6 train loss: 1.1721, eval loss 1.6447018384933472
Epoch 7 train loss: 1.1944, eval loss 1.63323175907135
Epoch 8 train loss: 1.1612, eval loss 1.6225416660308838
Epoch 9 train loss: 0.9837, eval loss 1.6145731210708618
Epoch 10 train loss: 1.0237, eval loss 1.605860710144043
Epoch 11 train loss: 1.0361, eval loss 1.59811270236969
Epoch 12 train loss: 0.9987, eval loss 1.5896975994110107
Epoch 13 train loss: 0.9479, eval loss 1.5843249559402466
Epoch 14 train loss: 0.9307, eval loss 1.578379511833191
Epoch 15 train loss: 0.9731, eval loss 1.5713821649551392
Epoch 16 train loss: 0.9480, eval loss 1.5644980669021606
Epoch 17 train loss: 0.9661, eval loss 1.5607964992523193
Epoch 18 train loss: 0.8657, eval loss 1.5533368587493896
Epoch 19 train loss: 0.8977, eval loss 1.548988938331604
Epoch 20 train loss: 0.8171, eval loss 1.5447856187820435
Epoch 21 train loss: 0.9136, eval loss 1.5389862060546875
Epoch 22 train loss: 0.8596, eval loss 1.5355061292648315
Epoch 23 train loss: 0.8520, eval loss 1.531786322593689
Epoch 24 train loss: 0.8548, eval loss 1.526189923286438
Epoch 25 train loss: 0.7832, eval loss 1.5221729278564453
Epoch 26 train loss: 0.8734, eval loss 1.518396258354187
Epoch 27 train loss: 0.7840, eval loss 1.5155901908874512
Epoch 28 train loss: 0.7309, eval loss 1.5116877555847168
Epoch 29 train loss: 0.8791, eval loss 1.5079249143600464
Epoch 30 train loss: 0.8132, eval loss 1.504732608795166
Epoch 31 train loss: 0.8789, eval loss 1.5007175207138062
Epoch 32 train loss: 0.7391, eval loss 1.498665452003479
Epoch 33 train loss: 0.7238, eval loss 1.4947856664657593
Epoch 34 train loss: 0.7401, eval loss 1.4926503896713257
Epoch 35 train loss: 0.7676, eval loss 1.4896821975708008
Epoch 36 train loss: 0.7542, eval loss 1.4874025583267212
Epoch 37 train loss: 0.7821, eval loss 1.4846285581588745
Epoch 38 train loss: 0.6976, eval loss 1.4822142124176025
Epoch 39 train loss: 0.7498, eval loss 1.4809552431106567
Epoch 40 train loss: 0.8548, eval loss 1.477429986000061
Epoch 41 train loss: 0.7603, eval loss 1.476766586303711
Epoch 42 train loss: 0.8354, eval loss 1.4747319221496582
Epoch 43 train loss: 0.6574, eval loss 1.4714598655700684
Epoch 44 train loss: 0.7575, eval loss 1.4694900512695312
Epoch 45 train loss: 0.7177, eval loss 1.4681556224822998
Epoch 46 train loss: 0.7397, eval loss 1.4664373397827148
Epoch 47 train loss: 0.7395, eval loss 1.4652334451675415
Epoch 48 train loss: 0.7455, eval loss 1.4646410942077637
Epoch 49 train loss: 0.7127, eval loss 1.462437629699707
Epoch 50 train loss: 0.7224, eval loss 1.460503339767456
Epoch 51 train loss: 0.6504, eval loss 1.4597724676132202
Epoch 52 train loss: 0.6708, eval loss 1.4590740203857422
Epoch 53 train loss: 0.7199, eval loss 1.4576823711395264
Epoch 54 train loss: 0.6993, eval loss 1.4556775093078613
Epoch 55 train loss: 0.7104, eval loss 1.4556914567947388
Epoch 56 train loss: 0.6817, eval loss 1.4548187255859375
Epoch 57 train loss: 0.7944, eval loss 1.4543377161026
Epoch 58 train loss: 0.8136, eval loss 1.4526053667068481
Epoch 59 train loss: 0.7213, eval loss 1.4517617225646973
Epoch 60 train loss: 0.6065, eval loss 1.4509059190750122
Epoch 61 train loss: 0.7218, eval loss 1.450661063194275
Epoch 62 train loss: 0.7609, eval loss 1.4493837356567383
Epoch 63 train loss: 0.7091, eval loss 1.4486695528030396
Epoch 64 train loss: 0.7655, eval loss 1.4478528499603271
Epoch 65 train loss: 0.7504, eval loss 1.447399616241455
Epoch 66 train loss: 0.6538, eval loss 1.4476138353347778
Epoch 67 train loss: 0.7551, eval loss 1.4463176727294922
Epoch 68 train loss: 0.6935, eval loss 1.4468199014663696
Epoch 69 train loss: 0.6573, eval loss 1.4453387260437012
Epoch 70 train loss: 0.6816, eval loss 1.4462566375732422
Epoch 71 train loss: 0.7149, eval loss 1.4451878070831299
Epoch 72 train loss: 0.6505, eval loss 1.4451395273208618
Epoch 73 train loss: 0.6757, eval loss 1.4433377981185913
Epoch 74 train loss: 0.7462, eval loss 1.4437034130096436
Epoch 75 train loss: 0.7925, eval loss 1.443716049194336
Epoch 76 train loss: 0.7800, eval loss 1.4424574375152588
Epoch 77 train loss: 0.6946, eval loss 1.4424631595611572
Epoch 78 train loss: 0.6950, eval loss 1.4434067010879517
Epoch 79 train loss: 0.7264, eval loss 1.4418823719024658
Epoch 80 train loss: 0.7161, eval loss 1.4416981935501099
Epoch 81 train loss: 0.7053, eval loss 1.4417566061019897
Epoch 82 train loss: 0.6617, eval loss 1.4417067766189575
Epoch 83 train loss: 0.6719, eval loss 1.4414788484573364
Epoch 84 train loss: 0.6847, eval loss 1.4413437843322754
Epoch 85 train loss: 0.6731, eval loss 1.4414361715316772
Epoch 86 train loss: 0.7195, eval loss 1.4410347938537598
Epoch 87 train loss: 0.8492, eval loss 1.4403291940689087
Epoch 88 train loss: 0.6937, eval loss 1.440032958984375
Epoch 89 train loss: 0.6825, eval loss 1.44023597240448
Epoch 90 train loss: 0.8149, eval loss 1.4398469924926758
Epoch 91 train loss: 0.6729, eval loss 1.4397093057632446
Epoch 92 train loss: 0.5751, eval loss 1.4386723041534424
Epoch 93 train loss: 0.6445, eval loss 1.4395116567611694
Epoch 94 train loss: 0.5725, eval loss 1.4391509294509888
Epoch 95 train loss: 0.6462, eval loss 1.4393601417541504
Epoch 96 train loss: 0.6287, eval loss 1.437894582748413
Epoch 97 train loss: 0.6507, eval loss 1.4379346370697021
Epoch 98 train loss: 0.6909, eval loss 1.4377845525741577
Epoch 99 train loss: 0.7306, eval loss 1.4370088577270508
Epoch 100 train loss: 0.6398, eval loss 1.4376556873321533
Epoch 101 train loss: 0.6857, eval loss 1.4372634887695312
Epoch 102 train loss: 0.6399, eval loss 1.4366443157196045
Epoch 103 train loss: 0.6304, eval loss 1.4381086826324463
Epoch 104 train loss: 0.7226, eval loss 1.4376646280288696
Epoch 105 train loss: 0.6123, eval loss 1.4378947019577026
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:55:58,659] Trial 4 finished with value: 1.4366443157196045 and parameters: {&#39;hidden_layers_size&#39;: 55, &#39;dropout_p&#39;: 0.32531481624838055, &#39;learning_rate&#39;: 2.7013444623979626e-05, &#39;batch_size&#39;: 129, &#39;l2_reg&#39;: 2.3681946724159617e-05}. Best is trial 4 with value: 1.4366443157196045.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.6389, eval loss 1.807981252670288
Epoch 1 train loss: 1.5956, eval loss 1.8004602193832397
Epoch 2 train loss: 1.5809, eval loss 1.7975214719772339
Epoch 3 train loss: 1.5369, eval loss 1.7919362783432007
Epoch 4 train loss: 1.5817, eval loss 1.7867006063461304
Epoch 5 train loss: 1.4635, eval loss 1.7788697481155396
Epoch 6 train loss: 1.4706, eval loss 1.775214433670044
Epoch 7 train loss: 1.4775, eval loss 1.7680587768554688
Epoch 8 train loss: 1.4599, eval loss 1.7652909755706787
Epoch 9 train loss: 1.3826, eval loss 1.7609078884124756
Epoch 10 train loss: 1.3957, eval loss 1.7545236349105835
Epoch 11 train loss: 1.3255, eval loss 1.7494133710861206
Epoch 12 train loss: 1.3689, eval loss 1.7447441816329956
Epoch 13 train loss: 1.3728, eval loss 1.7398957014083862
Epoch 14 train loss: 1.3422, eval loss 1.7362419366836548
Epoch 15 train loss: 1.3713, eval loss 1.7329868078231812
Epoch 16 train loss: 1.3096, eval loss 1.7280950546264648
Epoch 17 train loss: 1.3244, eval loss 1.723274827003479
Epoch 18 train loss: 1.2797, eval loss 1.719258189201355
Epoch 19 train loss: 1.3093, eval loss 1.7140400409698486
Epoch 20 train loss: 1.2757, eval loss 1.7097703218460083
Epoch 21 train loss: 1.2869, eval loss 1.7070400714874268
Epoch 22 train loss: 1.2148, eval loss 1.7022819519042969
Epoch 23 train loss: 1.2452, eval loss 1.7000596523284912
Epoch 24 train loss: 1.2141, eval loss 1.695723533630371
Epoch 25 train loss: 1.1896, eval loss 1.6921237707138062
Epoch 26 train loss: 1.2196, eval loss 1.688851237297058
Epoch 27 train loss: 1.2342, eval loss 1.6852936744689941
Epoch 28 train loss: 1.2051, eval loss 1.6805002689361572
Epoch 29 train loss: 1.1977, eval loss 1.6786463260650635
Epoch 30 train loss: 1.1930, eval loss 1.6732982397079468
Epoch 31 train loss: 1.2234, eval loss 1.6725456714630127
Epoch 32 train loss: 1.1967, eval loss 1.6687805652618408
Epoch 33 train loss: 1.1252, eval loss 1.6653518676757812
Epoch 34 train loss: 1.1028, eval loss 1.6631344556808472
Epoch 35 train loss: 1.1292, eval loss 1.6580599546432495
Epoch 36 train loss: 1.1319, eval loss 1.655574083328247
Epoch 37 train loss: 1.0893, eval loss 1.6540417671203613
Epoch 38 train loss: 1.1051, eval loss 1.6496236324310303
Epoch 39 train loss: 1.0971, eval loss 1.6463121175765991
Epoch 40 train loss: 1.1439, eval loss 1.6449763774871826
Epoch 41 train loss: 1.0698, eval loss 1.6426727771759033
Epoch 42 train loss: 1.0815, eval loss 1.638780951499939
Epoch 43 train loss: 1.0420, eval loss 1.6372480392456055
Epoch 44 train loss: 1.0708, eval loss 1.6332104206085205
Epoch 45 train loss: 1.0322, eval loss 1.6322230100631714
Epoch 46 train loss: 1.0684, eval loss 1.6286534070968628
Epoch 47 train loss: 1.0900, eval loss 1.6266547441482544
Epoch 48 train loss: 1.0862, eval loss 1.6261504888534546
Epoch 49 train loss: 1.0897, eval loss 1.6212263107299805
Epoch 50 train loss: 1.0679, eval loss 1.6191179752349854
Epoch 51 train loss: 1.0314, eval loss 1.6157625913619995
Epoch 52 train loss: 1.0753, eval loss 1.6142257452011108
Epoch 53 train loss: 1.0471, eval loss 1.611889123916626
Epoch 54 train loss: 1.0195, eval loss 1.609240174293518
Epoch 55 train loss: 0.9965, eval loss 1.6082473993301392
Epoch 56 train loss: 0.9910, eval loss 1.6044273376464844
Epoch 57 train loss: 0.9946, eval loss 1.6025632619857788
Epoch 58 train loss: 0.9410, eval loss 1.601472020149231
Epoch 59 train loss: 0.9912, eval loss 1.6000697612762451
Epoch 60 train loss: 0.9096, eval loss 1.597005844116211
Epoch 61 train loss: 0.9721, eval loss 1.59441339969635
Epoch 62 train loss: 0.9134, eval loss 1.5924111604690552
Epoch 63 train loss: 0.9564, eval loss 1.5903029441833496
Epoch 64 train loss: 0.9151, eval loss 1.5889801979064941
Epoch 65 train loss: 0.9482, eval loss 1.5861916542053223
Epoch 66 train loss: 0.9579, eval loss 1.5856679677963257
Epoch 67 train loss: 1.0227, eval loss 1.5832464694976807
Epoch 68 train loss: 0.9540, eval loss 1.5817313194274902
Epoch 69 train loss: 1.0035, eval loss 1.5791467428207397
Epoch 70 train loss: 0.8659, eval loss 1.5796198844909668
Epoch 71 train loss: 0.9342, eval loss 1.5761604309082031
Epoch 72 train loss: 0.9495, eval loss 1.574589490890503
Epoch 73 train loss: 0.9444, eval loss 1.5722711086273193
Epoch 74 train loss: 0.8868, eval loss 1.5688225030899048
Epoch 75 train loss: 0.8882, eval loss 1.5687799453735352
Epoch 76 train loss: 0.9303, eval loss 1.567748785018921
Epoch 77 train loss: 0.9343, eval loss 1.5667445659637451
Epoch 78 train loss: 0.8525, eval loss 1.5657554864883423
Epoch 79 train loss: 0.9005, eval loss 1.561161994934082
Epoch 80 train loss: 0.8587, eval loss 1.560178518295288
Epoch 81 train loss: 0.9289, eval loss 1.558426022529602
Epoch 82 train loss: 0.8427, eval loss 1.5572259426116943
Epoch 83 train loss: 0.8805, eval loss 1.5582681894302368
Epoch 84 train loss: 0.8632, eval loss 1.5540285110473633
Epoch 85 train loss: 0.9005, eval loss 1.5537208318710327
Epoch 86 train loss: 0.9289, eval loss 1.5518124103546143
Epoch 87 train loss: 0.8766, eval loss 1.5498582124710083
Epoch 88 train loss: 0.8451, eval loss 1.548403263092041
Epoch 89 train loss: 0.8440, eval loss 1.5473923683166504
Epoch 90 train loss: 0.7762, eval loss 1.5457491874694824
Epoch 91 train loss: 0.8902, eval loss 1.5424410104751587
Epoch 92 train loss: 0.8230, eval loss 1.541938066482544
Epoch 93 train loss: 0.8772, eval loss 1.5408225059509277
Epoch 94 train loss: 0.8097, eval loss 1.5402774810791016
Epoch 95 train loss: 0.8155, eval loss 1.537996768951416
Epoch 96 train loss: 0.9016, eval loss 1.5378551483154297
Epoch 97 train loss: 0.8407, eval loss 1.5341763496398926
Epoch 98 train loss: 0.8740, eval loss 1.5340921878814697
Epoch 99 train loss: 0.8065, eval loss 1.533538818359375
Epoch 100 train loss: 0.8494, eval loss 1.5316972732543945
Epoch 101 train loss: 0.8471, eval loss 1.5308178663253784
Epoch 102 train loss: 0.8487, eval loss 1.5299973487854004
Epoch 103 train loss: 0.8666, eval loss 1.5264668464660645
Epoch 104 train loss: 0.8670, eval loss 1.5268632173538208
Epoch 105 train loss: 0.7964, eval loss 1.5250738859176636
Epoch 106 train loss: 0.8587, eval loss 1.5238792896270752
Epoch 107 train loss: 0.7912, eval loss 1.5244953632354736
Epoch 108 train loss: 0.8079, eval loss 1.5215983390808105
Epoch 109 train loss: 0.7230, eval loss 1.5212825536727905
Epoch 110 train loss: 0.8328, eval loss 1.520555019378662
Epoch 111 train loss: 0.8084, eval loss 1.5180774927139282
Epoch 112 train loss: 0.7672, eval loss 1.516634225845337
Epoch 113 train loss: 0.8631, eval loss 1.5179320573806763
Epoch 114 train loss: 0.7525, eval loss 1.514899492263794
Epoch 115 train loss: 0.8114, eval loss 1.5147885084152222
Epoch 116 train loss: 0.8295, eval loss 1.5140551328659058
Epoch 117 train loss: 0.7710, eval loss 1.5130500793457031
Epoch 118 train loss: 0.8163, eval loss 1.511544942855835
Epoch 119 train loss: 0.8303, eval loss 1.5101221799850464
Epoch 120 train loss: 0.8378, eval loss 1.5094550848007202
Epoch 121 train loss: 0.8062, eval loss 1.5077991485595703
Epoch 122 train loss: 0.7668, eval loss 1.5066280364990234
Epoch 123 train loss: 0.8203, eval loss 1.5075558423995972
Epoch 124 train loss: 0.7535, eval loss 1.5055338144302368
Epoch 125 train loss: 0.7941, eval loss 1.5052447319030762
Epoch 126 train loss: 0.8121, eval loss 1.5031434297561646
Epoch 127 train loss: 0.7861, eval loss 1.502203345298767
Epoch 128 train loss: 0.7552, eval loss 1.5020610094070435
Epoch 129 train loss: 0.7748, eval loss 1.5006917715072632
Epoch 130 train loss: 0.7732, eval loss 1.5003228187561035
Epoch 131 train loss: 0.6950, eval loss 1.4994763135910034
Epoch 132 train loss: 0.7609, eval loss 1.498957633972168
Epoch 133 train loss: 0.8019, eval loss 1.497849941253662
Epoch 134 train loss: 0.8179, eval loss 1.4957046508789062
Epoch 135 train loss: 0.8114, eval loss 1.4963505268096924
Epoch 136 train loss: 0.7744, eval loss 1.494387149810791
Epoch 137 train loss: 0.7565, eval loss 1.4949891567230225
Epoch 138 train loss: 0.8262, eval loss 1.4931880235671997
Epoch 139 train loss: 0.7932, eval loss 1.4925055503845215
Epoch 140 train loss: 0.7469, eval loss 1.4912575483322144
Epoch 141 train loss: 0.7427, eval loss 1.4916573762893677
Epoch 142 train loss: 0.7874, eval loss 1.490714192390442
Epoch 143 train loss: 0.7740, eval loss 1.489362359046936
Epoch 144 train loss: 0.7191, eval loss 1.48931884765625
Epoch 145 train loss: 0.7861, eval loss 1.488510251045227
Epoch 146 train loss: 0.7194, eval loss 1.4877020120620728
Epoch 147 train loss: 0.7402, eval loss 1.4874275922775269
Epoch 148 train loss: 0.7472, eval loss 1.4861613512039185
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:57:17,339] Trial 5 finished with value: 1.4849458932876587 and parameters: {&#39;hidden_layers_size&#39;: 79, &#39;dropout_p&#39;: 0.3892221148571247, &#39;learning_rate&#39;: 5.602285591827152e-06, &#39;batch_size&#39;: 147, &#39;l2_reg&#39;: 8.793989913918417e-05}. Best is trial 5 with value: 1.4849458932876587.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7450, eval loss 1.4849458932876587
Epoch 0 train loss: 0.8143, eval loss 1.4574309587478638
Epoch 1 train loss: 0.7465, eval loss 1.4399099349975586
Epoch 2 train loss: 0.8463, eval loss 1.4369920492172241
Epoch 3 train loss: 0.7390, eval loss 1.4350630044937134
Epoch 4 train loss: 0.7134, eval loss 1.432953119277954
Epoch 5 train loss: 0.7348, eval loss 1.4316658973693848
Epoch 6 train loss: 0.6799, eval loss 1.4294854402542114
Epoch 7 train loss: 0.6812, eval loss 1.4324995279312134
Epoch 8 train loss: 0.6901, eval loss 1.4308865070343018
Epoch 9 train loss: 0.6832, eval loss 1.4288564920425415
Epoch 10 train loss: 0.6842, eval loss 1.4295388460159302
Epoch 11 train loss: 0.6777, eval loss 1.4291431903839111
Epoch 12 train loss: 0.6471, eval loss 1.4294958114624023
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:57:24,055] Trial 6 finished with value: 1.4288564920425415 and parameters: {&#39;hidden_layers_size&#39;: 57, &#39;dropout_p&#39;: 0.323525811047646, &#39;learning_rate&#39;: 0.001639888995675964, &#39;batch_size&#39;: 163, &#39;l2_reg&#39;: 0.00011608784665298614}. Best is trial 5 with value: 1.4849458932876587.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.9078, eval loss 1.5830994844436646
Epoch 1 train loss: 0.7911, eval loss 1.5127074718475342
Epoch 2 train loss: 0.7519, eval loss 1.483310580253601
Epoch 3 train loss: 0.7245, eval loss 1.4668145179748535
Epoch 4 train loss: 0.7093, eval loss 1.457176923751831
Epoch 5 train loss: 0.6778, eval loss 1.4505764245986938
Epoch 6 train loss: 0.6856, eval loss 1.4463560581207275
Epoch 7 train loss: 0.7100, eval loss 1.444113850593567
Epoch 8 train loss: 0.6831, eval loss 1.4424225091934204
Epoch 9 train loss: 0.6624, eval loss 1.4395655393600464
Epoch 10 train loss: 0.6884, eval loss 1.4384881258010864
Epoch 11 train loss: 0.6852, eval loss 1.4374748468399048
Epoch 12 train loss: 0.6543, eval loss 1.437628149986267
Epoch 13 train loss: 0.6698, eval loss 1.435391902923584
Epoch 14 train loss: 0.6418, eval loss 1.4346774816513062
Epoch 15 train loss: 0.6515, eval loss 1.4336631298065186
Epoch 16 train loss: 0.6790, eval loss 1.4340733289718628
Epoch 17 train loss: 0.6480, eval loss 1.4336438179016113
Epoch 18 train loss: 0.6213, eval loss 1.4334313869476318
Epoch 19 train loss: 0.6609, eval loss 1.4321469068527222
Epoch 20 train loss: 0.6459, eval loss 1.4307550191879272
Epoch 21 train loss: 0.6377, eval loss 1.4321523904800415
Epoch 22 train loss: 0.6326, eval loss 1.4326740503311157
Epoch 23 train loss: 0.6384, eval loss 1.4315388202667236
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:57:33,055] Trial 7 finished with value: 1.4307550191879272 and parameters: {&#39;hidden_layers_size&#39;: 111, &#39;dropout_p&#39;: 0.25927807638886824, &#39;learning_rate&#39;: 0.00048809904371579404, &#39;batch_size&#39;: 386, &#39;l2_reg&#39;: 1.3953238064565572e-05}. Best is trial 5 with value: 1.4849458932876587.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7237, eval loss 1.4412562847137451
Epoch 1 train loss: 0.7140, eval loss 1.4383854866027832
Epoch 2 train loss: 0.6877, eval loss 1.4352675676345825
Epoch 3 train loss: 0.6937, eval loss 1.4340802431106567
Epoch 4 train loss: 0.7252, eval loss 1.4334564208984375
Epoch 5 train loss: 0.6693, eval loss 1.434956431388855
Epoch 6 train loss: 0.6778, eval loss 1.432584524154663
Epoch 7 train loss: 0.7323, eval loss 1.432875633239746
Epoch 8 train loss: 0.6877, eval loss 1.4320319890975952
Epoch 9 train loss: 0.6865, eval loss 1.4326467514038086
Epoch 10 train loss: 0.6779, eval loss 1.4330477714538574
Epoch 11 train loss: 0.7092, eval loss 1.4316794872283936
Epoch 12 train loss: 0.6684, eval loss 1.430398941040039
Epoch 13 train loss: 0.6363, eval loss 1.4295066595077515
Epoch 14 train loss: 0.6839, eval loss 1.430540680885315
Epoch 15 train loss: 0.6811, eval loss 1.4294984340667725
Epoch 16 train loss: 0.6713, eval loss 1.4299521446228027
Epoch 17 train loss: 0.6645, eval loss 1.4309502840042114
Epoch 18 train loss: 0.6465, eval loss 1.4300217628479004
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:57:40,810] Trial 8 finished with value: 1.4294984340667725 and parameters: {&#39;hidden_layers_size&#39;: 193, &#39;dropout_p&#39;: 0.440294896991348, &#39;learning_rate&#39;: 0.0033072981741150294, &#39;batch_size&#39;: 410, &#39;l2_reg&#39;: 0.0002210739711032062}. Best is trial 5 with value: 1.4849458932876587.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.2573, eval loss 1.7127341032028198
Epoch 1 train loss: 1.2439, eval loss 1.7114677429199219
Epoch 2 train loss: 1.2134, eval loss 1.7111068964004517
Epoch 3 train loss: 1.2367, eval loss 1.7094391584396362
Epoch 4 train loss: 1.3360, eval loss 1.708016276359558
Epoch 5 train loss: 1.2274, eval loss 1.7086055278778076
Epoch 6 train loss: 1.2834, eval loss 1.7064292430877686
Epoch 7 train loss: 1.2744, eval loss 1.7046992778778076
Epoch 8 train loss: 1.2906, eval loss 1.7039823532104492
Epoch 9 train loss: 1.2446, eval loss 1.7031527757644653
Epoch 10 train loss: 1.2651, eval loss 1.703141450881958
Epoch 11 train loss: 1.2363, eval loss 1.7012020349502563
Epoch 12 train loss: 1.2014, eval loss 1.7008224725723267
Epoch 13 train loss: 1.1951, eval loss 1.6991922855377197
Epoch 14 train loss: 1.2006, eval loss 1.697727084159851
Epoch 15 train loss: 1.1852, eval loss 1.6971427202224731
Epoch 16 train loss: 1.2667, eval loss 1.6980986595153809
Epoch 17 train loss: 1.2789, eval loss 1.6946078538894653
Epoch 18 train loss: 1.2565, eval loss 1.6942541599273682
Epoch 19 train loss: 1.2020, eval loss 1.6937856674194336
Epoch 20 train loss: 1.2672, eval loss 1.6916321516036987
Epoch 21 train loss: 1.2883, eval loss 1.6912548542022705
Epoch 22 train loss: 1.2003, eval loss 1.6900503635406494
Epoch 23 train loss: 1.2183, eval loss 1.6901581287384033
Epoch 24 train loss: 1.1961, eval loss 1.6883022785186768
Epoch 25 train loss: 1.2392, eval loss 1.6889828443527222
Epoch 26 train loss: 1.1990, eval loss 1.6863712072372437
Epoch 27 train loss: 1.1891, eval loss 1.6858855485916138
Epoch 28 train loss: 1.2184, eval loss 1.6848256587982178
Epoch 29 train loss: 1.1868, eval loss 1.6835073232650757
Epoch 30 train loss: 1.2343, eval loss 1.6830910444259644
Epoch 31 train loss: 1.1730, eval loss 1.6823004484176636
Epoch 32 train loss: 1.1535, eval loss 1.6822729110717773
Epoch 33 train loss: 1.1543, eval loss 1.680031657218933
Epoch 34 train loss: 1.1667, eval loss 1.679181456565857
Epoch 35 train loss: 1.1970, eval loss 1.678755521774292
Epoch 36 train loss: 1.1376, eval loss 1.6770927906036377
Epoch 37 train loss: 1.3039, eval loss 1.6781227588653564
Epoch 38 train loss: 1.1740, eval loss 1.6772444248199463
Epoch 39 train loss: 1.2086, eval loss 1.6757200956344604
Epoch 40 train loss: 1.1579, eval loss 1.6749647855758667
Epoch 41 train loss: 1.1887, eval loss 1.6730399131774902
Epoch 42 train loss: 1.1676, eval loss 1.6712980270385742
Epoch 43 train loss: 1.1472, eval loss 1.6719939708709717
Epoch 44 train loss: 1.1521, eval loss 1.6699522733688354
Epoch 45 train loss: 1.1199, eval loss 1.6698888540267944
Epoch 46 train loss: 1.1308, eval loss 1.6687670946121216
Epoch 47 train loss: 1.1465, eval loss 1.6691055297851562
Epoch 48 train loss: 1.1536, eval loss 1.6668626070022583
Epoch 49 train loss: 1.1150, eval loss 1.6667970418930054
Epoch 50 train loss: 1.1539, eval loss 1.6661622524261475
Epoch 51 train loss: 1.1108, eval loss 1.6648163795471191
Epoch 52 train loss: 1.1670, eval loss 1.6634364128112793
Epoch 53 train loss: 1.1627, eval loss 1.6632362604141235
Epoch 54 train loss: 1.1358, eval loss 1.662529468536377
Epoch 55 train loss: 1.1651, eval loss 1.6618810892105103
Epoch 56 train loss: 1.1727, eval loss 1.6600793600082397
Epoch 57 train loss: 1.0864, eval loss 1.6594868898391724
Epoch 58 train loss: 1.1241, eval loss 1.65828537940979
Epoch 59 train loss: 1.1697, eval loss 1.6577577590942383
Epoch 60 train loss: 1.1775, eval loss 1.6564899682998657
Epoch 61 train loss: 1.1506, eval loss 1.6557564735412598
Epoch 62 train loss: 1.1314, eval loss 1.6546927690505981
Epoch 63 train loss: 1.1033, eval loss 1.6544049978256226
Epoch 64 train loss: 1.1252, eval loss 1.654241919517517
Epoch 65 train loss: 1.1310, eval loss 1.6533994674682617
Epoch 66 train loss: 1.0995, eval loss 1.6524527072906494
Epoch 67 train loss: 1.1207, eval loss 1.6521174907684326
Epoch 68 train loss: 1.0828, eval loss 1.6517925262451172
Epoch 69 train loss: 1.1109, eval loss 1.64961576461792
Epoch 70 train loss: 1.2157, eval loss 1.649580717086792
Epoch 71 train loss: 1.0763, eval loss 1.647810459136963
Epoch 72 train loss: 1.1042, eval loss 1.6486845016479492
Epoch 73 train loss: 1.1192, eval loss 1.6455904245376587
Epoch 74 train loss: 1.1290, eval loss 1.6486022472381592
Epoch 75 train loss: 1.1300, eval loss 1.6462247371673584
Epoch 76 train loss: 1.1268, eval loss 1.6452935934066772
Epoch 77 train loss: 1.1712, eval loss 1.6449203491210938
Epoch 78 train loss: 1.1116, eval loss 1.6433414220809937
Epoch 79 train loss: 1.0762, eval loss 1.6433172225952148
Epoch 80 train loss: 1.1024, eval loss 1.6405138969421387
Epoch 81 train loss: 1.1264, eval loss 1.642269253730774
Epoch 82 train loss: 1.1088, eval loss 1.6408114433288574
Epoch 83 train loss: 1.0793, eval loss 1.6392171382904053
Epoch 84 train loss: 1.0894, eval loss 1.638628602027893
Epoch 85 train loss: 1.1117, eval loss 1.6374461650848389
Epoch 86 train loss: 1.1054, eval loss 1.6357313394546509
Epoch 87 train loss: 1.0788, eval loss 1.6359785795211792
Epoch 88 train loss: 1.0430, eval loss 1.6363909244537354
Epoch 89 train loss: 1.0853, eval loss 1.635183572769165
Epoch 90 train loss: 1.1124, eval loss 1.636392593383789
Epoch 91 train loss: 1.0697, eval loss 1.6344074010849
Epoch 92 train loss: 1.0685, eval loss 1.63225257396698
Epoch 93 train loss: 1.0872, eval loss 1.63227117061615
Epoch 94 train loss: 1.0596, eval loss 1.6310067176818848
Epoch 95 train loss: 1.0519, eval loss 1.631244421005249
Epoch 96 train loss: 1.0821, eval loss 1.630739450454712
Epoch 97 train loss: 1.0983, eval loss 1.6312788724899292
Epoch 98 train loss: 1.0424, eval loss 1.6308141946792603
Epoch 99 train loss: 1.0700, eval loss 1.628419280052185
Epoch 100 train loss: 1.0599, eval loss 1.6292638778686523
Epoch 101 train loss: 1.0954, eval loss 1.6264334917068481
Epoch 102 train loss: 1.0413, eval loss 1.6257668733596802
Epoch 103 train loss: 1.0626, eval loss 1.6250560283660889
Epoch 104 train loss: 1.0062, eval loss 1.6257600784301758
Epoch 105 train loss: 1.0634, eval loss 1.6242082118988037
Epoch 106 train loss: 1.0660, eval loss 1.6246479749679565
Epoch 107 train loss: 1.0468, eval loss 1.6222857236862183
Epoch 108 train loss: 1.1021, eval loss 1.621734619140625
Epoch 109 train loss: 1.0083, eval loss 1.6214075088500977
Epoch 110 train loss: 1.0417, eval loss 1.620761752128601
Epoch 111 train loss: 1.0411, eval loss 1.622240662574768
Epoch 112 train loss: 1.0691, eval loss 1.6195447444915771
Epoch 113 train loss: 1.0380, eval loss 1.6204872131347656
Epoch 114 train loss: 1.0049, eval loss 1.619309663772583
Epoch 115 train loss: 1.0259, eval loss 1.6187726259231567
Epoch 116 train loss: 0.9812, eval loss 1.618636965751648
Epoch 117 train loss: 1.0577, eval loss 1.6174511909484863
Epoch 118 train loss: 1.0278, eval loss 1.616117000579834
Epoch 119 train loss: 0.9692, eval loss 1.6141386032104492
Epoch 120 train loss: 0.9962, eval loss 1.614225149154663
Epoch 121 train loss: 1.0027, eval loss 1.615375280380249
Epoch 122 train loss: 0.9894, eval loss 1.6148650646209717
Epoch 123 train loss: 1.0603, eval loss 1.6131560802459717
Epoch 124 train loss: 1.0224, eval loss 1.612517237663269
Epoch 125 train loss: 1.0152, eval loss 1.6116422414779663
Epoch 126 train loss: 0.9781, eval loss 1.6119147539138794
Epoch 127 train loss: 0.9922, eval loss 1.6096264123916626
Epoch 128 train loss: 0.9771, eval loss 1.6104730367660522
Epoch 129 train loss: 0.9939, eval loss 1.6092194318771362
Epoch 130 train loss: 1.0479, eval loss 1.6095181703567505
Epoch 131 train loss: 0.9901, eval loss 1.6076582670211792
Epoch 132 train loss: 1.0413, eval loss 1.6082632541656494
Epoch 133 train loss: 1.0260, eval loss 1.6075447797775269
Epoch 134 train loss: 0.9938, eval loss 1.6063977479934692
Epoch 135 train loss: 1.1350, eval loss 1.6066120862960815
Epoch 136 train loss: 0.9725, eval loss 1.6060224771499634
Epoch 137 train loss: 0.9985, eval loss 1.6050561666488647
Epoch 138 train loss: 1.0007, eval loss 1.6055294275283813
Epoch 139 train loss: 0.9577, eval loss 1.604835033416748
Epoch 140 train loss: 1.0405, eval loss 1.6038038730621338
Epoch 141 train loss: 1.0578, eval loss 1.6042132377624512
Epoch 142 train loss: 1.0197, eval loss 1.6029815673828125
Epoch 143 train loss: 0.9749, eval loss 1.6023802757263184
Epoch 144 train loss: 1.0207, eval loss 1.6012595891952515
Epoch 145 train loss: 0.9965, eval loss 1.6002548933029175
Epoch 146 train loss: 0.9534, eval loss 1.6002719402313232
Epoch 147 train loss: 0.9949, eval loss 1.6012160778045654
Epoch 148 train loss: 0.9891, eval loss 1.5988456010818481
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 11:58:55,850] Trial 9 finished with value: 1.5983518362045288 and parameters: {&#39;hidden_layers_size&#39;: 61, &#39;dropout_p&#39;: 0.3335171955849856, &#39;learning_rate&#39;: 1.218558277703623e-06, &#39;batch_size&#39;: 149, &#39;l2_reg&#39;: 8.82343506258215e-05}. Best is trial 9 with value: 1.5983518362045288.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.9757, eval loss 1.5983518362045288
Epoch 0 train loss: 1.8167, eval loss 1.8361661434173584
Epoch 1 train loss: 1.7844, eval loss 1.8327094316482544
Epoch 2 train loss: 1.7676, eval loss 1.830435037612915
Epoch 3 train loss: 1.6944, eval loss 1.8292911052703857
Epoch 4 train loss: 1.7405, eval loss 1.8237731456756592
Epoch 5 train loss: 1.7374, eval loss 1.8194588422775269
Epoch 6 train loss: 1.7057, eval loss 1.8185237646102905
Epoch 7 train loss: 1.6584, eval loss 1.8168212175369263
Epoch 8 train loss: 1.7315, eval loss 1.8118305206298828
Epoch 9 train loss: 1.6620, eval loss 1.8092132806777954
Epoch 10 train loss: 1.6265, eval loss 1.8066412210464478
Epoch 11 train loss: 1.6185, eval loss 1.8041006326675415
Epoch 12 train loss: 1.6677, eval loss 1.8003767728805542
Epoch 13 train loss: 1.6482, eval loss 1.8005175590515137
Epoch 14 train loss: 1.6992, eval loss 1.794893741607666
Epoch 15 train loss: 1.5990, eval loss 1.7939708232879639
Epoch 16 train loss: 1.5770, eval loss 1.7887749671936035
Epoch 17 train loss: 1.5592, eval loss 1.7892825603485107
Epoch 18 train loss: 1.5912, eval loss 1.7856582403182983
Epoch 19 train loss: 1.5880, eval loss 1.7808547019958496
Epoch 20 train loss: 1.5992, eval loss 1.7782596349716187
Epoch 21 train loss: 1.5902, eval loss 1.780239462852478
Epoch 22 train loss: 1.5704, eval loss 1.7746174335479736
Epoch 23 train loss: 1.4924, eval loss 1.7748056650161743
Epoch 24 train loss: 1.5439, eval loss 1.770710825920105
Epoch 25 train loss: 1.5738, eval loss 1.7679671049118042
Epoch 26 train loss: 1.5955, eval loss 1.7678672075271606
Epoch 27 train loss: 1.5668, eval loss 1.765138030052185
Epoch 28 train loss: 1.5277, eval loss 1.762365460395813
Epoch 29 train loss: 1.5569, eval loss 1.759416103363037
Epoch 30 train loss: 1.5503, eval loss 1.7556071281433105
Epoch 31 train loss: 1.5986, eval loss 1.7543643712997437
Epoch 32 train loss: 1.5532, eval loss 1.7513326406478882
Epoch 33 train loss: 1.4848, eval loss 1.7504955530166626
Epoch 34 train loss: 1.4539, eval loss 1.7484025955200195
Epoch 35 train loss: 1.5096, eval loss 1.7461527585983276
Epoch 36 train loss: 1.4404, eval loss 1.7442482709884644
Epoch 37 train loss: 1.4359, eval loss 1.7435311079025269
Epoch 38 train loss: 1.4028, eval loss 1.7410613298416138
Epoch 39 train loss: 1.4188, eval loss 1.737724781036377
Epoch 40 train loss: 1.4885, eval loss 1.7356441020965576
Epoch 41 train loss: 1.4414, eval loss 1.7356783151626587
Epoch 42 train loss: 1.3784, eval loss 1.7338496446609497
Epoch 43 train loss: 1.4270, eval loss 1.731167197227478
Epoch 44 train loss: 1.4527, eval loss 1.7274222373962402
Epoch 45 train loss: 1.4065, eval loss 1.7272014617919922
Epoch 46 train loss: 1.4510, eval loss 1.7263669967651367
Epoch 47 train loss: 1.3804, eval loss 1.7238377332687378
Epoch 48 train loss: 1.4424, eval loss 1.7192516326904297
Epoch 49 train loss: 1.3665, eval loss 1.7195457220077515
Epoch 50 train loss: 1.4120, eval loss 1.7166410684585571
Epoch 51 train loss: 1.4013, eval loss 1.7153890132904053
Epoch 52 train loss: 1.3654, eval loss 1.714573860168457
Epoch 53 train loss: 1.3835, eval loss 1.7115358114242554
Epoch 54 train loss: 1.3523, eval loss 1.709256887435913
Epoch 55 train loss: 1.3002, eval loss 1.7084074020385742
Epoch 56 train loss: 1.3150, eval loss 1.7093403339385986
Epoch 57 train loss: 1.3710, eval loss 1.7056174278259277
Epoch 58 train loss: 1.3182, eval loss 1.7044296264648438
Epoch 59 train loss: 1.3150, eval loss 1.7034944295883179
Epoch 60 train loss: 1.3808, eval loss 1.7002818584442139
Epoch 61 train loss: 1.3191, eval loss 1.7014824151992798
Epoch 62 train loss: 1.3233, eval loss 1.701650619506836
Epoch 63 train loss: 1.3115, eval loss 1.6963359117507935
Epoch 64 train loss: 1.2693, eval loss 1.693961262702942
Epoch 65 train loss: 1.2999, eval loss 1.6926281452178955
Epoch 66 train loss: 1.2821, eval loss 1.6928900480270386
Epoch 67 train loss: 1.3464, eval loss 1.688643217086792
Epoch 68 train loss: 1.3034, eval loss 1.6883078813552856
Epoch 69 train loss: 1.2987, eval loss 1.6882754564285278
Epoch 70 train loss: 1.2766, eval loss 1.6853604316711426
Epoch 71 train loss: 1.3768, eval loss 1.6848113536834717
Epoch 72 train loss: 1.2809, eval loss 1.682633876800537
Epoch 73 train loss: 1.2520, eval loss 1.6817876100540161
Epoch 74 train loss: 1.2735, eval loss 1.6785295009613037
Epoch 75 train loss: 1.1580, eval loss 1.6800874471664429
Epoch 76 train loss: 1.2212, eval loss 1.677596926689148
Epoch 77 train loss: 1.2178, eval loss 1.6764699220657349
Epoch 78 train loss: 1.2480, eval loss 1.6769782304763794
Epoch 79 train loss: 1.2250, eval loss 1.6742610931396484
Epoch 80 train loss: 1.2664, eval loss 1.6722652912139893
Epoch 81 train loss: 1.2598, eval loss 1.6725414991378784
Epoch 82 train loss: 1.2322, eval loss 1.6706420183181763
Epoch 83 train loss: 1.2019, eval loss 1.6691941022872925
Epoch 84 train loss: 1.2151, eval loss 1.6666035652160645
Epoch 85 train loss: 1.1985, eval loss 1.6657944917678833
Epoch 86 train loss: 1.2919, eval loss 1.664588212966919
Epoch 87 train loss: 1.1901, eval loss 1.6638559103012085
Epoch 88 train loss: 1.2675, eval loss 1.662807822227478
Epoch 89 train loss: 1.2180, eval loss 1.660475254058838
Epoch 90 train loss: 1.2410, eval loss 1.6623029708862305
Epoch 91 train loss: 1.1824, eval loss 1.6574316024780273
Epoch 92 train loss: 1.1974, eval loss 1.6583259105682373
Epoch 93 train loss: 1.1529, eval loss 1.656527042388916
Epoch 94 train loss: 1.1332, eval loss 1.6543810367584229
Epoch 95 train loss: 1.1658, eval loss 1.655651330947876
Epoch 96 train loss: 1.1706, eval loss 1.6528383493423462
Epoch 97 train loss: 1.2057, eval loss 1.651404619216919
Epoch 98 train loss: 1.1169, eval loss 1.6532381772994995
Epoch 99 train loss: 1.1894, eval loss 1.6503890752792358
Epoch 100 train loss: 1.1885, eval loss 1.6492618322372437
Epoch 101 train loss: 1.1665, eval loss 1.6470609903335571
Epoch 102 train loss: 1.1515, eval loss 1.6460553407669067
Epoch 103 train loss: 1.1720, eval loss 1.646386742591858
Epoch 104 train loss: 1.1217, eval loss 1.6456307172775269
Epoch 105 train loss: 1.1220, eval loss 1.6435588598251343
Epoch 106 train loss: 1.1492, eval loss 1.6429164409637451
Epoch 107 train loss: 1.0601, eval loss 1.6405631303787231
Epoch 108 train loss: 1.1053, eval loss 1.640823483467102
Epoch 109 train loss: 1.0905, eval loss 1.6399883031845093
Epoch 110 train loss: 1.1739, eval loss 1.6395364999771118
Epoch 111 train loss: 1.1071, eval loss 1.6388978958129883
Epoch 112 train loss: 1.1178, eval loss 1.6377876996994019
Epoch 113 train loss: 1.2030, eval loss 1.6358476877212524
Epoch 114 train loss: 1.0995, eval loss 1.6359442472457886
Epoch 115 train loss: 1.0798, eval loss 1.6344937086105347
Epoch 116 train loss: 1.1434, eval loss 1.6334943771362305
Epoch 117 train loss: 1.1110, eval loss 1.6306986808776855
Epoch 118 train loss: 1.0909, eval loss 1.629085659980774
Epoch 119 train loss: 1.1372, eval loss 1.6292608976364136
Epoch 120 train loss: 1.1303, eval loss 1.6294704675674438
Epoch 121 train loss: 1.0919, eval loss 1.6268686056137085
Epoch 122 train loss: 1.0932, eval loss 1.627995252609253
Epoch 123 train loss: 1.0845, eval loss 1.62576425075531
Epoch 124 train loss: 1.1455, eval loss 1.6260583400726318
Epoch 125 train loss: 1.1305, eval loss 1.6248648166656494
Epoch 126 train loss: 1.0633, eval loss 1.6250674724578857
Epoch 127 train loss: 1.0983, eval loss 1.6210755109786987
Epoch 128 train loss: 1.0554, eval loss 1.6214746236801147
Epoch 129 train loss: 1.0907, eval loss 1.6213020086288452
Epoch 130 train loss: 1.1121, eval loss 1.620283842086792
Epoch 131 train loss: 1.0395, eval loss 1.6196165084838867
Epoch 132 train loss: 1.0937, eval loss 1.618436574935913
Epoch 133 train loss: 1.0872, eval loss 1.6167919635772705
Epoch 134 train loss: 1.0055, eval loss 1.6163592338562012
Epoch 135 train loss: 1.0671, eval loss 1.615475058555603
Epoch 136 train loss: 1.0415, eval loss 1.6152039766311646
Epoch 137 train loss: 1.0718, eval loss 1.6131404638290405
Epoch 138 train loss: 1.0288, eval loss 1.6098557710647583
Epoch 139 train loss: 1.0318, eval loss 1.6122326850891113
Epoch 140 train loss: 1.0433, eval loss 1.611917495727539
Epoch 141 train loss: 1.0673, eval loss 1.6102412939071655
Epoch 142 train loss: 1.0582, eval loss 1.6084859371185303
Epoch 143 train loss: 1.0590, eval loss 1.6083885431289673
Epoch 144 train loss: 1.0507, eval loss 1.6067304611206055
Epoch 145 train loss: 0.9950, eval loss 1.6062841415405273
Epoch 146 train loss: 1.0280, eval loss 1.604134202003479
Epoch 147 train loss: 1.0157, eval loss 1.6054487228393555
Epoch 148 train loss: 1.0253, eval loss 1.6052470207214355
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:00:19,939] Trial 10 finished with value: 1.604019045829773 and parameters: {&#39;hidden_layers_size&#39;: 74, &#39;dropout_p&#39;: 0.33136891009652225, &#39;learning_rate&#39;: 2.22717072173014e-06, &#39;batch_size&#39;: 128, &#39;l2_reg&#39;: 0.00012254471855770472}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 1.0482, eval loss 1.604019045829773
Epoch 0 train loss: 1.5965, eval loss 1.8047709465026855
Epoch 1 train loss: 1.5960, eval loss 1.7960457801818848
Epoch 2 train loss: 1.6215, eval loss 1.7882399559020996
Epoch 3 train loss: 1.5327, eval loss 1.7791756391525269
Epoch 4 train loss: 1.5479, eval loss 1.7713788747787476
Epoch 5 train loss: 1.4365, eval loss 1.7631067037582397
Epoch 6 train loss: 1.4975, eval loss 1.7570745944976807
Epoch 7 train loss: 1.5370, eval loss 1.7496657371520996
Epoch 8 train loss: 1.4846, eval loss 1.7437385320663452
Epoch 9 train loss: 1.3625, eval loss 1.7370630502700806
Epoch 10 train loss: 1.4339, eval loss 1.7307111024856567
Epoch 11 train loss: 1.4143, eval loss 1.7250785827636719
Epoch 12 train loss: 1.3309, eval loss 1.7185893058776855
Epoch 13 train loss: 1.3115, eval loss 1.7132006883621216
Epoch 14 train loss: 1.3895, eval loss 1.70828378200531
Epoch 15 train loss: 1.2887, eval loss 1.7028430700302124
Epoch 16 train loss: 1.3049, eval loss 1.6988258361816406
Epoch 17 train loss: 1.2574, eval loss 1.6921696662902832
Epoch 18 train loss: 1.2975, eval loss 1.6889865398406982
Epoch 19 train loss: 1.2391, eval loss 1.6834865808486938
Epoch 20 train loss: 1.2508, eval loss 1.6806379556655884
Epoch 21 train loss: 1.2860, eval loss 1.6763546466827393
Epoch 22 train loss: 1.2057, eval loss 1.6725358963012695
Epoch 23 train loss: 1.2217, eval loss 1.667621374130249
Epoch 24 train loss: 1.2402, eval loss 1.664218783378601
Epoch 25 train loss: 1.1415, eval loss 1.6594243049621582
Epoch 26 train loss: 1.1674, eval loss 1.6565260887145996
Epoch 27 train loss: 1.1395, eval loss 1.6535793542861938
Epoch 28 train loss: 1.1247, eval loss 1.6499924659729004
Epoch 29 train loss: 1.1655, eval loss 1.6471662521362305
Epoch 30 train loss: 1.1226, eval loss 1.6434201002120972
Epoch 31 train loss: 1.1107, eval loss 1.6403374671936035
Epoch 32 train loss: 1.1060, eval loss 1.636975884437561
Epoch 33 train loss: 1.0816, eval loss 1.6342321634292603
Epoch 34 train loss: 1.0822, eval loss 1.6304585933685303
Epoch 35 train loss: 1.0553, eval loss 1.6290152072906494
Epoch 36 train loss: 1.1426, eval loss 1.62554132938385
Epoch 37 train loss: 1.0232, eval loss 1.6226866245269775
Epoch 38 train loss: 1.0722, eval loss 1.6213773488998413
Epoch 39 train loss: 1.0195, eval loss 1.616672396659851
Epoch 40 train loss: 1.0296, eval loss 1.6145416498184204
Epoch 41 train loss: 1.0548, eval loss 1.6120898723602295
Epoch 42 train loss: 1.0686, eval loss 1.6108522415161133
Epoch 43 train loss: 1.0081, eval loss 1.6067380905151367
Epoch 44 train loss: 1.0434, eval loss 1.6042635440826416
Epoch 45 train loss: 1.0499, eval loss 1.6031956672668457
Epoch 46 train loss: 1.0106, eval loss 1.6000382900238037
Epoch 47 train loss: 1.0246, eval loss 1.5995795726776123
Epoch 48 train loss: 0.9890, eval loss 1.5955445766448975
Epoch 49 train loss: 1.0017, eval loss 1.5941462516784668
Epoch 50 train loss: 0.9861, eval loss 1.592423915863037
Epoch 51 train loss: 1.0414, eval loss 1.5899314880371094
Epoch 52 train loss: 0.9335, eval loss 1.589928150177002
Epoch 53 train loss: 1.0130, eval loss 1.586998462677002
Epoch 54 train loss: 0.9588, eval loss 1.5848557949066162
Epoch 55 train loss: 0.9901, eval loss 1.582783818244934
Epoch 56 train loss: 0.9870, eval loss 1.5803838968276978
Epoch 57 train loss: 0.9849, eval loss 1.5785179138183594
Epoch 58 train loss: 0.9274, eval loss 1.577549934387207
Epoch 59 train loss: 0.9801, eval loss 1.575279712677002
Epoch 60 train loss: 0.9249, eval loss 1.5731289386749268
Epoch 61 train loss: 0.8829, eval loss 1.5721896886825562
Epoch 62 train loss: 0.9142, eval loss 1.570094347000122
Epoch 63 train loss: 0.9219, eval loss 1.5692296028137207
Epoch 64 train loss: 0.9203, eval loss 1.5671964883804321
Epoch 65 train loss: 0.9123, eval loss 1.5653611421585083
Epoch 66 train loss: 0.9540, eval loss 1.564013957977295
Epoch 67 train loss: 0.8975, eval loss 1.5626975297927856
Epoch 68 train loss: 0.9339, eval loss 1.5608612298965454
Epoch 69 train loss: 0.9343, eval loss 1.5585311651229858
Epoch 70 train loss: 0.9428, eval loss 1.5577354431152344
Epoch 71 train loss: 0.9228, eval loss 1.55620539188385
Epoch 72 train loss: 0.9244, eval loss 1.5548557043075562
Epoch 73 train loss: 0.8825, eval loss 1.553346037864685
Epoch 74 train loss: 0.9163, eval loss 1.5535314083099365
Epoch 75 train loss: 0.8898, eval loss 1.5510737895965576
Epoch 76 train loss: 0.8985, eval loss 1.5494123697280884
Epoch 77 train loss: 0.9276, eval loss 1.5476759672164917
Epoch 78 train loss: 0.9054, eval loss 1.5469826459884644
Epoch 79 train loss: 0.8706, eval loss 1.545756220817566
Epoch 80 train loss: 0.9168, eval loss 1.5445961952209473
Epoch 81 train loss: 0.8355, eval loss 1.543640375137329
Epoch 82 train loss: 0.8943, eval loss 1.5411274433135986
Epoch 83 train loss: 0.8745, eval loss 1.5404229164123535
Epoch 84 train loss: 0.8580, eval loss 1.5393719673156738
Epoch 85 train loss: 0.9224, eval loss 1.5378347635269165
Epoch 86 train loss: 0.8567, eval loss 1.5370351076126099
Epoch 87 train loss: 0.8412, eval loss 1.5364819765090942
Epoch 88 train loss: 0.8406, eval loss 1.5342960357666016
Epoch 89 train loss: 0.8221, eval loss 1.53327476978302
Epoch 90 train loss: 0.8710, eval loss 1.5325006246566772
Epoch 91 train loss: 0.8729, eval loss 1.531151294708252
Epoch 92 train loss: 0.8620, eval loss 1.53004789352417
Epoch 93 train loss: 0.8602, eval loss 1.5298278331756592
Epoch 94 train loss: 0.7901, eval loss 1.5281070470809937
Epoch 95 train loss: 0.8277, eval loss 1.5262644290924072
Epoch 96 train loss: 0.8530, eval loss 1.5257666110992432
Epoch 97 train loss: 0.8260, eval loss 1.5251047611236572
Epoch 98 train loss: 0.8638, eval loss 1.523867130279541
Epoch 99 train loss: 0.8353, eval loss 1.5237336158752441
Epoch 100 train loss: 0.8196, eval loss 1.5221107006072998
Epoch 101 train loss: 0.8204, eval loss 1.5206139087677002
Epoch 102 train loss: 0.8353, eval loss 1.5200250148773193
Epoch 103 train loss: 0.8151, eval loss 1.5181622505187988
Epoch 104 train loss: 0.8102, eval loss 1.5182572603225708
Epoch 105 train loss: 0.8369, eval loss 1.5169703960418701
Epoch 106 train loss: 0.8126, eval loss 1.5151573419570923
Epoch 107 train loss: 0.8456, eval loss 1.5151909589767456
Epoch 108 train loss: 0.8110, eval loss 1.5144709348678589
Epoch 109 train loss: 0.7934, eval loss 1.5136274099349976
Epoch 110 train loss: 0.7934, eval loss 1.5122603178024292
Epoch 111 train loss: 0.7972, eval loss 1.5123575925827026
Epoch 112 train loss: 0.8203, eval loss 1.5116873979568481
Epoch 113 train loss: 0.7677, eval loss 1.5104711055755615
Epoch 114 train loss: 0.8113, eval loss 1.5098942518234253
Epoch 115 train loss: 0.8513, eval loss 1.5091516971588135
Epoch 116 train loss: 0.7929, eval loss 1.5085151195526123
Epoch 117 train loss: 0.7932, eval loss 1.507208228111267
Epoch 118 train loss: 0.8333, eval loss 1.5065340995788574
Epoch 119 train loss: 0.8069, eval loss 1.5062295198440552
Epoch 120 train loss: 0.8255, eval loss 1.5047645568847656
Epoch 121 train loss: 0.7454, eval loss 1.5045095682144165
Epoch 122 train loss: 0.8307, eval loss 1.5034726858139038
Epoch 123 train loss: 0.7626, eval loss 1.502123236656189
Epoch 124 train loss: 0.7675, eval loss 1.5026004314422607
Epoch 125 train loss: 0.7502, eval loss 1.5015901327133179
Epoch 126 train loss: 0.8253, eval loss 1.4990310668945312
Epoch 127 train loss: 0.7506, eval loss 1.5000358819961548
Epoch 128 train loss: 0.8028, eval loss 1.4982502460479736
Epoch 129 train loss: 0.7462, eval loss 1.4983563423156738
Epoch 130 train loss: 0.7609, eval loss 1.4980846643447876
Epoch 131 train loss: 0.7682, eval loss 1.4970035552978516
Epoch 132 train loss: 0.7523, eval loss 1.4964118003845215
Epoch 133 train loss: 0.7890, eval loss 1.49569833278656
Epoch 134 train loss: 0.7907, eval loss 1.4950915575027466
Epoch 135 train loss: 0.8370, eval loss 1.4946186542510986
Epoch 136 train loss: 0.7696, eval loss 1.4941221475601196
Epoch 137 train loss: 0.7949, eval loss 1.4935473203659058
Epoch 138 train loss: 0.7785, eval loss 1.492287278175354
Epoch 139 train loss: 0.7720, eval loss 1.492241621017456
Epoch 140 train loss: 0.7756, eval loss 1.4914593696594238
Epoch 141 train loss: 0.7802, eval loss 1.4913334846496582
Epoch 142 train loss: 0.8022, eval loss 1.4902968406677246
Epoch 143 train loss: 0.8101, eval loss 1.4895777702331543
Epoch 144 train loss: 0.7797, eval loss 1.4889781475067139
Epoch 145 train loss: 0.7918, eval loss 1.4883965253829956
Epoch 146 train loss: 0.7184, eval loss 1.48777174949646
Epoch 147 train loss: 0.7981, eval loss 1.4876115322113037
Epoch 148 train loss: 0.7108, eval loss 1.487038016319275
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:01:23,149] Trial 11 finished with value: 1.4864838123321533 and parameters: {&#39;hidden_layers_size&#39;: 213, &#39;dropout_p&#39;: 0.36216709088446125, &#39;learning_rate&#39;: 5.2940213719974975e-06, &#39;batch_size&#39;: 383, &#39;l2_reg&#39;: 3.4424603013924284e-05}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7635, eval loss 1.4864838123321533
Epoch 0 train loss: 0.8362, eval loss 1.4302172660827637
Epoch 1 train loss: 0.7828, eval loss 1.4340970516204834
Epoch 2 train loss: 0.7205, eval loss 1.4297698736190796
Epoch 3 train loss: 0.7146, eval loss 1.4280736446380615
Epoch 4 train loss: 0.6643, eval loss 1.4266185760498047
Epoch 5 train loss: 0.6408, eval loss 1.4290642738342285
Epoch 6 train loss: 0.6785, eval loss 1.4312639236450195
Epoch 7 train loss: 0.6536, eval loss 1.430992841720581
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:01:27,346] Trial 12 finished with value: 1.4266185760498047 and parameters: {&#39;hidden_layers_size&#39;: 144, &#39;dropout_p&#39;: 0.3112749295395019, &#39;learning_rate&#39;: 0.022921845040939203, &#39;batch_size&#39;: 225, &#39;l2_reg&#39;: 0.00022311867281809498}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7834, eval loss 1.4314632415771484
Epoch 1 train loss: 0.8209, eval loss 1.4325178861618042
Epoch 2 train loss: 0.7661, eval loss 1.4285625219345093
Epoch 3 train loss: 0.6919, eval loss 1.4291861057281494
Epoch 4 train loss: 0.7505, eval loss 1.4273971319198608
Epoch 5 train loss: 0.7207, eval loss 1.4258660078048706
Epoch 6 train loss: 0.7354, eval loss 1.4294683933258057
Epoch 7 train loss: 0.7394, eval loss 1.4301553964614868
Epoch 8 train loss: 0.7040, eval loss 1.4268364906311035
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:01:32,700] Trial 13 finished with value: 1.4258660078048706 and parameters: {&#39;hidden_layers_size&#39;: 129, &#39;dropout_p&#39;: 0.4287796405673766, &#39;learning_rate&#39;: 0.009527087967219797, &#39;batch_size&#39;: 162, &#39;l2_reg&#39;: 0.00013634559328734786}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.5125, eval loss 1.7800815105438232
Epoch 1 train loss: 1.4650, eval loss 1.7722440958023071
Epoch 2 train loss: 1.4603, eval loss 1.7623013257980347
Epoch 3 train loss: 1.3826, eval loss 1.7550312280654907
Epoch 4 train loss: 1.3752, eval loss 1.7458875179290771
Epoch 5 train loss: 1.3789, eval loss 1.7401067018508911
Epoch 6 train loss: 1.3527, eval loss 1.7303485870361328
Epoch 7 train loss: 1.2970, eval loss 1.7240208387374878
Epoch 8 train loss: 1.3195, eval loss 1.7164167165756226
Epoch 9 train loss: 1.2668, eval loss 1.7097499370574951
Epoch 10 train loss: 1.2803, eval loss 1.7041105031967163
Epoch 11 train loss: 1.2535, eval loss 1.6983213424682617
Epoch 12 train loss: 1.2369, eval loss 1.6921731233596802
Epoch 13 train loss: 1.1712, eval loss 1.6870054006576538
Epoch 14 train loss: 1.1953, eval loss 1.6814374923706055
Epoch 15 train loss: 1.1834, eval loss 1.6752749681472778
Epoch 16 train loss: 1.2173, eval loss 1.671687364578247
Epoch 17 train loss: 1.1439, eval loss 1.6675511598587036
Epoch 18 train loss: 1.1791, eval loss 1.6624234914779663
Epoch 19 train loss: 1.1203, eval loss 1.6578192710876465
Epoch 20 train loss: 1.1026, eval loss 1.6535190343856812
Epoch 21 train loss: 1.1050, eval loss 1.6493021249771118
Epoch 22 train loss: 1.1357, eval loss 1.6461398601531982
Epoch 23 train loss: 1.1262, eval loss 1.6416172981262207
Epoch 24 train loss: 1.0998, eval loss 1.6383745670318604
Epoch 25 train loss: 1.0735, eval loss 1.6342514753341675
Epoch 26 train loss: 1.1066, eval loss 1.6302067041397095
Epoch 27 train loss: 1.0575, eval loss 1.626824975013733
Epoch 28 train loss: 1.0483, eval loss 1.6240290403366089
Epoch 29 train loss: 1.0357, eval loss 1.6227538585662842
Epoch 30 train loss: 1.0517, eval loss 1.6183987855911255
Epoch 31 train loss: 1.0183, eval loss 1.6140269041061401
Epoch 32 train loss: 1.0277, eval loss 1.6114708185195923
Epoch 33 train loss: 1.0280, eval loss 1.6083341836929321
Epoch 34 train loss: 0.9783, eval loss 1.6061614751815796
Epoch 35 train loss: 1.0112, eval loss 1.6030172109603882
Epoch 36 train loss: 1.0002, eval loss 1.60051429271698
Epoch 37 train loss: 0.9863, eval loss 1.5956573486328125
Epoch 38 train loss: 1.0179, eval loss 1.5948337316513062
Epoch 39 train loss: 0.9464, eval loss 1.592589020729065
Epoch 40 train loss: 0.9999, eval loss 1.5894140005111694
Epoch 41 train loss: 0.9770, eval loss 1.5879014730453491
Epoch 42 train loss: 0.9273, eval loss 1.584403157234192
Epoch 43 train loss: 0.9468, eval loss 1.5825114250183105
Epoch 44 train loss: 0.9526, eval loss 1.5788646936416626
Epoch 45 train loss: 0.9328, eval loss 1.5771986246109009
Epoch 46 train loss: 0.9124, eval loss 1.5750328302383423
Epoch 47 train loss: 0.9070, eval loss 1.5746159553527832
Epoch 48 train loss: 0.9006, eval loss 1.5713592767715454
Epoch 49 train loss: 0.9223, eval loss 1.5685172080993652
Epoch 50 train loss: 0.9048, eval loss 1.566699743270874
Epoch 51 train loss: 0.9317, eval loss 1.5636540651321411
Epoch 52 train loss: 0.8862, eval loss 1.5620590448379517
Epoch 53 train loss: 0.9201, eval loss 1.5617526769638062
Epoch 54 train loss: 0.8909, eval loss 1.5589007139205933
Epoch 55 train loss: 0.8878, eval loss 1.556339144706726
Epoch 56 train loss: 0.8858, eval loss 1.555436611175537
Epoch 57 train loss: 0.8811, eval loss 1.5534043312072754
Epoch 58 train loss: 0.8627, eval loss 1.5520869493484497
Epoch 59 train loss: 0.8612, eval loss 1.550342321395874
Epoch 60 train loss: 0.8942, eval loss 1.5471140146255493
Epoch 61 train loss: 0.8523, eval loss 1.5455973148345947
Epoch 62 train loss: 0.8265, eval loss 1.5443336963653564
Epoch 63 train loss: 0.8194, eval loss 1.5427865982055664
Epoch 64 train loss: 0.8390, eval loss 1.540690541267395
Epoch 65 train loss: 0.8458, eval loss 1.5392043590545654
Epoch 66 train loss: 0.8720, eval loss 1.5381755828857422
Epoch 67 train loss: 0.8230, eval loss 1.5353269577026367
Epoch 68 train loss: 0.8383, eval loss 1.5339686870574951
Epoch 69 train loss: 0.8543, eval loss 1.5332931280136108
Epoch 70 train loss: 0.8493, eval loss 1.5306085348129272
Epoch 71 train loss: 0.8143, eval loss 1.5291410684585571
Epoch 72 train loss: 0.8120, eval loss 1.5282052755355835
Epoch 73 train loss: 0.8139, eval loss 1.5274966955184937
Epoch 74 train loss: 0.8107, eval loss 1.5254276990890503
Epoch 75 train loss: 0.8276, eval loss 1.5236082077026367
Epoch 76 train loss: 0.7818, eval loss 1.5222797393798828
Epoch 77 train loss: 0.8125, eval loss 1.5210288763046265
Epoch 78 train loss: 0.8216, eval loss 1.5199499130249023
Epoch 79 train loss: 0.7978, eval loss 1.51854407787323
Epoch 80 train loss: 0.7836, eval loss 1.5180697441101074
Epoch 81 train loss: 0.8089, eval loss 1.5158658027648926
Epoch 82 train loss: 0.7636, eval loss 1.5148696899414062
Epoch 83 train loss: 0.8081, eval loss 1.5138219594955444
Epoch 84 train loss: 0.7735, eval loss 1.5129307508468628
Epoch 85 train loss: 0.7837, eval loss 1.5098655223846436
Epoch 86 train loss: 0.7708, eval loss 1.5087555646896362
Epoch 87 train loss: 0.8247, eval loss 1.507851004600525
Epoch 88 train loss: 0.7876, eval loss 1.5066665410995483
Epoch 89 train loss: 0.7569, eval loss 1.505995750427246
Epoch 90 train loss: 0.7546, eval loss 1.505220651626587
Epoch 91 train loss: 0.7873, eval loss 1.5039628744125366
Epoch 92 train loss: 0.7897, eval loss 1.5029282569885254
Epoch 93 train loss: 0.7481, eval loss 1.5017133951187134
Epoch 94 train loss: 0.8000, eval loss 1.500206708908081
Epoch 95 train loss: 0.7825, eval loss 1.4999927282333374
Epoch 96 train loss: 0.7951, eval loss 1.498462200164795
Epoch 97 train loss: 0.7682, eval loss 1.4979103803634644
Epoch 98 train loss: 0.7304, eval loss 1.4967411756515503
Epoch 99 train loss: 0.7573, eval loss 1.4965530633926392
Epoch 100 train loss: 0.7738, eval loss 1.4942163228988647
Epoch 101 train loss: 0.7812, eval loss 1.4941184520721436
Epoch 102 train loss: 0.7735, eval loss 1.4933149814605713
Epoch 103 train loss: 0.7623, eval loss 1.4916367530822754
Epoch 104 train loss: 0.7387, eval loss 1.4912306070327759
Epoch 105 train loss: 0.7528, eval loss 1.490180492401123
Epoch 106 train loss: 0.7437, eval loss 1.4893099069595337
Epoch 107 train loss: 0.8045, eval loss 1.4875677824020386
Epoch 108 train loss: 0.7317, eval loss 1.4874423742294312
Epoch 109 train loss: 0.7270, eval loss 1.4865907430648804
Epoch 110 train loss: 0.7338, eval loss 1.4860684871673584
Epoch 111 train loss: 0.7172, eval loss 1.4853097200393677
Epoch 112 train loss: 0.7342, eval loss 1.483856201171875
Epoch 113 train loss: 0.7103, eval loss 1.4835052490234375
Epoch 114 train loss: 0.7223, eval loss 1.4830011129379272
Epoch 115 train loss: 0.7192, eval loss 1.4819740056991577
Epoch 116 train loss: 0.7699, eval loss 1.4803310632705688
Epoch 117 train loss: 0.7359, eval loss 1.4812531471252441
Epoch 118 train loss: 0.7160, eval loss 1.4795818328857422
Epoch 119 train loss: 0.6967, eval loss 1.4792604446411133
Epoch 120 train loss: 0.7374, eval loss 1.4784280061721802
Epoch 121 train loss: 0.7217, eval loss 1.477648377418518
Epoch 122 train loss: 0.7236, eval loss 1.4769177436828613
Epoch 123 train loss: 0.7189, eval loss 1.4765113592147827
Epoch 124 train loss: 0.7482, eval loss 1.475844144821167
Epoch 125 train loss: 0.7236, eval loss 1.474865198135376
Epoch 126 train loss: 0.7402, eval loss 1.4747536182403564
Epoch 127 train loss: 0.7057, eval loss 1.4743967056274414
Epoch 128 train loss: 0.7479, eval loss 1.473408579826355
Epoch 129 train loss: 0.6898, eval loss 1.472427248954773
Epoch 130 train loss: 0.7451, eval loss 1.472371220588684
Epoch 131 train loss: 0.7183, eval loss 1.4713860750198364
Epoch 132 train loss: 0.7207, eval loss 1.47138512134552
Epoch 133 train loss: 0.6905, eval loss 1.4702881574630737
Epoch 134 train loss: 0.7151, eval loss 1.4696130752563477
Epoch 135 train loss: 0.7383, eval loss 1.4691601991653442
Epoch 136 train loss: 0.6932, eval loss 1.4683960676193237
Epoch 137 train loss: 0.7051, eval loss 1.4679758548736572
Epoch 138 train loss: 0.6829, eval loss 1.4671460390090942
Epoch 139 train loss: 0.7320, eval loss 1.4667654037475586
Epoch 140 train loss: 0.7107, eval loss 1.466544508934021
Epoch 141 train loss: 0.7160, eval loss 1.4667267799377441
Epoch 142 train loss: 0.7213, eval loss 1.4657673835754395
Epoch 143 train loss: 0.7229, eval loss 1.465782880783081
Epoch 144 train loss: 0.7575, eval loss 1.4641485214233398
Epoch 145 train loss: 0.6849, eval loss 1.4639660120010376
Epoch 146 train loss: 0.7438, eval loss 1.4638805389404297
Epoch 147 train loss: 0.7334, eval loss 1.4637503623962402
Epoch 148 train loss: 0.6605, eval loss 1.4628188610076904
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:02:43,528] Trial 14 finished with value: 1.4627571105957031 and parameters: {&#39;hidden_layers_size&#39;: 121, &#39;dropout_p&#39;: 0.29991383317927034, &#39;learning_rate&#39;: 6.0129957046778105e-06, &#39;batch_size&#39;: 215, &#39;l2_reg&#39;: 0.0009516744939626131}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7196, eval loss 1.4627571105957031
Epoch 0 train loss: 1.1965, eval loss 1.7229923009872437
Epoch 1 train loss: 1.0994, eval loss 1.6612000465393066
Epoch 2 train loss: 1.1219, eval loss 1.627011775970459
Epoch 3 train loss: 0.9734, eval loss 1.6005452871322632
Epoch 4 train loss: 0.9406, eval loss 1.578818917274475
Epoch 5 train loss: 0.8827, eval loss 1.560258150100708
Epoch 6 train loss: 0.9022, eval loss 1.5453599691390991
Epoch 7 train loss: 0.8525, eval loss 1.5312225818634033
Epoch 8 train loss: 0.8162, eval loss 1.5202038288116455
Epoch 9 train loss: 0.7948, eval loss 1.5092308521270752
Epoch 10 train loss: 0.8507, eval loss 1.5018463134765625
Epoch 11 train loss: 0.7991, eval loss 1.4939216375350952
Epoch 12 train loss: 0.7755, eval loss 1.489458680152893
Epoch 13 train loss: 0.7466, eval loss 1.4835783243179321
Epoch 14 train loss: 0.8216, eval loss 1.4797132015228271
Epoch 15 train loss: 0.8275, eval loss 1.4761546850204468
Epoch 16 train loss: 0.6950, eval loss 1.4703694581985474
Epoch 17 train loss: 0.7240, eval loss 1.4685450792312622
Epoch 18 train loss: 0.7680, eval loss 1.4656745195388794
Epoch 19 train loss: 0.7634, eval loss 1.463205337524414
Epoch 20 train loss: 0.7628, eval loss 1.461527705192566
Epoch 21 train loss: 0.7211, eval loss 1.4593548774719238
Epoch 22 train loss: 0.7787, eval loss 1.457098126411438
Epoch 23 train loss: 0.7002, eval loss 1.4561187028884888
Epoch 24 train loss: 0.7583, eval loss 1.4554394483566284
Epoch 25 train loss: 0.6764, eval loss 1.4531835317611694
Epoch 26 train loss: 0.6943, eval loss 1.4510449171066284
Epoch 27 train loss: 0.7296, eval loss 1.451075792312622
Epoch 28 train loss: 0.7178, eval loss 1.4500254392623901
Epoch 29 train loss: 0.7614, eval loss 1.4497960805892944
Epoch 30 train loss: 0.7135, eval loss 1.4491852521896362
Epoch 31 train loss: 0.6522, eval loss 1.4475047588348389
Epoch 32 train loss: 0.7119, eval loss 1.4467535018920898
Epoch 33 train loss: 0.6721, eval loss 1.4459953308105469
Epoch 34 train loss: 0.6946, eval loss 1.4447720050811768
Epoch 35 train loss: 0.7276, eval loss 1.4446550607681274
Epoch 36 train loss: 0.6554, eval loss 1.4445022344589233
Epoch 37 train loss: 0.7159, eval loss 1.442472219467163
Epoch 38 train loss: 0.6779, eval loss 1.4426581859588623
Epoch 39 train loss: 0.6776, eval loss 1.4422427415847778
Epoch 40 train loss: 0.6977, eval loss 1.4419164657592773
Epoch 41 train loss: 0.7015, eval loss 1.441953420639038
Epoch 42 train loss: 0.6797, eval loss 1.4410251379013062
Epoch 43 train loss: 0.6084, eval loss 1.4410803318023682
Epoch 44 train loss: 0.6433, eval loss 1.4412370920181274
Epoch 45 train loss: 0.7059, eval loss 1.4396885633468628
Epoch 46 train loss: 0.6702, eval loss 1.439793586730957
Epoch 47 train loss: 0.6195, eval loss 1.4382132291793823
Epoch 48 train loss: 0.7075, eval loss 1.4391202926635742
Epoch 49 train loss: 0.7666, eval loss 1.4385161399841309
Epoch 50 train loss: 0.6372, eval loss 1.4388248920440674
Epoch 51 train loss: 0.7475, eval loss 1.4371999502182007
Epoch 52 train loss: 0.6417, eval loss 1.438188076019287
Epoch 53 train loss: 0.5711, eval loss 1.437935471534729
Epoch 54 train loss: 0.6197, eval loss 1.4368129968643188
Epoch 55 train loss: 0.6344, eval loss 1.437606930732727
Epoch 56 train loss: 0.6032, eval loss 1.4378089904785156
Epoch 57 train loss: 0.6905, eval loss 1.4367454051971436
Epoch 58 train loss: 0.5749, eval loss 1.4358049631118774
Epoch 59 train loss: 0.7271, eval loss 1.4367419481277466
Epoch 60 train loss: 0.5374, eval loss 1.4352587461471558
Epoch 61 train loss: 0.6163, eval loss 1.4358367919921875
Epoch 62 train loss: 0.6065, eval loss 1.4358454942703247
Epoch 63 train loss: 0.5077, eval loss 1.4355512857437134
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:03:06,385] Trial 15 finished with value: 1.4352587461471558 and parameters: {&#39;hidden_layers_size&#39;: 71, &#39;dropout_p&#39;: 0.437871736266903, &#39;learning_rate&#39;: 0.00018625712671515435, &#39;batch_size&#39;: 461, &#39;l2_reg&#39;: 0.0003932995173590204}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4032, eval loss 1.7294985055923462
Epoch 1 train loss: 1.3037, eval loss 1.7234677076339722
Epoch 2 train loss: 1.2648, eval loss 1.7150424718856812
Epoch 3 train loss: 1.3452, eval loss 1.7081843614578247
Epoch 4 train loss: 1.2671, eval loss 1.700881004333496
Epoch 5 train loss: 1.2996, eval loss 1.6951887607574463
Epoch 6 train loss: 1.2462, eval loss 1.6875277757644653
Epoch 7 train loss: 1.2284, eval loss 1.6805890798568726
Epoch 8 train loss: 1.1391, eval loss 1.6751989126205444
Epoch 9 train loss: 1.2244, eval loss 1.6697666645050049
Epoch 10 train loss: 1.1645, eval loss 1.6647183895111084
Epoch 11 train loss: 1.1078, eval loss 1.659447193145752
Epoch 12 train loss: 1.1108, eval loss 1.6550815105438232
Epoch 13 train loss: 1.1122, eval loss 1.649787425994873
Epoch 14 train loss: 1.0835, eval loss 1.6450939178466797
Epoch 15 train loss: 1.1047, eval loss 1.6401314735412598
Epoch 16 train loss: 1.0294, eval loss 1.6355986595153809
Epoch 17 train loss: 1.0643, eval loss 1.6321371793746948
Epoch 18 train loss: 1.0372, eval loss 1.6287575960159302
Epoch 19 train loss: 1.0447, eval loss 1.6240595579147339
Epoch 20 train loss: 1.0620, eval loss 1.6213206052780151
Epoch 21 train loss: 1.0537, eval loss 1.6177815198898315
Epoch 22 train loss: 1.0439, eval loss 1.6137570142745972
Epoch 23 train loss: 1.0176, eval loss 1.6116408109664917
Epoch 24 train loss: 1.0257, eval loss 1.6069014072418213
Epoch 25 train loss: 0.9862, eval loss 1.6041208505630493
Epoch 26 train loss: 1.0595, eval loss 1.6009036302566528
Epoch 27 train loss: 0.9422, eval loss 1.5980719327926636
Epoch 28 train loss: 1.0064, eval loss 1.59475576877594
Epoch 29 train loss: 0.9460, eval loss 1.592268705368042
Epoch 30 train loss: 0.9883, eval loss 1.5900776386260986
Epoch 31 train loss: 0.9453, eval loss 1.5874894857406616
Epoch 32 train loss: 0.9375, eval loss 1.5841524600982666
Epoch 33 train loss: 0.9784, eval loss 1.5816247463226318
Epoch 34 train loss: 0.9328, eval loss 1.5791162252426147
Epoch 35 train loss: 0.9175, eval loss 1.577260136604309
Epoch 36 train loss: 0.9115, eval loss 1.5739381313323975
Epoch 37 train loss: 0.9014, eval loss 1.5718244314193726
Epoch 38 train loss: 0.9018, eval loss 1.5703731775283813
Epoch 39 train loss: 0.9222, eval loss 1.5670723915100098
Epoch 40 train loss: 0.8726, eval loss 1.5660054683685303
Epoch 41 train loss: 0.8873, eval loss 1.5636731386184692
Epoch 42 train loss: 0.8991, eval loss 1.5615546703338623
Epoch 43 train loss: 0.8841, eval loss 1.560177206993103
Epoch 44 train loss: 0.9099, eval loss 1.5583606958389282
Epoch 45 train loss: 0.8900, eval loss 1.5557101964950562
Epoch 46 train loss: 0.8893, eval loss 1.554482102394104
Epoch 47 train loss: 0.8502, eval loss 1.552092432975769
Epoch 48 train loss: 0.8374, eval loss 1.5505481958389282
Epoch 49 train loss: 0.8948, eval loss 1.5489269495010376
Epoch 50 train loss: 0.8719, eval loss 1.546019434928894
Epoch 51 train loss: 0.9034, eval loss 1.5449676513671875
Epoch 52 train loss: 0.8336, eval loss 1.5422923564910889
Epoch 53 train loss: 0.8408, eval loss 1.5412081480026245
Epoch 54 train loss: 0.8634, eval loss 1.5404728651046753
Epoch 55 train loss: 0.8414, eval loss 1.537904143333435
Epoch 56 train loss: 0.8113, eval loss 1.5358864068984985
Epoch 57 train loss: 0.8155, eval loss 1.5349228382110596
Epoch 58 train loss: 0.8481, eval loss 1.5341768264770508
Epoch 59 train loss: 0.8243, eval loss 1.5322972536087036
Epoch 60 train loss: 0.8190, eval loss 1.5312844514846802
Epoch 61 train loss: 0.7863, eval loss 1.5295488834381104
Epoch 62 train loss: 0.8452, eval loss 1.5288245677947998
Epoch 63 train loss: 0.8384, eval loss 1.527420997619629
Epoch 64 train loss: 0.8770, eval loss 1.5257296562194824
Epoch 65 train loss: 0.8065, eval loss 1.5244337320327759
Epoch 66 train loss: 0.8084, eval loss 1.5234249830245972
Epoch 67 train loss: 0.8289, eval loss 1.521203637123108
Epoch 68 train loss: 0.8023, eval loss 1.520541787147522
Epoch 69 train loss: 0.8155, eval loss 1.5191375017166138
Epoch 70 train loss: 0.8348, eval loss 1.5182442665100098
Epoch 71 train loss: 0.7992, eval loss 1.5159640312194824
Epoch 72 train loss: 0.8106, eval loss 1.5154958963394165
Epoch 73 train loss: 0.7732, eval loss 1.5142322778701782
Epoch 74 train loss: 0.8285, eval loss 1.5128520727157593
Epoch 75 train loss: 0.8323, eval loss 1.5114768743515015
Epoch 76 train loss: 0.8103, eval loss 1.5116199254989624
Epoch 77 train loss: 0.7845, eval loss 1.5097206830978394
Epoch 78 train loss: 0.8186, eval loss 1.5088664293289185
Epoch 79 train loss: 0.8075, eval loss 1.5080384016036987
Epoch 80 train loss: 0.8072, eval loss 1.5066016912460327
Epoch 81 train loss: 0.7601, eval loss 1.5052473545074463
Epoch 82 train loss: 0.7883, eval loss 1.5051946640014648
Epoch 83 train loss: 0.7800, eval loss 1.5039970874786377
Epoch 84 train loss: 0.8037, eval loss 1.5026942491531372
Epoch 85 train loss: 0.7500, eval loss 1.5018819570541382
Epoch 86 train loss: 0.7482, eval loss 1.5004186630249023
Epoch 87 train loss: 0.7848, eval loss 1.5002609491348267
Epoch 88 train loss: 0.7908, eval loss 1.4991527795791626
Epoch 89 train loss: 0.8240, eval loss 1.4981611967086792
Epoch 90 train loss: 0.7476, eval loss 1.4978272914886475
Epoch 91 train loss: 0.7730, eval loss 1.4964680671691895
Epoch 92 train loss: 0.7364, eval loss 1.4959276914596558
Epoch 93 train loss: 0.8080, eval loss 1.4950522184371948
Epoch 94 train loss: 0.7432, eval loss 1.4934895038604736
Epoch 95 train loss: 0.7565, eval loss 1.492944359779358
Epoch 96 train loss: 0.8040, eval loss 1.4915424585342407
Epoch 97 train loss: 0.7121, eval loss 1.491189956665039
Epoch 98 train loss: 0.7679, eval loss 1.4908051490783691
Epoch 99 train loss: 0.7518, eval loss 1.4900346994400024
Epoch 100 train loss: 0.7985, eval loss 1.4894148111343384
Epoch 101 train loss: 0.7392, eval loss 1.4884260892868042
Epoch 102 train loss: 0.7346, eval loss 1.488081932067871
Epoch 103 train loss: 0.7512, eval loss 1.4871083498001099
Epoch 104 train loss: 0.7385, eval loss 1.485919713973999
Epoch 105 train loss: 0.7443, eval loss 1.4865111112594604
Epoch 106 train loss: 0.7650, eval loss 1.4851058721542358
Epoch 107 train loss: 0.7857, eval loss 1.483662486076355
Epoch 108 train loss: 0.7389, eval loss 1.4839482307434082
Epoch 109 train loss: 0.7557, eval loss 1.4830716848373413
Epoch 110 train loss: 0.7328, eval loss 1.4823977947235107
Epoch 111 train loss: 0.7620, eval loss 1.4814033508300781
Epoch 112 train loss: 0.7532, eval loss 1.4810233116149902
Epoch 113 train loss: 0.7433, eval loss 1.4803357124328613
Epoch 114 train loss: 0.7776, eval loss 1.4800491333007812
Epoch 115 train loss: 0.6871, eval loss 1.4791650772094727
Epoch 116 train loss: 0.7235, eval loss 1.4790760278701782
Epoch 117 train loss: 0.7193, eval loss 1.4784877300262451
Epoch 118 train loss: 0.7785, eval loss 1.47694993019104
Epoch 119 train loss: 0.7623, eval loss 1.4767720699310303
Epoch 120 train loss: 0.6901, eval loss 1.4758062362670898
Epoch 121 train loss: 0.7356, eval loss 1.4757412672042847
Epoch 122 train loss: 0.7475, eval loss 1.4749208688735962
Epoch 123 train loss: 0.7074, eval loss 1.4745765924453735
Epoch 124 train loss: 0.7545, eval loss 1.4738744497299194
Epoch 125 train loss: 0.7649, eval loss 1.4728862047195435
Epoch 126 train loss: 0.7214, eval loss 1.4727572202682495
Epoch 127 train loss: 0.7279, eval loss 1.4723149538040161
Epoch 128 train loss: 0.7010, eval loss 1.4728752374649048
Epoch 129 train loss: 0.7239, eval loss 1.4717013835906982
Epoch 130 train loss: 0.6886, eval loss 1.4712884426116943
Epoch 131 train loss: 0.7142, eval loss 1.4711426496505737
Epoch 132 train loss: 0.7560, eval loss 1.4702496528625488
Epoch 133 train loss: 0.7252, eval loss 1.470263957977295
Epoch 134 train loss: 0.7335, eval loss 1.4695115089416504
Epoch 135 train loss: 0.7199, eval loss 1.468845248222351
Epoch 136 train loss: 0.6998, eval loss 1.4683955907821655
Epoch 137 train loss: 0.7112, eval loss 1.468226432800293
Epoch 138 train loss: 0.7025, eval loss 1.4680956602096558
Epoch 139 train loss: 0.7697, eval loss 1.467373013496399
Epoch 140 train loss: 0.7135, eval loss 1.4667811393737793
Epoch 141 train loss: 0.7153, eval loss 1.4664604663848877
Epoch 142 train loss: 0.6942, eval loss 1.46535325050354
Epoch 143 train loss: 0.7371, eval loss 1.4655250310897827
Epoch 144 train loss: 0.7277, eval loss 1.4654439687728882
Epoch 145 train loss: 0.6870, eval loss 1.4645206928253174
Epoch 146 train loss: 0.7514, eval loss 1.4641609191894531
Epoch 147 train loss: 0.7260, eval loss 1.4642982482910156
Epoch 148 train loss: 0.7304, eval loss 1.4637410640716553
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:04:09,529] Trial 16 finished with value: 1.4637410640716553 and parameters: {&#39;hidden_layers_size&#39;: 107, &#39;dropout_p&#39;: 0.39266611891718056, &#39;learning_rate&#39;: 9.495161071185034e-06, &#39;batch_size&#39;: 295, &#39;l2_reg&#39;: 7.64616524773608e-05}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7479, eval loss 1.4639668464660645
Epoch 0 train loss: 1.1123, eval loss 1.6468656063079834
Epoch 1 train loss: 1.0239, eval loss 1.5952845811843872
Epoch 2 train loss: 0.9695, eval loss 1.5622106790542603
Epoch 3 train loss: 0.8154, eval loss 1.5402562618255615
Epoch 4 train loss: 0.8050, eval loss 1.5221784114837646
Epoch 5 train loss: 0.8156, eval loss 1.5089564323425293
Epoch 6 train loss: 0.7940, eval loss 1.49684739112854
Epoch 7 train loss: 0.7689, eval loss 1.488135814666748
Epoch 8 train loss: 0.7531, eval loss 1.4811172485351562
Epoch 9 train loss: 0.7354, eval loss 1.4740455150604248
Epoch 10 train loss: 0.7903, eval loss 1.4686981439590454
Epoch 11 train loss: 0.7370, eval loss 1.4643141031265259
Epoch 12 train loss: 0.6562, eval loss 1.4606893062591553
Epoch 13 train loss: 0.7646, eval loss 1.457921028137207
Epoch 14 train loss: 0.7465, eval loss 1.4551681280136108
Epoch 15 train loss: 0.7428, eval loss 1.45291268825531
Epoch 16 train loss: 0.7621, eval loss 1.450881004333496
Epoch 17 train loss: 0.7122, eval loss 1.4477850198745728
Epoch 18 train loss: 0.6664, eval loss 1.4470264911651611
Epoch 19 train loss: 0.7078, eval loss 1.4462069272994995
Epoch 20 train loss: 0.6686, eval loss 1.4447389841079712
Epoch 21 train loss: 0.6657, eval loss 1.4434709548950195
Epoch 22 train loss: 0.7260, eval loss 1.4432791471481323
Epoch 23 train loss: 0.6543, eval loss 1.4418048858642578
Epoch 24 train loss: 0.7559, eval loss 1.4409958124160767
Epoch 25 train loss: 0.6988, eval loss 1.4399586915969849
Epoch 26 train loss: 0.6408, eval loss 1.4392576217651367
Epoch 27 train loss: 0.6103, eval loss 1.4391207695007324
Epoch 28 train loss: 0.6380, eval loss 1.4388588666915894
Epoch 29 train loss: 0.6269, eval loss 1.438184380531311
Epoch 30 train loss: 0.5537, eval loss 1.4370681047439575
Epoch 31 train loss: 0.7125, eval loss 1.437332272529602
Epoch 32 train loss: 0.6346, eval loss 1.436058521270752
Epoch 33 train loss: 0.6081, eval loss 1.4364352226257324
Epoch 34 train loss: 0.6112, eval loss 1.435857892036438
Epoch 35 train loss: 0.5416, eval loss 1.4353270530700684
Epoch 36 train loss: 0.7010, eval loss 1.4350593090057373
Epoch 37 train loss: 0.6511, eval loss 1.4351696968078613
Epoch 38 train loss: 0.6214, eval loss 1.4347686767578125
Epoch 39 train loss: 0.6849, eval loss 1.4337741136550903
Epoch 40 train loss: 0.5689, eval loss 1.4346067905426025
Epoch 41 train loss: 0.6732, eval loss 1.4341497421264648
Epoch 42 train loss: 0.6964, eval loss 1.4336254596710205
Epoch 43 train loss: 0.5712, eval loss 1.4326844215393066
Epoch 44 train loss: 0.6676, eval loss 1.43317449092865
Epoch 45 train loss: 0.6512, eval loss 1.4331047534942627
Epoch 46 train loss: 0.6076, eval loss 1.4330103397369385
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:04:33,116] Trial 17 finished with value: 1.4326844215393066 and parameters: {&#39;hidden_layers_size&#39;: 134, &#39;dropout_p&#39;: 0.3366923291272439, &#39;learning_rate&#39;: 9.204712398723734e-05, &#39;batch_size&#39;: 212, &#39;l2_reg&#39;: 0.00018896143933117384}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.0890, eval loss 1.6460046768188477
Epoch 1 train loss: 0.9197, eval loss 1.5881035327911377
Epoch 2 train loss: 0.8918, eval loss 1.552332878112793
Epoch 3 train loss: 0.8152, eval loss 1.5277966260910034
Epoch 4 train loss: 0.8186, eval loss 1.509259819984436
Epoch 5 train loss: 0.7817, eval loss 1.4949637651443481
Epoch 6 train loss: 0.7019, eval loss 1.4851161241531372
Epoch 7 train loss: 0.7188, eval loss 1.4770994186401367
Epoch 8 train loss: 0.6954, eval loss 1.469916582107544
Epoch 9 train loss: 0.7371, eval loss 1.4644482135772705
Epoch 10 train loss: 0.6890, eval loss 1.4599238634109497
Epoch 11 train loss: 0.7532, eval loss 1.4572826623916626
Epoch 12 train loss: 0.7325, eval loss 1.4546782970428467
Epoch 13 train loss: 0.7467, eval loss 1.4518240690231323
Epoch 14 train loss: 0.7030, eval loss 1.4500946998596191
Epoch 15 train loss: 0.6650, eval loss 1.448241114616394
Epoch 16 train loss: 0.6627, eval loss 1.4467077255249023
Epoch 17 train loss: 0.6967, eval loss 1.4456870555877686
Epoch 18 train loss: 0.7667, eval loss 1.4438281059265137
Epoch 19 train loss: 0.6989, eval loss 1.442477822303772
Epoch 20 train loss: 0.6860, eval loss 1.4422006607055664
Epoch 21 train loss: 0.7199, eval loss 1.440866470336914
Epoch 22 train loss: 0.6641, eval loss 1.4404094219207764
Epoch 23 train loss: 0.7055, eval loss 1.4395477771759033
Epoch 24 train loss: 0.7242, eval loss 1.4400790929794312
Epoch 25 train loss: 0.6681, eval loss 1.4387720823287964
Epoch 26 train loss: 0.6686, eval loss 1.4383976459503174
Epoch 27 train loss: 0.6281, eval loss 1.4368913173675537
Epoch 28 train loss: 0.6836, eval loss 1.4365956783294678
Epoch 29 train loss: 0.7353, eval loss 1.4366986751556396
Epoch 30 train loss: 0.6782, eval loss 1.4364500045776367
Epoch 31 train loss: 0.6740, eval loss 1.436387300491333
Epoch 32 train loss: 0.6888, eval loss 1.4350252151489258
Epoch 33 train loss: 0.6733, eval loss 1.4354852437973022
Epoch 34 train loss: 0.6790, eval loss 1.4356602430343628
Epoch 35 train loss: 0.7082, eval loss 1.4356234073638916
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:04:50,505] Trial 18 finished with value: 1.4350252151489258 and parameters: {&#39;hidden_layers_size&#39;: 94, &#39;dropout_p&#39;: 0.3038518730514599, &#39;learning_rate&#39;: 0.00011458291191919601, &#39;batch_size&#39;: 193, &#39;l2_reg&#39;: 0.00014386059578503607}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.0512, eval loss 1.4317905902862549
Epoch 1 train loss: 0.8688, eval loss 1.4331815242767334
Epoch 2 train loss: 0.5396, eval loss 1.4314998388290405
Epoch 3 train loss: 0.6318, eval loss 1.4319485425949097
Epoch 4 train loss: 0.7159, eval loss 1.431221842765808
Epoch 5 train loss: 0.5695, eval loss 1.4277889728546143
Epoch 6 train loss: 0.5628, eval loss 1.4275132417678833
Epoch 7 train loss: 0.4138, eval loss 1.4268102645874023
Epoch 8 train loss: 0.4200, eval loss 1.429624319076538
Epoch 9 train loss: 0.5735, eval loss 1.4269088506698608
Epoch 10 train loss: 0.3999, eval loss 1.428053617477417
Epoch 11 train loss: 0.3550, eval loss 1.426342487335205
Epoch 12 train loss: 0.5195, eval loss 1.425267219543457
Epoch 13 train loss: 0.4006, eval loss 1.4240643978118896
Epoch 14 train loss: 0.3292, eval loss 1.4246742725372314
Epoch 15 train loss: 0.3529, eval loss 1.4248906373977661
Epoch 16 train loss: 0.2981, eval loss 1.425062894821167
Epoch 17 train loss: 0.2729, eval loss 1.4224984645843506
Epoch 18 train loss: 0.5064, eval loss 1.4244859218597412
Epoch 19 train loss: 0.3513, eval loss 1.4240081310272217
Epoch 20 train loss: 0.3307, eval loss 1.4238722324371338
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:04:59,125] Trial 19 finished with value: 1.4224984645843506 and parameters: {&#39;hidden_layers_size&#39;: 128, &#39;dropout_p&#39;: 0.4422921623955842, &#39;learning_rate&#39;: 0.005511537710141839, &#39;batch_size&#39;: 341, &#39;l2_reg&#39;: 2.3874142479923986e-05}. Best is trial 10 with value: 1.604019045829773.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4443, eval loss 1.7709441184997559
Epoch 1 train loss: 1.4473, eval loss 1.769761085510254
Epoch 2 train loss: 1.4151, eval loss 1.7692837715148926
Epoch 3 train loss: 1.4558, eval loss 1.767385482788086
Epoch 4 train loss: 1.3998, eval loss 1.7662322521209717
Epoch 5 train loss: 1.4646, eval loss 1.7656043767929077
Epoch 6 train loss: 1.4819, eval loss 1.765187382698059
Epoch 7 train loss: 1.4732, eval loss 1.7631601095199585
Epoch 8 train loss: 1.4541, eval loss 1.762381672859192
Epoch 9 train loss: 1.4287, eval loss 1.7601577043533325
Epoch 10 train loss: 1.4196, eval loss 1.7594207525253296
Epoch 11 train loss: 1.4224, eval loss 1.759424090385437
Epoch 12 train loss: 1.3831, eval loss 1.7568528652191162
Epoch 13 train loss: 1.3857, eval loss 1.7559165954589844
Epoch 14 train loss: 1.3854, eval loss 1.7551696300506592
Epoch 15 train loss: 1.3981, eval loss 1.7531284093856812
Epoch 16 train loss: 1.3655, eval loss 1.7532397508621216
Epoch 17 train loss: 1.4061, eval loss 1.7518978118896484
Epoch 18 train loss: 1.3961, eval loss 1.7497122287750244
Epoch 19 train loss: 1.4125, eval loss 1.74912428855896
Epoch 20 train loss: 1.4049, eval loss 1.7488234043121338
Epoch 21 train loss: 1.3354, eval loss 1.7483649253845215
Epoch 22 train loss: 1.3812, eval loss 1.7466039657592773
Epoch 23 train loss: 1.3642, eval loss 1.7454758882522583
Epoch 24 train loss: 1.3496, eval loss 1.7443695068359375
Epoch 25 train loss: 1.3710, eval loss 1.7430347204208374
Epoch 26 train loss: 1.3826, eval loss 1.742311954498291
Epoch 27 train loss: 1.3532, eval loss 1.7409262657165527
Epoch 28 train loss: 1.3427, eval loss 1.7395809888839722
Epoch 29 train loss: 1.3231, eval loss 1.739061951637268
Epoch 30 train loss: 1.3415, eval loss 1.7386006116867065
Epoch 31 train loss: 1.3482, eval loss 1.7369871139526367
Epoch 32 train loss: 1.3859, eval loss 1.7360285520553589
Epoch 33 train loss: 1.3192, eval loss 1.734147310256958
Epoch 34 train loss: 1.3425, eval loss 1.7336803674697876
Epoch 35 train loss: 1.3501, eval loss 1.732131004333496
Epoch 36 train loss: 1.3489, eval loss 1.731186866760254
Epoch 37 train loss: 1.3211, eval loss 1.7311885356903076
Epoch 38 train loss: 1.3021, eval loss 1.7306135892868042
Epoch 39 train loss: 1.3093, eval loss 1.7288172245025635
Epoch 40 train loss: 1.3367, eval loss 1.7272781133651733
Epoch 41 train loss: 1.3250, eval loss 1.7270042896270752
Epoch 42 train loss: 1.3551, eval loss 1.7254087924957275
Epoch 43 train loss: 1.3133, eval loss 1.7255879640579224
Epoch 44 train loss: 1.3390, eval loss 1.723724603652954
Epoch 45 train loss: 1.3233, eval loss 1.7232447862625122
Epoch 46 train loss: 1.3137, eval loss 1.721996784210205
Epoch 47 train loss: 1.2611, eval loss 1.720478892326355
Epoch 48 train loss: 1.3049, eval loss 1.7194079160690308
Epoch 49 train loss: 1.3052, eval loss 1.7181870937347412
Epoch 50 train loss: 1.2939, eval loss 1.7181614637374878
Epoch 51 train loss: 1.2563, eval loss 1.7172253131866455
Epoch 52 train loss: 1.2998, eval loss 1.7155989408493042
Epoch 53 train loss: 1.3055, eval loss 1.715700387954712
Epoch 54 train loss: 1.2465, eval loss 1.7141871452331543
Epoch 55 train loss: 1.2537, eval loss 1.7128559350967407
Epoch 56 train loss: 1.2852, eval loss 1.7121779918670654
Epoch 57 train loss: 1.2623, eval loss 1.7111788988113403
Epoch 58 train loss: 1.2407, eval loss 1.7106541395187378
Epoch 59 train loss: 1.2201, eval loss 1.7093825340270996
Epoch 60 train loss: 1.2450, eval loss 1.7089850902557373
Epoch 61 train loss: 1.2551, eval loss 1.708899974822998
Epoch 62 train loss: 1.2315, eval loss 1.7074428796768188
Epoch 63 train loss: 1.2710, eval loss 1.7059032917022705
Epoch 64 train loss: 1.2467, eval loss 1.7055450677871704
Epoch 65 train loss: 1.2503, eval loss 1.704084873199463
Epoch 66 train loss: 1.2234, eval loss 1.7031430006027222
Epoch 67 train loss: 1.2606, eval loss 1.7009117603302002
Epoch 68 train loss: 1.2215, eval loss 1.7015644311904907
Epoch 69 train loss: 1.2322, eval loss 1.6999163627624512
Epoch 70 train loss: 1.2776, eval loss 1.6997497081756592
Epoch 71 train loss: 1.2539, eval loss 1.699523687362671
Epoch 72 train loss: 1.2129, eval loss 1.697155237197876
Epoch 73 train loss: 1.1969, eval loss 1.6976526975631714
Epoch 74 train loss: 1.2373, eval loss 1.6963287591934204
Epoch 75 train loss: 1.2391, eval loss 1.6955171823501587
Epoch 76 train loss: 1.2060, eval loss 1.6940876245498657
Epoch 77 train loss: 1.2068, eval loss 1.6933999061584473
Epoch 78 train loss: 1.2341, eval loss 1.6931960582733154
Epoch 79 train loss: 1.1688, eval loss 1.6913490295410156
Epoch 80 train loss: 1.2507, eval loss 1.6903632879257202
Epoch 81 train loss: 1.1854, eval loss 1.6897671222686768
Epoch 82 train loss: 1.2209, eval loss 1.6900911331176758
Epoch 83 train loss: 1.2507, eval loss 1.6889501810073853
Epoch 84 train loss: 1.1655, eval loss 1.686850666999817
Epoch 85 train loss: 1.1693, eval loss 1.6866344213485718
Epoch 86 train loss: 1.2049, eval loss 1.6864694356918335
Epoch 87 train loss: 1.1924, eval loss 1.6853011846542358
Epoch 88 train loss: 1.2004, eval loss 1.6842775344848633
Epoch 89 train loss: 1.1598, eval loss 1.6833305358886719
Epoch 90 train loss: 1.1931, eval loss 1.6819392442703247
Epoch 91 train loss: 1.1713, eval loss 1.6825287342071533
Epoch 92 train loss: 1.1393, eval loss 1.6813730001449585
Epoch 93 train loss: 1.1787, eval loss 1.6808356046676636
Epoch 94 train loss: 1.1538, eval loss 1.6795673370361328
Epoch 95 train loss: 1.1687, eval loss 1.6786307096481323
Epoch 96 train loss: 1.1422, eval loss 1.678231120109558
Epoch 97 train loss: 1.1363, eval loss 1.6771743297576904
Epoch 98 train loss: 1.1769, eval loss 1.6762734651565552
Epoch 99 train loss: 1.1698, eval loss 1.6764785051345825
Epoch 100 train loss: 1.1813, eval loss 1.6746916770935059
Epoch 101 train loss: 1.1476, eval loss 1.6732432842254639
Epoch 102 train loss: 1.1461, eval loss 1.673274278640747
Epoch 103 train loss: 1.1441, eval loss 1.6724848747253418
Epoch 104 train loss: 1.1311, eval loss 1.6707789897918701
Epoch 105 train loss: 1.1491, eval loss 1.6712826490402222
Epoch 106 train loss: 1.1195, eval loss 1.6699340343475342
Epoch 107 train loss: 1.1670, eval loss 1.670265793800354
Epoch 108 train loss: 1.1391, eval loss 1.6682604551315308
Epoch 109 train loss: 1.1408, eval loss 1.6690868139266968
Epoch 110 train loss: 1.1395, eval loss 1.6675574779510498
Epoch 111 train loss: 1.1332, eval loss 1.6659936904907227
Epoch 112 train loss: 1.1455, eval loss 1.666291356086731
Epoch 113 train loss: 1.1245, eval loss 1.6643245220184326
Epoch 114 train loss: 1.1396, eval loss 1.6648701429367065
Epoch 115 train loss: 1.1124, eval loss 1.6624542474746704
Epoch 116 train loss: 1.1334, eval loss 1.662988305091858
Epoch 117 train loss: 1.1438, eval loss 1.6621911525726318
Epoch 118 train loss: 1.1469, eval loss 1.6606717109680176
Epoch 119 train loss: 1.1515, eval loss 1.6600812673568726
Epoch 120 train loss: 1.1130, eval loss 1.6594557762145996
Epoch 121 train loss: 1.1175, eval loss 1.6595051288604736
Epoch 122 train loss: 1.1588, eval loss 1.658706784248352
Epoch 123 train loss: 1.1192, eval loss 1.6584532260894775
Epoch 124 train loss: 1.1016, eval loss 1.6570827960968018
Epoch 125 train loss: 1.1240, eval loss 1.6569403409957886
Epoch 126 train loss: 1.1143, eval loss 1.6559182405471802
Epoch 127 train loss: 1.0916, eval loss 1.654486060142517
Epoch 128 train loss: 1.1237, eval loss 1.6539556980133057
Epoch 129 train loss: 1.1024, eval loss 1.653713583946228
Epoch 130 train loss: 1.1087, eval loss 1.652287483215332
Epoch 131 train loss: 1.0922, eval loss 1.652044415473938
Epoch 132 train loss: 1.1201, eval loss 1.6513556241989136
Epoch 133 train loss: 1.0793, eval loss 1.6516811847686768
Epoch 134 train loss: 1.0812, eval loss 1.6496145725250244
Epoch 135 train loss: 1.0750, eval loss 1.6495591402053833
Epoch 136 train loss: 1.1007, eval loss 1.6484277248382568
Epoch 137 train loss: 1.1189, eval loss 1.6487452983856201
Epoch 138 train loss: 1.0846, eval loss 1.6475638151168823
Epoch 139 train loss: 1.1092, eval loss 1.647822380065918
Epoch 140 train loss: 1.0838, eval loss 1.6465013027191162
Epoch 141 train loss: 1.0758, eval loss 1.6466832160949707
Epoch 142 train loss: 1.0683, eval loss 1.6454957723617554
Epoch 143 train loss: 1.0895, eval loss 1.643575668334961
Epoch 144 train loss: 1.0587, eval loss 1.6443095207214355
Epoch 145 train loss: 1.0496, eval loss 1.6430078744888306
Epoch 146 train loss: 1.0537, eval loss 1.6424428224563599
Epoch 147 train loss: 1.0492, eval loss 1.6427032947540283
Epoch 148 train loss: 1.1013, eval loss 1.6402353048324585
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:05:53,438] Trial 20 finished with value: 1.6402353048324585 and parameters: {&#39;hidden_layers_size&#39;: 60, &#39;dropout_p&#39;: 0.3995040408348781, &#39;learning_rate&#39;: 3.318907011962408e-06, &#39;batch_size&#39;: 349, &#39;l2_reg&#39;: 0.00010193425277998233}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 1.0321, eval loss 1.6405385732650757
Epoch 0 train loss: 1.3830, eval loss 1.7371782064437866
Epoch 1 train loss: 1.2807, eval loss 1.696141004562378
Epoch 2 train loss: 1.2397, eval loss 1.6649166345596313
Epoch 3 train loss: 1.0758, eval loss 1.6402961015701294
Epoch 4 train loss: 1.0515, eval loss 1.620387315750122
Epoch 5 train loss: 1.0202, eval loss 1.605616807937622
Epoch 6 train loss: 0.9638, eval loss 1.5902318954467773
Epoch 7 train loss: 0.9073, eval loss 1.5799126625061035
Epoch 8 train loss: 0.8905, eval loss 1.5675199031829834
Epoch 9 train loss: 0.8480, eval loss 1.5578429698944092
Epoch 10 train loss: 0.9143, eval loss 1.5495572090148926
Epoch 11 train loss: 0.8841, eval loss 1.5412238836288452
Epoch 12 train loss: 0.8395, eval loss 1.5348477363586426
Epoch 13 train loss: 0.7609, eval loss 1.5291043519973755
Epoch 14 train loss: 0.7893, eval loss 1.522608757019043
Epoch 15 train loss: 0.7817, eval loss 1.5172967910766602
Epoch 16 train loss: 0.8228, eval loss 1.5120371580123901
Epoch 17 train loss: 0.7324, eval loss 1.507459044456482
Epoch 18 train loss: 0.8117, eval loss 1.504860281944275
Epoch 19 train loss: 0.7425, eval loss 1.5001507997512817
Epoch 20 train loss: 0.8056, eval loss 1.4965384006500244
Epoch 21 train loss: 0.7756, eval loss 1.4935815334320068
Epoch 22 train loss: 0.8186, eval loss 1.4898409843444824
Epoch 23 train loss: 0.7236, eval loss 1.4875209331512451
Epoch 24 train loss: 0.7971, eval loss 1.4843436479568481
Epoch 25 train loss: 0.7459, eval loss 1.482652187347412
Epoch 26 train loss: 0.7589, eval loss 1.4800506830215454
Epoch 27 train loss: 0.7395, eval loss 1.478090763092041
Epoch 28 train loss: 0.6652, eval loss 1.476558804512024
Epoch 29 train loss: 0.6782, eval loss 1.4741922616958618
Epoch 30 train loss: 0.7192, eval loss 1.4721797704696655
Epoch 31 train loss: 0.6831, eval loss 1.4708291292190552
Epoch 32 train loss: 0.6892, eval loss 1.4691131114959717
Epoch 33 train loss: 0.7128, eval loss 1.4678086042404175
Epoch 34 train loss: 0.7004, eval loss 1.467305064201355
Epoch 35 train loss: 0.7386, eval loss 1.4657089710235596
Epoch 36 train loss: 0.7261, eval loss 1.4636917114257812
Epoch 37 train loss: 0.7071, eval loss 1.463066577911377
Epoch 38 train loss: 0.7095, eval loss 1.4624637365341187
Epoch 39 train loss: 0.7304, eval loss 1.4615973234176636
Epoch 40 train loss: 0.7221, eval loss 1.459319829940796
Epoch 41 train loss: 0.6425, eval loss 1.4586422443389893
Epoch 42 train loss: 0.6327, eval loss 1.458749532699585
Epoch 43 train loss: 0.7070, eval loss 1.4565155506134033
Epoch 44 train loss: 0.6759, eval loss 1.4566681385040283
Epoch 45 train loss: 0.7634, eval loss 1.4554880857467651
Epoch 46 train loss: 0.6710, eval loss 1.4557381868362427
Epoch 47 train loss: 0.6936, eval loss 1.454275369644165
Epoch 48 train loss: 0.6504, eval loss 1.4536420106887817
Epoch 49 train loss: 0.7403, eval loss 1.4541763067245483
Epoch 50 train loss: 0.7858, eval loss 1.4527268409729004
Epoch 51 train loss: 0.7213, eval loss 1.4524339437484741
Epoch 52 train loss: 0.7364, eval loss 1.4510122537612915
Epoch 53 train loss: 0.6778, eval loss 1.4511215686798096
Epoch 54 train loss: 0.7029, eval loss 1.450154423713684
Epoch 55 train loss: 0.6977, eval loss 1.450442910194397
Epoch 56 train loss: 0.6777, eval loss 1.4497593641281128
Epoch 57 train loss: 0.6913, eval loss 1.4498450756072998
Epoch 58 train loss: 0.6838, eval loss 1.449217438697815
Epoch 59 train loss: 0.6872, eval loss 1.448731541633606
Epoch 60 train loss: 0.6833, eval loss 1.4477094411849976
Epoch 61 train loss: 0.7113, eval loss 1.4480429887771606
Epoch 62 train loss: 0.6599, eval loss 1.4478832483291626
Epoch 63 train loss: 0.6750, eval loss 1.4477041959762573
Epoch 64 train loss: 0.7093, eval loss 1.4466286897659302
Epoch 65 train loss: 0.6989, eval loss 1.4464609622955322
Epoch 66 train loss: 0.6696, eval loss 1.4470936059951782
Epoch 67 train loss: 0.7011, eval loss 1.4460997581481934
Epoch 68 train loss: 0.7000, eval loss 1.44597589969635
Epoch 69 train loss: 0.6781, eval loss 1.4454947710037231
Epoch 70 train loss: 0.6953, eval loss 1.4452099800109863
Epoch 71 train loss: 0.7324, eval loss 1.446273684501648
Epoch 72 train loss: 0.6983, eval loss 1.4451404809951782
Epoch 73 train loss: 0.7080, eval loss 1.4449023008346558
Epoch 74 train loss: 0.6968, eval loss 1.4447218179702759
Epoch 75 train loss: 0.6943, eval loss 1.4437730312347412
Epoch 76 train loss: 0.6719, eval loss 1.4441189765930176
Epoch 77 train loss: 0.6130, eval loss 1.4445521831512451
Epoch 78 train loss: 0.7207, eval loss 1.4442873001098633
Epoch 79 train loss: 0.6280, eval loss 1.4431986808776855
Epoch 80 train loss: 0.6880, eval loss 1.4425749778747559
Epoch 81 train loss: 0.6945, eval loss 1.4428850412368774
Epoch 82 train loss: 0.7365, eval loss 1.443195104598999
Epoch 83 train loss: 0.6768, eval loss 1.4433842897415161
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:06:39,212] Trial 21 finished with value: 1.4425749778747559 and parameters: {&#39;hidden_layers_size&#39;: 210, &#39;dropout_p&#39;: 0.4443365775135407, &#39;learning_rate&#39;: 2.5065943882363546e-05, &#39;batch_size&#39;: 213, &#39;l2_reg&#39;: 1.3005984918832581e-05}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7789, eval loss 1.4850879907608032
Epoch 1 train loss: 0.7604, eval loss 1.4539666175842285
Epoch 2 train loss: 0.7526, eval loss 1.449983835220337
Epoch 3 train loss: 0.7159, eval loss 1.4458825588226318
Epoch 4 train loss: 0.6785, eval loss 1.4421112537384033
Epoch 5 train loss: 0.7153, eval loss 1.442028522491455
Epoch 6 train loss: 0.7099, eval loss 1.43940007686615
Epoch 7 train loss: 0.6742, eval loss 1.4411336183547974
Epoch 8 train loss: 0.6895, eval loss 1.4382628202438354
Epoch 9 train loss: 0.7108, eval loss 1.43754243850708
Epoch 10 train loss: 0.6746, eval loss 1.43584144115448
Epoch 11 train loss: 0.7077, eval loss 1.4382853507995605
Epoch 12 train loss: 0.7041, eval loss 1.4350024461746216
Epoch 13 train loss: 0.6717, eval loss 1.4353976249694824
Epoch 14 train loss: 0.6780, eval loss 1.43459951877594
Epoch 15 train loss: 0.6887, eval loss 1.4354734420776367
Epoch 16 train loss: 0.6831, eval loss 1.4336670637130737
Epoch 17 train loss: 0.6808, eval loss 1.4325919151306152
Epoch 18 train loss: 0.6926, eval loss 1.4353444576263428
Epoch 19 train loss: 0.6418, eval loss 1.4334651231765747
Epoch 20 train loss: 0.6602, eval loss 1.4313865900039673
Epoch 21 train loss: 0.6833, eval loss 1.4331157207489014
Epoch 22 train loss: 0.6615, eval loss 1.4316421747207642
Epoch 23 train loss: 0.6376, eval loss 1.4300856590270996
Epoch 24 train loss: 0.6509, eval loss 1.4318130016326904
Epoch 25 train loss: 0.6923, eval loss 1.429935097694397
Epoch 26 train loss: 0.6794, eval loss 1.4303407669067383
Epoch 27 train loss: 0.6736, eval loss 1.4311649799346924
Epoch 28 train loss: 0.6613, eval loss 1.427552580833435
Epoch 29 train loss: 0.6451, eval loss 1.4286506175994873
Epoch 30 train loss: 0.6639, eval loss 1.4300708770751953
Epoch 31 train loss: 0.6457, eval loss 1.4288045167922974
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:06:50,282] Trial 22 finished with value: 1.427552580833435 and parameters: {&#39;hidden_layers_size&#39;: 69, &#39;dropout_p&#39;: 0.39611763614178486, &#39;learning_rate&#39;: 0.0024386476344047054, &#39;batch_size&#39;: 477, &#39;l2_reg&#39;: 1.4484273308865696e-05}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.2933, eval loss 1.7314453125
Epoch 1 train loss: 1.2086, eval loss 1.7016844749450684
Epoch 2 train loss: 1.1511, eval loss 1.6772552728652954
Epoch 3 train loss: 1.1418, eval loss 1.6586949825286865
Epoch 4 train loss: 1.0743, eval loss 1.6404985189437866
Epoch 5 train loss: 1.0518, eval loss 1.626481294631958
Epoch 6 train loss: 1.0078, eval loss 1.6103652715682983
Epoch 7 train loss: 0.9855, eval loss 1.5999683141708374
Epoch 8 train loss: 0.9664, eval loss 1.589551568031311
Epoch 9 train loss: 0.8701, eval loss 1.5822575092315674
Epoch 10 train loss: 0.9573, eval loss 1.572230339050293
Epoch 11 train loss: 0.8893, eval loss 1.565720558166504
Epoch 12 train loss: 0.9187, eval loss 1.5570095777511597
Epoch 13 train loss: 0.8952, eval loss 1.5520074367523193
Epoch 14 train loss: 0.8575, eval loss 1.5447314977645874
Epoch 15 train loss: 0.8216, eval loss 1.5409830808639526
Epoch 16 train loss: 0.8351, eval loss 1.5356281995773315
Epoch 17 train loss: 0.8560, eval loss 1.5290858745574951
Epoch 18 train loss: 0.8484, eval loss 1.5244874954223633
Epoch 19 train loss: 0.7885, eval loss 1.5213195085525513
Epoch 20 train loss: 0.7823, eval loss 1.5168616771697998
Epoch 21 train loss: 0.7777, eval loss 1.5125771760940552
Epoch 22 train loss: 0.8221, eval loss 1.508954644203186
Epoch 23 train loss: 0.8231, eval loss 1.5063139200210571
Epoch 24 train loss: 0.7748, eval loss 1.5028990507125854
Epoch 25 train loss: 0.7822, eval loss 1.49966561794281
Epoch 26 train loss: 0.8310, eval loss 1.4968448877334595
Epoch 27 train loss: 0.7944, eval loss 1.4940167665481567
Epoch 28 train loss: 0.7467, eval loss 1.4922462701797485
Epoch 29 train loss: 0.7548, eval loss 1.4895374774932861
Epoch 30 train loss: 0.7799, eval loss 1.4859609603881836
Epoch 31 train loss: 0.7857, eval loss 1.4844545125961304
Epoch 32 train loss: 0.7388, eval loss 1.4831383228302002
Epoch 33 train loss: 0.7884, eval loss 1.481903076171875
Epoch 34 train loss: 0.7442, eval loss 1.4790480136871338
Epoch 35 train loss: 0.7639, eval loss 1.47769033908844
Epoch 36 train loss: 0.7189, eval loss 1.4754191637039185
Epoch 37 train loss: 0.7762, eval loss 1.4740573167800903
Epoch 38 train loss: 0.7196, eval loss 1.4735445976257324
Epoch 39 train loss: 0.7620, eval loss 1.4718905687332153
Epoch 40 train loss: 0.7734, eval loss 1.4704569578170776
Epoch 41 train loss: 0.8021, eval loss 1.4694114923477173
Epoch 42 train loss: 0.7458, eval loss 1.4676167964935303
Epoch 43 train loss: 0.7411, eval loss 1.4679852724075317
Epoch 44 train loss: 0.7790, eval loss 1.4659152030944824
Epoch 45 train loss: 0.7481, eval loss 1.4651292562484741
Epoch 46 train loss: 0.7406, eval loss 1.4641214609146118
Epoch 47 train loss: 0.7638, eval loss 1.4639335870742798
Epoch 48 train loss: 0.7259, eval loss 1.4615176916122437
Epoch 49 train loss: 0.7600, eval loss 1.460246205329895
Epoch 50 train loss: 0.7205, eval loss 1.4593448638916016
Epoch 51 train loss: 0.7989, eval loss 1.4590893983840942
Epoch 52 train loss: 0.7171, eval loss 1.4590160846710205
Epoch 53 train loss: 0.7248, eval loss 1.4578484296798706
Epoch 54 train loss: 0.7197, eval loss 1.4569381475448608
Epoch 55 train loss: 0.7443, eval loss 1.4577845335006714
Epoch 56 train loss: 0.7698, eval loss 1.4570766687393188
Epoch 57 train loss: 0.7442, eval loss 1.4547001123428345
Epoch 58 train loss: 0.7085, eval loss 1.4548122882843018
Epoch 59 train loss: 0.7949, eval loss 1.454885482788086
Epoch 60 train loss: 0.6803, eval loss 1.4546256065368652
Epoch 61 train loss: 0.7052, eval loss 1.4536833763122559
Epoch 62 train loss: 0.7399, eval loss 1.4531315565109253
Epoch 63 train loss: 0.7978, eval loss 1.4535751342773438
Epoch 64 train loss: 0.6979, eval loss 1.4526584148406982
Epoch 65 train loss: 0.7059, eval loss 1.4524827003479004
Epoch 66 train loss: 0.7889, eval loss 1.4518046379089355
Epoch 67 train loss: 0.7202, eval loss 1.4511773586273193
Epoch 68 train loss: 0.6916, eval loss 1.4502146244049072
Epoch 69 train loss: 0.6757, eval loss 1.4505037069320679
Epoch 70 train loss: 0.7370, eval loss 1.4501161575317383
Epoch 71 train loss: 0.7789, eval loss 1.4514665603637695
Epoch 72 train loss: 0.7063, eval loss 1.4498069286346436
Epoch 73 train loss: 0.7829, eval loss 1.4498661756515503
Epoch 74 train loss: 0.7458, eval loss 1.4489243030548096
Epoch 75 train loss: 0.7434, eval loss 1.4487587213516235
Epoch 76 train loss: 0.7240, eval loss 1.4478939771652222
Epoch 77 train loss: 0.7324, eval loss 1.4483791589736938
Epoch 78 train loss: 0.7140, eval loss 1.4479044675827026
Epoch 79 train loss: 0.7669, eval loss 1.4485934972763062
Epoch 80 train loss: 0.7220, eval loss 1.447037935256958
Epoch 81 train loss: 0.7651, eval loss 1.4471873044967651
Epoch 82 train loss: 0.7510, eval loss 1.447634220123291
Epoch 83 train loss: 0.7383, eval loss 1.4464360475540161
Epoch 84 train loss: 0.7566, eval loss 1.446785569190979
Epoch 85 train loss: 0.7460, eval loss 1.4469836950302124
Epoch 86 train loss: 0.6711, eval loss 1.4456912279129028
Epoch 87 train loss: 0.7388, eval loss 1.44680655002594
Epoch 88 train loss: 0.7230, eval loss 1.4460053443908691
Epoch 89 train loss: 0.7506, eval loss 1.445310115814209
Epoch 90 train loss: 0.7094, eval loss 1.4455294609069824
Epoch 91 train loss: 0.7560, eval loss 1.445064663887024
Epoch 92 train loss: 0.6895, eval loss 1.4452184438705444
Epoch 93 train loss: 0.7833, eval loss 1.444801688194275
Epoch 94 train loss: 0.7490, eval loss 1.4443764686584473
Epoch 95 train loss: 0.7167, eval loss 1.4450417757034302
Epoch 96 train loss: 0.7436, eval loss 1.4453158378601074
Epoch 97 train loss: 0.7482, eval loss 1.4450098276138306
Epoch 98 train loss: 0.7916, eval loss 1.4441262483596802
Epoch 99 train loss: 0.6936, eval loss 1.4437282085418701
Epoch 100 train loss: 0.7566, eval loss 1.4439878463745117
Epoch 101 train loss: 0.7828, eval loss 1.4444514513015747
Epoch 102 train loss: 0.7451, eval loss 1.4440929889678955
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:08:02,301] Trial 23 finished with value: 1.4437282085418701 and parameters: {&#39;hidden_layers_size&#39;: 204, &#39;dropout_p&#39;: 0.3859481194452074, &#39;learning_rate&#39;: 1.2170940438495193e-05, &#39;batch_size&#39;: 138, &#39;l2_reg&#39;: 3.185550507964966e-05}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 0.7436, eval loss 1.444145917892456
Epoch 1 train loss: 0.8436, eval loss 1.444703459739685
Epoch 2 train loss: 0.7930, eval loss 1.4479087591171265
Epoch 3 train loss: 0.6846, eval loss 1.4490834474563599
Epoch 4 train loss: 0.6191, eval loss 1.442521572113037
Epoch 5 train loss: 0.6479, eval loss 1.4385219812393188
Epoch 6 train loss: 0.6806, eval loss 1.451742172241211
Epoch 7 train loss: 0.6858, eval loss 1.4419848918914795
Epoch 8 train loss: 0.6659, eval loss 1.442987084388733
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:08:06,649] Trial 24 finished with value: 1.4385219812393188 and parameters: {&#39;hidden_layers_size&#39;: 95, &#39;dropout_p&#39;: 0.27173970048254203, &#39;learning_rate&#39;: 0.09051468506534932, &#39;batch_size&#39;: 269, &#39;l2_reg&#39;: 0.0009163162083524767}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.3708, eval loss 1.7360703945159912
Epoch 1 train loss: 1.3578, eval loss 1.7321337461471558
Epoch 2 train loss: 1.3349, eval loss 1.7258684635162354
Epoch 3 train loss: 1.3180, eval loss 1.7237709760665894
Epoch 4 train loss: 1.3030, eval loss 1.7189867496490479
Epoch 5 train loss: 1.2951, eval loss 1.716554880142212
Epoch 6 train loss: 1.3146, eval loss 1.7115845680236816
Epoch 7 train loss: 1.2898, eval loss 1.7095144987106323
Epoch 8 train loss: 1.2528, eval loss 1.7061238288879395
Epoch 9 train loss: 1.2883, eval loss 1.7024821043014526
Epoch 10 train loss: 1.2450, eval loss 1.698730230331421
Epoch 11 train loss: 1.2515, eval loss 1.6951680183410645
Epoch 12 train loss: 1.2675, eval loss 1.6933263540267944
Epoch 13 train loss: 1.2367, eval loss 1.6891024112701416
Epoch 14 train loss: 1.2217, eval loss 1.6853199005126953
Epoch 15 train loss: 1.1748, eval loss 1.683685064315796
Epoch 16 train loss: 1.1975, eval loss 1.680625081062317
Epoch 17 train loss: 1.2074, eval loss 1.677560806274414
Epoch 18 train loss: 1.1550, eval loss 1.6745673418045044
Epoch 19 train loss: 1.1884, eval loss 1.6722434759140015
Epoch 20 train loss: 1.1453, eval loss 1.6683977842330933
Epoch 21 train loss: 1.1359, eval loss 1.6665650606155396
Epoch 22 train loss: 1.1677, eval loss 1.6652483940124512
Epoch 23 train loss: 1.0926, eval loss 1.6610538959503174
Epoch 24 train loss: 1.1369, eval loss 1.66008722782135
Epoch 25 train loss: 1.1572, eval loss 1.6559935808181763
Epoch 26 train loss: 1.1314, eval loss 1.654019832611084
Epoch 27 train loss: 1.1496, eval loss 1.6519497632980347
Epoch 28 train loss: 1.1188, eval loss 1.649198293685913
Epoch 29 train loss: 1.0782, eval loss 1.6470011472702026
Epoch 30 train loss: 1.1081, eval loss 1.644824743270874
Epoch 31 train loss: 1.1030, eval loss 1.6430189609527588
Epoch 32 train loss: 1.0869, eval loss 1.641332745552063
Epoch 33 train loss: 1.0777, eval loss 1.6384252309799194
Epoch 34 train loss: 1.0562, eval loss 1.6362366676330566
Epoch 35 train loss: 1.0798, eval loss 1.6357637643814087
Epoch 36 train loss: 1.0279, eval loss 1.632226586341858
Epoch 37 train loss: 1.0715, eval loss 1.6307013034820557
Epoch 38 train loss: 1.0464, eval loss 1.628829002380371
Epoch 39 train loss: 1.0406, eval loss 1.627294659614563
Epoch 40 train loss: 1.0350, eval loss 1.6247968673706055
Epoch 41 train loss: 1.0280, eval loss 1.6235599517822266
Epoch 42 train loss: 1.0168, eval loss 1.6227021217346191
Epoch 43 train loss: 0.9929, eval loss 1.6205832958221436
Epoch 44 train loss: 1.0070, eval loss 1.6185632944107056
Epoch 45 train loss: 1.0327, eval loss 1.6170443296432495
Epoch 46 train loss: 0.9799, eval loss 1.6152195930480957
Epoch 47 train loss: 0.9733, eval loss 1.6134679317474365
Epoch 48 train loss: 1.0257, eval loss 1.6127493381500244
Epoch 49 train loss: 0.9724, eval loss 1.610945224761963
Epoch 50 train loss: 1.0188, eval loss 1.610106348991394
Epoch 51 train loss: 0.9704, eval loss 1.6073914766311646
Epoch 52 train loss: 0.9976, eval loss 1.6057389974594116
Epoch 53 train loss: 0.9964, eval loss 1.6050482988357544
Epoch 54 train loss: 0.9763, eval loss 1.6034826040267944
Epoch 55 train loss: 0.9595, eval loss 1.6009557247161865
Epoch 56 train loss: 0.9747, eval loss 1.6006052494049072
Epoch 57 train loss: 0.9897, eval loss 1.5983885526657104
Epoch 58 train loss: 0.9497, eval loss 1.598095178604126
Epoch 59 train loss: 0.9799, eval loss 1.5960487127304077
Epoch 60 train loss: 0.9712, eval loss 1.5952479839324951
Epoch 61 train loss: 0.9925, eval loss 1.5937974452972412
Epoch 62 train loss: 0.9587, eval loss 1.5937669277191162
Epoch 63 train loss: 0.9203, eval loss 1.5907262563705444
Epoch 64 train loss: 0.9473, eval loss 1.5899640321731567
Epoch 65 train loss: 0.9472, eval loss 1.5890827178955078
Epoch 66 train loss: 0.9388, eval loss 1.5872563123703003
Epoch 67 train loss: 0.9390, eval loss 1.5861186981201172
Epoch 68 train loss: 0.9723, eval loss 1.5846681594848633
Epoch 69 train loss: 0.9358, eval loss 1.5846970081329346
Epoch 70 train loss: 0.9463, eval loss 1.5825523138046265
Epoch 71 train loss: 0.9381, eval loss 1.5819337368011475
Epoch 72 train loss: 0.9376, eval loss 1.5813071727752686
Epoch 73 train loss: 0.9228, eval loss 1.5794758796691895
Epoch 74 train loss: 0.9484, eval loss 1.5789446830749512
Epoch 75 train loss: 0.9309, eval loss 1.576988935470581
Epoch 76 train loss: 0.9232, eval loss 1.576200008392334
Epoch 77 train loss: 0.9161, eval loss 1.574525237083435
Epoch 78 train loss: 0.9058, eval loss 1.5743308067321777
Epoch 79 train loss: 0.9044, eval loss 1.5732382535934448
Epoch 80 train loss: 0.9012, eval loss 1.5716617107391357
Epoch 81 train loss: 0.8817, eval loss 1.5706137418746948
Epoch 82 train loss: 0.9153, eval loss 1.5698578357696533
Epoch 83 train loss: 0.9137, eval loss 1.5692652463912964
Epoch 84 train loss: 0.8915, eval loss 1.568211317062378
Epoch 85 train loss: 0.9065, eval loss 1.5670888423919678
Epoch 86 train loss: 0.8893, eval loss 1.5666111707687378
Epoch 87 train loss: 0.8902, eval loss 1.5653523206710815
Epoch 88 train loss: 0.8638, eval loss 1.5636107921600342
Epoch 89 train loss: 0.8591, eval loss 1.5634231567382812
Epoch 90 train loss: 0.8796, eval loss 1.5618677139282227
Epoch 91 train loss: 0.8822, eval loss 1.562185525894165
Epoch 92 train loss: 0.8896, eval loss 1.5607881546020508
Epoch 93 train loss: 0.8551, eval loss 1.56024169921875
Epoch 94 train loss: 0.8659, eval loss 1.5586429834365845
Epoch 95 train loss: 0.8657, eval loss 1.558495283126831
Epoch 96 train loss: 0.8246, eval loss 1.5575352907180786
Epoch 97 train loss: 0.8555, eval loss 1.5561387538909912
Epoch 98 train loss: 0.8651, eval loss 1.5555236339569092
Epoch 99 train loss: 0.8666, eval loss 1.5545153617858887
Epoch 100 train loss: 0.8654, eval loss 1.5537381172180176
Epoch 101 train loss: 0.8612, eval loss 1.552303671836853
Epoch 102 train loss: 0.8629, eval loss 1.5525825023651123
Epoch 103 train loss: 0.8460, eval loss 1.5503541231155396
Epoch 104 train loss: 0.8938, eval loss 1.550878882408142
Epoch 105 train loss: 0.8751, eval loss 1.5490264892578125
Epoch 106 train loss: 0.8518, eval loss 1.548208236694336
Epoch 107 train loss: 0.8501, eval loss 1.5484908819198608
Epoch 108 train loss: 0.8683, eval loss 1.5476917028427124
Epoch 109 train loss: 0.8679, eval loss 1.5474627017974854
Epoch 110 train loss: 0.8312, eval loss 1.5455570220947266
Epoch 111 train loss: 0.8590, eval loss 1.5459227561950684
Epoch 112 train loss: 0.8380, eval loss 1.54440176486969
Epoch 113 train loss: 0.8421, eval loss 1.5434681177139282
Epoch 114 train loss: 0.8584, eval loss 1.542917013168335
Epoch 115 train loss: 0.8197, eval loss 1.542732834815979
Epoch 116 train loss: 0.8582, eval loss 1.5418788194656372
Epoch 117 train loss: 0.8248, eval loss 1.5403538942337036
Epoch 118 train loss: 0.8513, eval loss 1.5399081707000732
Epoch 119 train loss: 0.8410, eval loss 1.5390794277191162
Epoch 120 train loss: 0.8176, eval loss 1.539129376411438
Epoch 121 train loss: 0.8444, eval loss 1.538482427597046
Epoch 122 train loss: 0.8597, eval loss 1.5372287034988403
Epoch 123 train loss: 0.8190, eval loss 1.537466049194336
Epoch 124 train loss: 0.8434, eval loss 1.5358333587646484
Epoch 125 train loss: 0.8108, eval loss 1.53514564037323
Epoch 126 train loss: 0.8337, eval loss 1.5348176956176758
Epoch 127 train loss: 0.8301, eval loss 1.534924030303955
Epoch 128 train loss: 0.8098, eval loss 1.5327378511428833
Epoch 129 train loss: 0.8133, eval loss 1.5317471027374268
Epoch 130 train loss: 0.8178, eval loss 1.5316686630249023
Epoch 131 train loss: 0.8251, eval loss 1.5313774347305298
Epoch 132 train loss: 0.8363, eval loss 1.52985680103302
Epoch 133 train loss: 0.8435, eval loss 1.529902696609497
Epoch 134 train loss: 0.8291, eval loss 1.52958345413208
Epoch 135 train loss: 0.8346, eval loss 1.5294675827026367
Epoch 136 train loss: 0.8465, eval loss 1.5288172960281372
Epoch 137 train loss: 0.8037, eval loss 1.5281198024749756
Epoch 138 train loss: 0.8421, eval loss 1.5276241302490234
Epoch 139 train loss: 0.7915, eval loss 1.5263813734054565
Epoch 140 train loss: 0.8173, eval loss 1.5263419151306152
Epoch 141 train loss: 0.8458, eval loss 1.5250763893127441
Epoch 142 train loss: 0.8351, eval loss 1.524495005607605
Epoch 143 train loss: 0.8030, eval loss 1.5250691175460815
Epoch 144 train loss: 0.8196, eval loss 1.523294448852539
Epoch 145 train loss: 0.8131, eval loss 1.5220526456832886
Epoch 146 train loss: 0.8256, eval loss 1.5219939947128296
Epoch 147 train loss: 0.8102, eval loss 1.5215859413146973
Epoch 148 train loss: 0.8052, eval loss 1.521398663520813
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:09:12,085] Trial 25 finished with value: 1.5209039449691772 and parameters: {&#39;hidden_layers_size&#39;: 203, &#39;dropout_p&#39;: 0.35752682496918486, &#39;learning_rate&#39;: 2.433415539418087e-06, &#39;batch_size&#39;: 343, &#39;l2_reg&#39;: 4.730500605689594e-05}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.7997, eval loss 1.5209039449691772
Epoch 0 train loss: 0.7978, eval loss 1.520890712738037
Epoch 1 train loss: 0.8423, eval loss 1.4739967584609985
Epoch 2 train loss: 0.7315, eval loss 1.4575177431106567
Epoch 3 train loss: 0.7507, eval loss 1.44858980178833
Epoch 4 train loss: 0.6716, eval loss 1.4477856159210205
Epoch 5 train loss: 0.6811, eval loss 1.4423903226852417
Epoch 6 train loss: 0.7426, eval loss 1.4406148195266724
Epoch 7 train loss: 0.7338, eval loss 1.4413203001022339
Epoch 8 train loss: 0.7077, eval loss 1.4374449253082275
Epoch 9 train loss: 0.6267, eval loss 1.4368637800216675
Epoch 10 train loss: 0.6399, eval loss 1.437151312828064
Epoch 11 train loss: 0.6540, eval loss 1.4365317821502686
Epoch 12 train loss: 0.6476, eval loss 1.4364378452301025
Epoch 13 train loss: 0.7015, eval loss 1.4362049102783203
Epoch 14 train loss: 0.6631, eval loss 1.4352513551712036
Epoch 15 train loss: 0.7148, eval loss 1.4346340894699097
Epoch 16 train loss: 0.6838, eval loss 1.4338067770004272
Epoch 17 train loss: 0.6309, eval loss 1.432753324508667
Epoch 18 train loss: 0.6038, eval loss 1.433260440826416
Epoch 19 train loss: 0.6567, eval loss 1.4338245391845703
Epoch 20 train loss: 0.7021, eval loss 1.4334853887557983
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:09:22,357] Trial 26 finished with value: 1.432753324508667 and parameters: {&#39;hidden_layers_size&#39;: 146, &#39;dropout_p&#39;: 0.4437772399358891, &#39;learning_rate&#39;: 0.000583487635507599, &#39;batch_size&#39;: 259, &#39;l2_reg&#39;: 1.0446072518469856e-05}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.4334, eval loss 1.7583783864974976
Epoch 1 train loss: 1.3669, eval loss 1.7524921894073486
Epoch 2 train loss: 1.4176, eval loss 1.7479381561279297
Epoch 3 train loss: 1.3921, eval loss 1.7434273958206177
Epoch 4 train loss: 1.3814, eval loss 1.7381194829940796
Epoch 5 train loss: 1.4211, eval loss 1.7342267036437988
Epoch 6 train loss: 1.3112, eval loss 1.7300132513046265
Epoch 7 train loss: 1.4159, eval loss 1.7261805534362793
Epoch 8 train loss: 1.4038, eval loss 1.7190601825714111
Epoch 9 train loss: 1.3156, eval loss 1.7181940078735352
Epoch 10 train loss: 1.3577, eval loss 1.7129648923873901
Epoch 11 train loss: 1.3491, eval loss 1.7095139026641846
Epoch 12 train loss: 1.2772, eval loss 1.7057806253433228
Epoch 13 train loss: 1.3048, eval loss 1.7013863325119019
Epoch 14 train loss: 1.2782, eval loss 1.6980935335159302
Epoch 15 train loss: 1.2805, eval loss 1.6947656869888306
Epoch 16 train loss: 1.2739, eval loss 1.692008137702942
Epoch 17 train loss: 1.2743, eval loss 1.6860318183898926
Epoch 18 train loss: 1.2573, eval loss 1.684167504310608
Epoch 19 train loss: 1.2292, eval loss 1.6822373867034912
Epoch 20 train loss: 1.2975, eval loss 1.6773804426193237
Epoch 21 train loss: 1.2292, eval loss 1.674608588218689
Epoch 22 train loss: 1.1688, eval loss 1.671287178993225
Epoch 23 train loss: 1.1491, eval loss 1.667820692062378
Epoch 24 train loss: 1.1818, eval loss 1.6664527654647827
Epoch 25 train loss: 1.1304, eval loss 1.6645265817642212
Epoch 26 train loss: 1.1789, eval loss 1.6605076789855957
Epoch 27 train loss: 1.1755, eval loss 1.657731294631958
Epoch 28 train loss: 1.2083, eval loss 1.6560872793197632
Epoch 29 train loss: 1.1150, eval loss 1.6527690887451172
Epoch 30 train loss: 1.1334, eval loss 1.6489778757095337
Epoch 31 train loss: 1.0917, eval loss 1.6460120677947998
Epoch 32 train loss: 1.0909, eval loss 1.6449304819107056
Epoch 33 train loss: 1.1074, eval loss 1.6410412788391113
Epoch 34 train loss: 1.1288, eval loss 1.6393193006515503
Epoch 35 train loss: 1.0620, eval loss 1.6380263566970825
Epoch 36 train loss: 1.0993, eval loss 1.6361957788467407
Epoch 37 train loss: 1.1082, eval loss 1.6328718662261963
Epoch 38 train loss: 1.0995, eval loss 1.6311753988265991
Epoch 39 train loss: 1.0345, eval loss 1.6282734870910645
Epoch 40 train loss: 1.1397, eval loss 1.6278085708618164
Epoch 41 train loss: 1.1025, eval loss 1.6257224082946777
Epoch 42 train loss: 1.0115, eval loss 1.62129807472229
Epoch 43 train loss: 1.0283, eval loss 1.620538353919983
Epoch 44 train loss: 1.0295, eval loss 1.6178863048553467
Epoch 45 train loss: 1.0121, eval loss 1.6149168014526367
Epoch 46 train loss: 1.0236, eval loss 1.6151485443115234
Epoch 47 train loss: 0.9728, eval loss 1.6118390560150146
Epoch 48 train loss: 1.0301, eval loss 1.610077142715454
Epoch 49 train loss: 1.0219, eval loss 1.6084773540496826
Epoch 50 train loss: 0.9951, eval loss 1.6073795557022095
Epoch 51 train loss: 1.0261, eval loss 1.6057225465774536
Epoch 52 train loss: 1.0137, eval loss 1.6044951677322388
Epoch 53 train loss: 1.0694, eval loss 1.6018093824386597
Epoch 54 train loss: 1.0368, eval loss 1.6001956462860107
Epoch 55 train loss: 0.9946, eval loss 1.597162127494812
Epoch 56 train loss: 0.9781, eval loss 1.5960116386413574
Epoch 57 train loss: 0.9896, eval loss 1.5954686403274536
Epoch 58 train loss: 1.0516, eval loss 1.5914775133132935
Epoch 59 train loss: 0.9632, eval loss 1.5927331447601318
Epoch 60 train loss: 0.9707, eval loss 1.5907833576202393
Epoch 61 train loss: 0.9590, eval loss 1.587378740310669
Epoch 62 train loss: 0.9759, eval loss 1.5872622728347778
Epoch 63 train loss: 0.9996, eval loss 1.5849937200546265
Epoch 64 train loss: 0.9842, eval loss 1.5844899415969849
Epoch 65 train loss: 0.9320, eval loss 1.5828194618225098
Epoch 66 train loss: 0.9252, eval loss 1.5798921585083008
Epoch 67 train loss: 0.9871, eval loss 1.5799452066421509
Epoch 68 train loss: 0.9606, eval loss 1.5766404867172241
Epoch 69 train loss: 0.9584, eval loss 1.5771677494049072
Epoch 70 train loss: 0.9426, eval loss 1.5754637718200684
Epoch 71 train loss: 0.9320, eval loss 1.5753040313720703
Epoch 72 train loss: 0.9047, eval loss 1.57326078414917
Epoch 73 train loss: 0.9052, eval loss 1.5717278718948364
Epoch 74 train loss: 0.9895, eval loss 1.5695232152938843
Epoch 75 train loss: 0.9097, eval loss 1.5683350563049316
Epoch 76 train loss: 0.9083, eval loss 1.5668282508850098
Epoch 77 train loss: 0.9024, eval loss 1.5660037994384766
Epoch 78 train loss: 0.9232, eval loss 1.5647563934326172
Epoch 79 train loss: 0.9421, eval loss 1.564778208732605
Epoch 80 train loss: 0.8359, eval loss 1.563469409942627
Epoch 81 train loss: 0.9553, eval loss 1.5602777004241943
Epoch 82 train loss: 0.9598, eval loss 1.559686303138733
Epoch 83 train loss: 0.8979, eval loss 1.558406114578247
Epoch 84 train loss: 0.9169, eval loss 1.5564568042755127
Epoch 85 train loss: 0.8799, eval loss 1.5562711954116821
Epoch 86 train loss: 0.9368, eval loss 1.5544480085372925
Epoch 87 train loss: 0.9065, eval loss 1.5537196397781372
Epoch 88 train loss: 0.9343, eval loss 1.5531175136566162
Epoch 89 train loss: 0.9318, eval loss 1.5515038967132568
Epoch 90 train loss: 0.9557, eval loss 1.5496736764907837
Epoch 91 train loss: 0.8506, eval loss 1.5482990741729736
Epoch 92 train loss: 0.8663, eval loss 1.5471982955932617
Epoch 93 train loss: 0.9369, eval loss 1.5480973720550537
Epoch 94 train loss: 0.8799, eval loss 1.5449488162994385
Epoch 95 train loss: 0.8854, eval loss 1.5459569692611694
Epoch 96 train loss: 0.9225, eval loss 1.544456124305725
Epoch 97 train loss: 0.8929, eval loss 1.5438028573989868
Epoch 98 train loss: 0.8839, eval loss 1.5424209833145142
Epoch 99 train loss: 0.8904, eval loss 1.5415749549865723
Epoch 100 train loss: 0.8734, eval loss 1.5404959917068481
Epoch 101 train loss: 0.8671, eval loss 1.539463758468628
Epoch 102 train loss: 0.8918, eval loss 1.5383927822113037
Epoch 103 train loss: 0.8759, eval loss 1.5366066694259644
Epoch 104 train loss: 0.9128, eval loss 1.5363173484802246
Epoch 105 train loss: 0.8662, eval loss 1.5359147787094116
Epoch 106 train loss: 0.8567, eval loss 1.5350338220596313
Epoch 107 train loss: 0.8853, eval loss 1.534287691116333
Epoch 108 train loss: 0.8308, eval loss 1.532236099243164
Epoch 109 train loss: 0.8848, eval loss 1.5310672521591187
Epoch 110 train loss: 0.9169, eval loss 1.5307579040527344
Epoch 111 train loss: 0.8719, eval loss 1.5297651290893555
Epoch 112 train loss: 0.8916, eval loss 1.529790997505188
Epoch 113 train loss: 0.8841, eval loss 1.5281336307525635
Epoch 114 train loss: 0.8916, eval loss 1.5267508029937744
Epoch 115 train loss: 0.8412, eval loss 1.5269895792007446
Epoch 116 train loss: 0.8612, eval loss 1.5248217582702637
Epoch 117 train loss: 0.8260, eval loss 1.523250699043274
Epoch 118 train loss: 0.8270, eval loss 1.5225390195846558
Epoch 119 train loss: 0.8430, eval loss 1.523844599723816
Epoch 120 train loss: 0.8811, eval loss 1.5220171213150024
Epoch 121 train loss: 0.8925, eval loss 1.5213176012039185
Epoch 122 train loss: 0.8760, eval loss 1.5206444263458252
Epoch 123 train loss: 0.8474, eval loss 1.5194451808929443
Epoch 124 train loss: 0.8576, eval loss 1.5186673402786255
Epoch 125 train loss: 0.8847, eval loss 1.517512559890747
Epoch 126 train loss: 0.8438, eval loss 1.5171189308166504
Epoch 127 train loss: 0.8678, eval loss 1.5165849924087524
Epoch 128 train loss: 0.8820, eval loss 1.5157948732376099
Epoch 129 train loss: 0.8486, eval loss 1.514670729637146
Epoch 130 train loss: 0.8726, eval loss 1.513278603553772
Epoch 131 train loss: 0.8621, eval loss 1.5133179426193237
Epoch 132 train loss: 0.7769, eval loss 1.5129404067993164
Epoch 133 train loss: 0.8120, eval loss 1.5132389068603516
Epoch 134 train loss: 0.8280, eval loss 1.511102557182312
Epoch 135 train loss: 0.8489, eval loss 1.5113794803619385
Epoch 136 train loss: 0.8019, eval loss 1.5103029012680054
Epoch 137 train loss: 0.8137, eval loss 1.5094672441482544
Epoch 138 train loss: 0.8328, eval loss 1.5080891847610474
Epoch 139 train loss: 0.8336, eval loss 1.5068824291229248
Epoch 140 train loss: 0.8769, eval loss 1.506847858428955
Epoch 141 train loss: 0.8006, eval loss 1.5076401233673096
Epoch 142 train loss: 0.8073, eval loss 1.5061432123184204
Epoch 143 train loss: 0.7893, eval loss 1.506118893623352
Epoch 144 train loss: 0.7861, eval loss 1.5063890218734741
Epoch 145 train loss: 0.8596, eval loss 1.504811406135559
Epoch 146 train loss: 0.8299, eval loss 1.504340410232544
Epoch 147 train loss: 0.8273, eval loss 1.5033886432647705
Epoch 148 train loss: 0.8032, eval loss 1.5021169185638428
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:10:40,224] Trial 27 finished with value: 1.5021169185638428 and parameters: {&#39;hidden_layers_size&#39;: 147, &#39;dropout_p&#39;: 0.4464801354971336, &#39;learning_rate&#39;: 3.448691274811924e-06, &#39;batch_size&#39;: 207, &#39;l2_reg&#39;: 0.0002531025277093918}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.8266, eval loss 1.5026029348373413
Epoch 0 train loss: 1.4034, eval loss 1.751881718635559
Epoch 1 train loss: 1.3996, eval loss 1.7429258823394775
Epoch 2 train loss: 1.3324, eval loss 1.7408287525177002
Epoch 3 train loss: 1.3439, eval loss 1.7373714447021484
Epoch 4 train loss: 1.2854, eval loss 1.7330735921859741
Epoch 5 train loss: 1.3168, eval loss 1.728844404220581
Epoch 6 train loss: 1.3498, eval loss 1.7265520095825195
Epoch 7 train loss: 1.3167, eval loss 1.7220971584320068
Epoch 8 train loss: 1.2975, eval loss 1.7191718816757202
Epoch 9 train loss: 1.2581, eval loss 1.7148677110671997
Epoch 10 train loss: 1.2808, eval loss 1.7130153179168701
Epoch 11 train loss: 1.2857, eval loss 1.7096906900405884
Epoch 12 train loss: 1.2542, eval loss 1.7076174020767212
Epoch 13 train loss: 1.2420, eval loss 1.7028135061264038
Epoch 14 train loss: 1.2256, eval loss 1.7004765272140503
Epoch 15 train loss: 1.2199, eval loss 1.6972907781600952
Epoch 16 train loss: 1.2219, eval loss 1.6942501068115234
Epoch 17 train loss: 1.1683, eval loss 1.6901437044143677
Epoch 18 train loss: 1.1967, eval loss 1.6881163120269775
Epoch 19 train loss: 1.2162, eval loss 1.6865228414535522
Epoch 20 train loss: 1.1743, eval loss 1.6828641891479492
Epoch 21 train loss: 1.1666, eval loss 1.6805635690689087
Epoch 22 train loss: 1.1721, eval loss 1.6774054765701294
Epoch 23 train loss: 1.1496, eval loss 1.6752244234085083
Epoch 24 train loss: 1.1824, eval loss 1.6741610765457153
Epoch 25 train loss: 1.1214, eval loss 1.6709576845169067
Epoch 26 train loss: 1.1218, eval loss 1.6685893535614014
Epoch 27 train loss: 1.1325, eval loss 1.6665513515472412
Epoch 28 train loss: 1.1544, eval loss 1.6637914180755615
Epoch 29 train loss: 1.1375, eval loss 1.6625189781188965
Epoch 30 train loss: 1.0965, eval loss 1.6602283716201782
Epoch 31 train loss: 1.0838, eval loss 1.6574597358703613
Epoch 32 train loss: 1.0817, eval loss 1.6549289226531982
Epoch 33 train loss: 1.1067, eval loss 1.6534919738769531
Epoch 34 train loss: 1.0549, eval loss 1.6509873867034912
Epoch 35 train loss: 1.0857, eval loss 1.648719072341919
Epoch 36 train loss: 1.0467, eval loss 1.6478731632232666
Epoch 37 train loss: 1.0559, eval loss 1.6446763277053833
Epoch 38 train loss: 1.0622, eval loss 1.6432245969772339
Epoch 39 train loss: 1.0447, eval loss 1.6416735649108887
Epoch 40 train loss: 1.0636, eval loss 1.6399809122085571
Epoch 41 train loss: 1.0435, eval loss 1.6381481885910034
Epoch 42 train loss: 1.0421, eval loss 1.6367089748382568
Epoch 43 train loss: 1.0031, eval loss 1.6346006393432617
Epoch 44 train loss: 1.0368, eval loss 1.633191466331482
Epoch 45 train loss: 1.0436, eval loss 1.631851077079773
Epoch 46 train loss: 1.0073, eval loss 1.6291483640670776
Epoch 47 train loss: 1.0386, eval loss 1.6283109188079834
Epoch 48 train loss: 1.0356, eval loss 1.6266201734542847
Epoch 49 train loss: 1.0396, eval loss 1.6249696016311646
Epoch 50 train loss: 0.9672, eval loss 1.6231520175933838
Epoch 51 train loss: 1.0049, eval loss 1.6216084957122803
Epoch 52 train loss: 0.9795, eval loss 1.6211527585983276
Epoch 53 train loss: 0.9747, eval loss 1.618589162826538
Epoch 54 train loss: 1.0425, eval loss 1.6175211668014526
Epoch 55 train loss: 0.9962, eval loss 1.6160471439361572
Epoch 56 train loss: 0.9949, eval loss 1.6142431497573853
Epoch 57 train loss: 0.9868, eval loss 1.6127362251281738
Epoch 58 train loss: 0.9919, eval loss 1.61125910282135
Epoch 59 train loss: 0.9671, eval loss 1.6105847358703613
Epoch 60 train loss: 0.9416, eval loss 1.6093333959579468
Epoch 61 train loss: 0.9372, eval loss 1.6070832014083862
Epoch 62 train loss: 0.9638, eval loss 1.6064276695251465
Epoch 63 train loss: 0.9481, eval loss 1.6048983335494995
Epoch 64 train loss: 0.9542, eval loss 1.6032644510269165
Epoch 65 train loss: 0.9537, eval loss 1.6021294593811035
Epoch 66 train loss: 0.9703, eval loss 1.6012641191482544
Epoch 67 train loss: 0.9487, eval loss 1.5995173454284668
Epoch 68 train loss: 0.9637, eval loss 1.598789930343628
Epoch 69 train loss: 0.9766, eval loss 1.5975430011749268
Epoch 70 train loss: 0.9291, eval loss 1.5961337089538574
Epoch 71 train loss: 0.9143, eval loss 1.5957996845245361
Epoch 72 train loss: 0.9392, eval loss 1.5948330163955688
Epoch 73 train loss: 0.9280, eval loss 1.5934253931045532
Epoch 74 train loss: 0.9209, eval loss 1.592211127281189
Epoch 75 train loss: 0.9211, eval loss 1.590827465057373
Epoch 76 train loss: 0.9163, eval loss 1.5893443822860718
Epoch 77 train loss: 0.9265, eval loss 1.589523196220398
Epoch 78 train loss: 0.9208, eval loss 1.588916540145874
Epoch 79 train loss: 0.8937, eval loss 1.5869616270065308
Epoch 80 train loss: 0.9192, eval loss 1.5854651927947998
Epoch 81 train loss: 0.9068, eval loss 1.585152506828308
Epoch 82 train loss: 0.9248, eval loss 1.583631992340088
Epoch 83 train loss: 0.9294, eval loss 1.582671880722046
Epoch 84 train loss: 0.8912, eval loss 1.5817921161651611
Epoch 85 train loss: 0.9201, eval loss 1.5804402828216553
Epoch 86 train loss: 0.8965, eval loss 1.579346776008606
Epoch 87 train loss: 0.8998, eval loss 1.5781437158584595
Epoch 88 train loss: 0.9046, eval loss 1.5775830745697021
Epoch 89 train loss: 0.9185, eval loss 1.576920747756958
Epoch 90 train loss: 0.8818, eval loss 1.5759319067001343
Epoch 91 train loss: 0.8715, eval loss 1.5739599466323853
Epoch 92 train loss: 0.8476, eval loss 1.5744565725326538
Epoch 93 train loss: 0.8919, eval loss 1.5732166767120361
Epoch 94 train loss: 0.8871, eval loss 1.5709999799728394
Epoch 95 train loss: 0.8658, eval loss 1.570920705795288
Epoch 96 train loss: 0.9022, eval loss 1.5696130990982056
Epoch 97 train loss: 0.8525, eval loss 1.5681737661361694
Epoch 98 train loss: 0.9032, eval loss 1.5683817863464355
Epoch 99 train loss: 0.8577, eval loss 1.5669928789138794
Epoch 100 train loss: 0.9221, eval loss 1.5662020444869995
Epoch 101 train loss: 0.8724, eval loss 1.5654343366622925
Epoch 102 train loss: 0.8731, eval loss 1.5645312070846558
Epoch 103 train loss: 0.8888, eval loss 1.5645205974578857
Epoch 104 train loss: 0.8493, eval loss 1.5622562170028687
Epoch 105 train loss: 0.8855, eval loss 1.56257164478302
Epoch 106 train loss: 0.8628, eval loss 1.5615886449813843
Epoch 107 train loss: 0.8594, eval loss 1.560174822807312
Epoch 108 train loss: 0.8523, eval loss 1.559621810913086
Epoch 109 train loss: 0.8505, eval loss 1.5596803426742554
Epoch 110 train loss: 0.8372, eval loss 1.5579338073730469
Epoch 111 train loss: 0.8635, eval loss 1.5570577383041382
Epoch 112 train loss: 0.8336, eval loss 1.556088924407959
Epoch 113 train loss: 0.8838, eval loss 1.556275725364685
Epoch 114 train loss: 0.8571, eval loss 1.5556100606918335
Epoch 115 train loss: 0.8439, eval loss 1.5546226501464844
Epoch 116 train loss: 0.8657, eval loss 1.553517460823059
Epoch 117 train loss: 0.8554, eval loss 1.5534695386886597
Epoch 118 train loss: 0.8397, eval loss 1.5519579648971558
Epoch 119 train loss: 0.8541, eval loss 1.5513509511947632
Epoch 120 train loss: 0.8496, eval loss 1.5499463081359863
Epoch 121 train loss: 0.8424, eval loss 1.5498096942901611
Epoch 122 train loss: 0.8457, eval loss 1.5488086938858032
Epoch 123 train loss: 0.8296, eval loss 1.548893690109253
Epoch 124 train loss: 0.8225, eval loss 1.5474258661270142
Epoch 125 train loss: 0.8443, eval loss 1.5468205213546753
Epoch 126 train loss: 0.8184, eval loss 1.5466961860656738
Epoch 127 train loss: 0.8246, eval loss 1.5455855131149292
Epoch 128 train loss: 0.8395, eval loss 1.5445129871368408
Epoch 129 train loss: 0.8421, eval loss 1.544510841369629
Epoch 130 train loss: 0.8025, eval loss 1.543440580368042
Epoch 131 train loss: 0.8328, eval loss 1.5435973405838013
Epoch 132 train loss: 0.8351, eval loss 1.5416886806488037
Epoch 133 train loss: 0.8308, eval loss 1.5416501760482788
Epoch 134 train loss: 0.7902, eval loss 1.5405620336532593
Epoch 135 train loss: 0.8320, eval loss 1.5401484966278076
Epoch 136 train loss: 0.8235, eval loss 1.5389491319656372
Epoch 137 train loss: 0.8217, eval loss 1.5388944149017334
Epoch 138 train loss: 0.8074, eval loss 1.5383130311965942
Epoch 139 train loss: 0.7941, eval loss 1.5369093418121338
Epoch 140 train loss: 0.7957, eval loss 1.5355420112609863
Epoch 141 train loss: 0.8311, eval loss 1.53621506690979
Epoch 142 train loss: 0.7929, eval loss 1.535362958908081
Epoch 143 train loss: 0.8144, eval loss 1.5346816778182983
Epoch 144 train loss: 0.8045, eval loss 1.5342974662780762
Epoch 145 train loss: 0.8234, eval loss 1.533180594444275
Epoch 146 train loss: 0.7950, eval loss 1.5333094596862793
Epoch 147 train loss: 0.7639, eval loss 1.5317745208740234
Epoch 148 train loss: 0.8200, eval loss 1.5319392681121826
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:11:44,044] Trial 28 finished with value: 1.5315419435501099 and parameters: {&#39;hidden_layers_size&#39;: 198, &#39;dropout_p&#39;: 0.27946060181245025, &#39;learning_rate&#39;: 2.280249025495501e-06, &#39;batch_size&#39;: 382, &#39;l2_reg&#39;: 1.0216986632808458e-05}. Best is trial 20 with value: 1.6402353048324585.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 0.8195, eval loss 1.5315419435501099
Epoch 0 train loss: 1.7420, eval loss 1.8367434740066528
Epoch 1 train loss: 1.7655, eval loss 1.8365254402160645
Epoch 2 train loss: 1.8151, eval loss 1.8361928462982178
Epoch 3 train loss: 1.7700, eval loss 1.8357040882110596
Epoch 4 train loss: 1.7694, eval loss 1.8361893892288208
Epoch 5 train loss: 1.7567, eval loss 1.834889531135559
Epoch 6 train loss: 1.8250, eval loss 1.8343600034713745
Epoch 7 train loss: 1.8244, eval loss 1.8344156742095947
Epoch 8 train loss: 1.7215, eval loss 1.8322224617004395
Epoch 9 train loss: 1.7227, eval loss 1.8320250511169434
Epoch 10 train loss: 1.7600, eval loss 1.83098566532135
Epoch 11 train loss: 1.7656, eval loss 1.8322641849517822
Epoch 12 train loss: 1.7256, eval loss 1.830580472946167
Epoch 13 train loss: 1.7514, eval loss 1.8304786682128906
Epoch 14 train loss: 1.7838, eval loss 1.8299674987792969
Epoch 15 train loss: 1.7590, eval loss 1.8290210962295532
Epoch 16 train loss: 1.7570, eval loss 1.8291414976119995
Epoch 17 train loss: 1.7353, eval loss 1.8279019594192505
Epoch 18 train loss: 1.7497, eval loss 1.8272310495376587
Epoch 19 train loss: 1.6884, eval loss 1.8267521858215332
Epoch 20 train loss: 1.7272, eval loss 1.8266817331314087
Epoch 21 train loss: 1.7358, eval loss 1.8252428770065308
Epoch 22 train loss: 1.7759, eval loss 1.8257657289505005
Epoch 23 train loss: 1.7423, eval loss 1.825995922088623
Epoch 24 train loss: 1.7631, eval loss 1.8227649927139282
Epoch 25 train loss: 1.7007, eval loss 1.8231455087661743
Epoch 26 train loss: 1.6818, eval loss 1.822570562362671
Epoch 27 train loss: 1.7630, eval loss 1.8226124048233032
Epoch 28 train loss: 1.6993, eval loss 1.8216596841812134
Epoch 29 train loss: 1.7191, eval loss 1.8217556476593018
Epoch 30 train loss: 1.7010, eval loss 1.822105884552002
Epoch 31 train loss: 1.7609, eval loss 1.8201680183410645
Epoch 32 train loss: 1.7592, eval loss 1.820066213607788
Epoch 33 train loss: 1.7363, eval loss 1.8200510740280151
Epoch 34 train loss: 1.7058, eval loss 1.8192825317382812
Epoch 35 train loss: 1.6903, eval loss 1.8175760507583618
Epoch 36 train loss: 1.7092, eval loss 1.8180334568023682
Epoch 37 train loss: 1.7200, eval loss 1.815900206565857
Epoch 38 train loss: 1.7384, eval loss 1.817353367805481
Epoch 39 train loss: 1.7077, eval loss 1.8161728382110596
Epoch 40 train loss: 1.7098, eval loss 1.815913438796997
Epoch 41 train loss: 1.6945, eval loss 1.8137080669403076
Epoch 42 train loss: 1.7155, eval loss 1.81320059299469
Epoch 43 train loss: 1.6871, eval loss 1.8139888048171997
Epoch 44 train loss: 1.6565, eval loss 1.8136446475982666
Epoch 45 train loss: 1.6802, eval loss 1.8124433755874634
Epoch 46 train loss: 1.6582, eval loss 1.812280297279358
Epoch 47 train loss: 1.6633, eval loss 1.8109116554260254
Epoch 48 train loss: 1.6798, eval loss 1.8115030527114868
Epoch 49 train loss: 1.7271, eval loss 1.8105055093765259
Epoch 50 train loss: 1.7041, eval loss 1.8092846870422363
Epoch 51 train loss: 1.6489, eval loss 1.809189796447754
Epoch 52 train loss: 1.6601, eval loss 1.809153437614441
Epoch 53 train loss: 1.7112, eval loss 1.808767557144165
Epoch 54 train loss: 1.6937, eval loss 1.8076329231262207
Epoch 55 train loss: 1.6857, eval loss 1.807673454284668
Epoch 56 train loss: 1.6358, eval loss 1.8063441514968872
Epoch 57 train loss: 1.6683, eval loss 1.8063786029815674
Epoch 58 train loss: 1.6762, eval loss 1.8063485622406006
Epoch 59 train loss: 1.6425, eval loss 1.8053815364837646
Epoch 60 train loss: 1.6665, eval loss 1.805729627609253
Epoch 61 train loss: 1.6527, eval loss 1.80384361743927
Epoch 62 train loss: 1.6370, eval loss 1.8043309450149536
Epoch 63 train loss: 1.6579, eval loss 1.803719162940979
Epoch 64 train loss: 1.6908, eval loss 1.802383303642273
Epoch 65 train loss: 1.6932, eval loss 1.801801323890686
Epoch 66 train loss: 1.6110, eval loss 1.800713062286377
Epoch 67 train loss: 1.6243, eval loss 1.8014951944351196
Epoch 68 train loss: 1.6458, eval loss 1.8009459972381592
Epoch 69 train loss: 1.6822, eval loss 1.8000388145446777
Epoch 70 train loss: 1.6324, eval loss 1.7999383211135864
Epoch 71 train loss: 1.6243, eval loss 1.7986526489257812
Epoch 72 train loss: 1.6115, eval loss 1.7984062433242798
Epoch 73 train loss: 1.6172, eval loss 1.7983282804489136
Epoch 74 train loss: 1.6856, eval loss 1.7977310419082642
Epoch 75 train loss: 1.6169, eval loss 1.7976120710372925
Epoch 76 train loss: 1.6158, eval loss 1.7967288494110107
Epoch 77 train loss: 1.6945, eval loss 1.7967787981033325
Epoch 78 train loss: 1.6227, eval loss 1.7961829900741577
Epoch 79 train loss: 1.6227, eval loss 1.794419765472412
Epoch 80 train loss: 1.6243, eval loss 1.7950119972229004
Epoch 81 train loss: 1.6323, eval loss 1.7937490940093994
Epoch 82 train loss: 1.6714, eval loss 1.7933928966522217
Epoch 83 train loss: 1.6223, eval loss 1.7937084436416626
Epoch 84 train loss: 1.6148, eval loss 1.793218970298767
Epoch 85 train loss: 1.5772, eval loss 1.7920958995819092
Epoch 86 train loss: 1.6310, eval loss 1.7913777828216553
Epoch 87 train loss: 1.6289, eval loss 1.7917646169662476
Epoch 88 train loss: 1.6061, eval loss 1.7910654544830322
Epoch 89 train loss: 1.6146, eval loss 1.789476752281189
Epoch 90 train loss: 1.6391, eval loss 1.7903623580932617
Epoch 91 train loss: 1.5577, eval loss 1.7894744873046875
Epoch 92 train loss: 1.5675, eval loss 1.7885305881500244
Epoch 93 train loss: 1.5840, eval loss 1.7874329090118408
Epoch 94 train loss: 1.5422, eval loss 1.7877241373062134
Epoch 95 train loss: 1.6290, eval loss 1.7870521545410156
Epoch 96 train loss: 1.6384, eval loss 1.7872459888458252
Epoch 97 train loss: 1.5651, eval loss 1.7866743803024292
Epoch 98 train loss: 1.5831, eval loss 1.7854722738265991
Epoch 99 train loss: 1.6093, eval loss 1.7859549522399902
Epoch 100 train loss: 1.6146, eval loss 1.7847747802734375
Epoch 101 train loss: 1.5746, eval loss 1.7844181060791016
Epoch 102 train loss: 1.5637, eval loss 1.7844030857086182
Epoch 103 train loss: 1.5635, eval loss 1.7847076654434204
Epoch 104 train loss: 1.5962, eval loss 1.7840512990951538
Epoch 105 train loss: 1.5279, eval loss 1.7824397087097168
Epoch 106 train loss: 1.5668, eval loss 1.7825682163238525
Epoch 107 train loss: 1.6233, eval loss 1.7812856435775757
Epoch 108 train loss: 1.5954, eval loss 1.7815934419631958
Epoch 109 train loss: 1.5504, eval loss 1.7799521684646606
Epoch 110 train loss: 1.5518, eval loss 1.7803772687911987
Epoch 111 train loss: 1.6174, eval loss 1.7799423933029175
Epoch 112 train loss: 1.5681, eval loss 1.7788307666778564
Epoch 113 train loss: 1.5913, eval loss 1.7793382406234741
Epoch 114 train loss: 1.5472, eval loss 1.7774096727371216
Epoch 115 train loss: 1.5673, eval loss 1.778714656829834
Epoch 116 train loss: 1.5131, eval loss 1.7775517702102661
Epoch 117 train loss: 1.5709, eval loss 1.7763144969940186
Epoch 118 train loss: 1.5419, eval loss 1.7769920825958252
Epoch 119 train loss: 1.5584, eval loss 1.776490330696106
Epoch 120 train loss: 1.5631, eval loss 1.775578498840332
Epoch 121 train loss: 1.5606, eval loss 1.7749913930892944
Epoch 122 train loss: 1.5474, eval loss 1.77384614944458
Epoch 123 train loss: 1.5775, eval loss 1.7740747928619385
Epoch 124 train loss: 1.5027, eval loss 1.774293303489685
Epoch 125 train loss: 1.5569, eval loss 1.7742143869400024
Epoch 126 train loss: 1.5613, eval loss 1.772764801979065
Epoch 127 train loss: 1.4835, eval loss 1.7726337909698486
Epoch 128 train loss: 1.5418, eval loss 1.772838830947876
Epoch 129 train loss: 1.5361, eval loss 1.7724931240081787
Epoch 130 train loss: 1.5050, eval loss 1.7717162370681763
Epoch 131 train loss: 1.5009, eval loss 1.7712922096252441
Epoch 132 train loss: 1.5121, eval loss 1.7708088159561157
Epoch 133 train loss: 1.5349, eval loss 1.7703909873962402
Epoch 134 train loss: 1.5211, eval loss 1.7705432176589966
Epoch 135 train loss: 1.5245, eval loss 1.7696729898452759
Epoch 136 train loss: 1.5414, eval loss 1.769102931022644
Epoch 137 train loss: 1.5210, eval loss 1.768677830696106
Epoch 138 train loss: 1.5424, eval loss 1.768642544746399
Epoch 139 train loss: 1.5574, eval loss 1.7667303085327148
Epoch 140 train loss: 1.5460, eval loss 1.7669581174850464
Epoch 141 train loss: 1.5032, eval loss 1.767021656036377
Epoch 142 train loss: 1.4669, eval loss 1.765872597694397
Epoch 143 train loss: 1.4595, eval loss 1.7657134532928467
Epoch 144 train loss: 1.4562, eval loss 1.7644996643066406
Epoch 145 train loss: 1.5081, eval loss 1.7650760412216187
Epoch 146 train loss: 1.5227, eval loss 1.7635375261306763
Epoch 147 train loss: 1.5396, eval loss 1.7642717361450195
Epoch 148 train loss: 1.5452, eval loss 1.7629363536834717
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-11-27 12:12:40,012] Trial 29 finished with value: 1.7629363536834717 and parameters: {&#39;hidden_layers_size&#39;: 56, &#39;dropout_p&#39;: 0.3454320083249626, &#39;learning_rate&#39;: 1.3472851063516434e-06, &#39;batch_size&#39;: 328, &#39;l2_reg&#39;: 0.0002133217242908211}. Best is trial 29 with value: 1.7629363536834717.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 149 train loss: 1.4796, eval loss 1.7639915943145752
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[169]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trial_random</span> <span class="o">=</span> <span class="n">study_random</span><span class="o">.</span><span class="n">best_trial</span>

<span class="n">trial_random</span><span class="o">.</span><span class="n">params</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[169]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;hidden_layers_size&#39;: 56,
 &#39;dropout_p&#39;: 0.3454320083249626,
 &#39;learning_rate&#39;: 1.3472851063516434e-06,
 &#39;batch_size&#39;: 328,
 &#39;l2_reg&#39;: 0.0002133217242908211}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[170]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_random</span><span class="p">,</span> <span class="n">test_metrics</span> <span class="o">=</span> <span class="n">get_model_stats</span><span class="p">(</span><span class="n">trial_random</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"===================================="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"AUROC: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'AUROC'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"F1: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'F1-score'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'precision'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Recall: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">test_metrics</span><span class="p">[</span><span class="s1">'recall'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 0 train loss: 1.5234, eval loss 1.7752177715301514
Epoch 1 train loss: 1.4828, eval loss 1.7721816301345825
Epoch 2 train loss: 1.4684, eval loss 1.7726083993911743
Epoch 3 train loss: 1.4572, eval loss 1.7713658809661865
Epoch 4 train loss: 1.4982, eval loss 1.771571159362793
Epoch 5 train loss: 1.5056, eval loss 1.770401954650879
Epoch 6 train loss: 1.4066, eval loss 1.7702879905700684
Epoch 7 train loss: 1.4497, eval loss 1.7689074277877808
Epoch 8 train loss: 1.4960, eval loss 1.7686022520065308
Epoch 9 train loss: 1.4309, eval loss 1.7688196897506714
Epoch 10 train loss: 1.4651, eval loss 1.7683310508728027
Epoch 11 train loss: 1.4655, eval loss 1.7678643465042114
Epoch 12 train loss: 1.4323, eval loss 1.7667655944824219
Epoch 13 train loss: 1.4661, eval loss 1.7670286893844604
Epoch 14 train loss: 1.3735, eval loss 1.7656943798065186
Epoch 15 train loss: 1.4271, eval loss 1.7652122974395752
Epoch 16 train loss: 1.4654, eval loss 1.7640377283096313
Epoch 17 train loss: 1.4586, eval loss 1.763957142829895
Epoch 18 train loss: 1.4264, eval loss 1.762635350227356
Epoch 19 train loss: 1.4221, eval loss 1.7610281705856323
Epoch 20 train loss: 1.4485, eval loss 1.7609045505523682
Epoch 21 train loss: 1.4302, eval loss 1.7596080303192139
Epoch 22 train loss: 1.4636, eval loss 1.7605916261672974
Epoch 23 train loss: 1.3965, eval loss 1.759772539138794
Epoch 24 train loss: 1.3997, eval loss 1.7591346502304077
Epoch 25 train loss: 1.4104, eval loss 1.7586417198181152
Epoch 26 train loss: 1.4086, eval loss 1.756998062133789
Epoch 27 train loss: 1.4753, eval loss 1.7571126222610474
Epoch 28 train loss: 1.4424, eval loss 1.756380319595337
Epoch 29 train loss: 1.4141, eval loss 1.754570484161377
Epoch 30 train loss: 1.3869, eval loss 1.7559396028518677
Epoch 31 train loss: 1.4076, eval loss 1.7550626993179321
Epoch 32 train loss: 1.4194, eval loss 1.7541115283966064
Epoch 33 train loss: 1.3324, eval loss 1.7534199953079224
Epoch 34 train loss: 1.4279, eval loss 1.7539253234863281
Epoch 35 train loss: 1.3845, eval loss 1.751582145690918
Epoch 36 train loss: 1.4249, eval loss 1.7518678903579712
Epoch 37 train loss: 1.4115, eval loss 1.751571536064148
Epoch 38 train loss: 1.3253, eval loss 1.7502799034118652
Epoch 39 train loss: 1.3786, eval loss 1.7492566108703613
Epoch 40 train loss: 1.3578, eval loss 1.7503008842468262
Epoch 41 train loss: 1.3820, eval loss 1.7492573261260986
Epoch 42 train loss: 1.3509, eval loss 1.749833345413208
Epoch 43 train loss: 1.4147, eval loss 1.7479649782180786
Epoch 44 train loss: 1.4127, eval loss 1.7474602460861206
Epoch 45 train loss: 1.4127, eval loss 1.747550368309021
Epoch 46 train loss: 1.4000, eval loss 1.7468470335006714
Epoch 47 train loss: 1.4182, eval loss 1.7458488941192627
Epoch 48 train loss: 1.4019, eval loss 1.7451850175857544
Epoch 49 train loss: 1.3591, eval loss 1.745029091835022
Epoch 50 train loss: 1.3900, eval loss 1.7436933517456055
Epoch 51 train loss: 1.4384, eval loss 1.7436105012893677
Epoch 52 train loss: 1.4080, eval loss 1.7426146268844604
Epoch 53 train loss: 1.4084, eval loss 1.7423996925354004
Epoch 54 train loss: 1.4117, eval loss 1.7418992519378662
Epoch 55 train loss: 1.3750, eval loss 1.741796851158142
Epoch 56 train loss: 1.3890, eval loss 1.7411627769470215
Epoch 57 train loss: 1.3840, eval loss 1.7398992776870728
Epoch 58 train loss: 1.3708, eval loss 1.7384471893310547
Epoch 59 train loss: 1.3596, eval loss 1.740502953529358
Epoch 60 train loss: 1.3305, eval loss 1.7393910884857178
Epoch 61 train loss: 1.3962, eval loss 1.7374552488327026
Epoch 62 train loss: 1.3972, eval loss 1.7371798753738403
Epoch 63 train loss: 1.3143, eval loss 1.736654281616211
Epoch 64 train loss: 1.3579, eval loss 1.7371506690979004
Epoch 65 train loss: 1.3299, eval loss 1.7357773780822754
Epoch 66 train loss: 1.3793, eval loss 1.7343730926513672
Epoch 67 train loss: 1.3646, eval loss 1.7347381114959717
Epoch 68 train loss: 1.3623, eval loss 1.7328063249588013
Epoch 69 train loss: 1.3677, eval loss 1.7340543270111084
Epoch 70 train loss: 1.3319, eval loss 1.7332831621170044
Epoch 71 train loss: 1.3092, eval loss 1.733762502670288
Epoch 72 train loss: 1.3088, eval loss 1.732682466506958
Epoch 73 train loss: 1.3643, eval loss 1.7318841218948364
Epoch 74 train loss: 1.3505, eval loss 1.7311255931854248
Epoch 75 train loss: 1.3360, eval loss 1.7306102514266968
Epoch 76 train loss: 1.2997, eval loss 1.7302258014678955
Epoch 77 train loss: 1.3780, eval loss 1.7298179864883423
Epoch 78 train loss: 1.2921, eval loss 1.7291889190673828
Epoch 79 train loss: 1.3105, eval loss 1.7290464639663696
Epoch 80 train loss: 1.3422, eval loss 1.7297645807266235
Epoch 81 train loss: 1.3755, eval loss 1.7265268564224243
Epoch 82 train loss: 1.2977, eval loss 1.7260942459106445
Epoch 83 train loss: 1.3284, eval loss 1.7261171340942383
Epoch 84 train loss: 1.2991, eval loss 1.726261854171753
Epoch 85 train loss: 1.2764, eval loss 1.7262545824050903
Epoch 86 train loss: 1.2782, eval loss 1.7253443002700806
Epoch 87 train loss: 1.2895, eval loss 1.7243553400039673
Epoch 88 train loss: 1.3267, eval loss 1.7237964868545532
Epoch 89 train loss: 1.3711, eval loss 1.7232937812805176
Epoch 90 train loss: 1.2772, eval loss 1.7230740785598755
Epoch 91 train loss: 1.3736, eval loss 1.722597599029541
Epoch 92 train loss: 1.2625, eval loss 1.721769094467163
Epoch 93 train loss: 1.3404, eval loss 1.721799612045288
Epoch 94 train loss: 1.2703, eval loss 1.719663381576538
Epoch 95 train loss: 1.3365, eval loss 1.7200449705123901
Epoch 96 train loss: 1.3059, eval loss 1.7197694778442383
Epoch 97 train loss: 1.3486, eval loss 1.719436764717102
Epoch 98 train loss: 1.3114, eval loss 1.7190768718719482
Epoch 99 train loss: 1.2686, eval loss 1.7186874151229858
Epoch 100 train loss: 1.3426, eval loss 1.717756986618042
Epoch 101 train loss: 1.2994, eval loss 1.7169777154922485
Epoch 102 train loss: 1.3505, eval loss 1.717178463935852
Epoch 103 train loss: 1.2985, eval loss 1.7162079811096191
Epoch 104 train loss: 1.3398, eval loss 1.7162368297576904
Epoch 105 train loss: 1.2902, eval loss 1.7150640487670898
Epoch 106 train loss: 1.2452, eval loss 1.714449167251587
Epoch 107 train loss: 1.2460, eval loss 1.715423345565796
Epoch 108 train loss: 1.2621, eval loss 1.7131683826446533
Epoch 109 train loss: 1.2993, eval loss 1.7128523588180542
Epoch 110 train loss: 1.2605, eval loss 1.713813066482544
Epoch 111 train loss: 1.3042, eval loss 1.7117496728897095
Epoch 112 train loss: 1.2359, eval loss 1.711962103843689
Epoch 113 train loss: 1.3403, eval loss 1.711441159248352
Epoch 114 train loss: 1.2686, eval loss 1.7114522457122803
Epoch 115 train loss: 1.3096, eval loss 1.7107515335083008
Epoch 116 train loss: 1.2595, eval loss 1.7100147008895874
Epoch 117 train loss: 1.2471, eval loss 1.7093435525894165
Epoch 118 train loss: 1.2415, eval loss 1.7099603414535522
Epoch 119 train loss: 1.2588, eval loss 1.7078957557678223
Epoch 120 train loss: 1.2654, eval loss 1.7081518173217773
Epoch 121 train loss: 1.2385, eval loss 1.7082672119140625
Epoch 122 train loss: 1.2767, eval loss 1.7062586545944214
Epoch 123 train loss: 1.2648, eval loss 1.7071195840835571
Epoch 124 train loss: 1.2178, eval loss 1.7065311670303345
Epoch 125 train loss: 1.2609, eval loss 1.7066353559494019
Epoch 126 train loss: 1.2635, eval loss 1.7049071788787842
Epoch 127 train loss: 1.2267, eval loss 1.704676628112793
Epoch 128 train loss: 1.2598, eval loss 1.7052903175354004
Epoch 129 train loss: 1.2697, eval loss 1.7038352489471436
Epoch 130 train loss: 1.2771, eval loss 1.7049858570098877
Epoch 131 train loss: 1.2460, eval loss 1.7023937702178955
Epoch 132 train loss: 1.2501, eval loss 1.7041945457458496
Epoch 133 train loss: 1.2531, eval loss 1.7030245065689087
Epoch 134 train loss: 1.2464, eval loss 1.702046513557434
Epoch 135 train loss: 1.2130, eval loss 1.7015236616134644
Epoch 136 train loss: 1.2533, eval loss 1.7007428407669067
Epoch 137 train loss: 1.2147, eval loss 1.7014113664627075
Epoch 138 train loss: 1.1808, eval loss 1.699170708656311
Epoch 139 train loss: 1.2160, eval loss 1.6985676288604736
Epoch 140 train loss: 1.2174, eval loss 1.7006545066833496
Epoch 141 train loss: 1.2824, eval loss 1.6993298530578613
Epoch 142 train loss: 1.2142, eval loss 1.6995733976364136
Epoch 143 train loss: 1.1908, eval loss 1.6979917287826538
Epoch 144 train loss: 1.2530, eval loss 1.6981017589569092
Epoch 145 train loss: 1.2129, eval loss 1.6981616020202637
Epoch 146 train loss: 1.2578, eval loss 1.6976449489593506
Epoch 147 train loss: 1.2413, eval loss 1.6977267265319824
Epoch 148 train loss: 1.2536, eval loss 1.6972832679748535
Epoch 149 train loss: 1.2790, eval loss 1.6961599588394165
====================================
AUROC: 83.91%
F1: 59.81%
Precision: 54.20%
Recall: 66.71%
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Podsumowanie">Podsumowanie<a class="anchor-link" href="#Podsumowanie">&#182;</a></h2><p>Oba treningi zostaly przeprowadzone dla max 150 epok. Poniżej znajduje się porównanie wyniku obu samplerów (<code>TPESampler</code> oraz <code>RandomSampler</code>)</p>
<table>
    <thead>
        <tr>
            <td><strong>Wskaźnik</strong></td>
            <td><strong>TPE</strong></td>
            <td><strong>Random</strong></td>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>AUROC</td>
            <td>80.45%</td>
            <td>83.91%</td>
        </tr>
        <tr>
            <td>F1</td>
            <td>56.22%</td>
            <td>59.81%</td>
        </tr>
        <tr>
            <td>Precision</td>
            <td>44.62%</td>
            <td>54.20%</td>
        </tr>
        <tr>
            <td>Recall</td>        
            <td>75.96%</td>
            <td>66.71%</td>
        </tr>
        <tr>
            <td colspan="3">
                <center><strong>Otrzymane parametry</strong></center>
            </td>
        </tr>
        <tr>
            <td>rozmiar warstw ukrytych (N)</td>
            <td>87</td>
            <td>56</td>
        </tr>
        <tr>
            <td>prawdopodobieństwo dropoutu</td>
            <td>0.489907983890005</td>
            <td>0.3454320083249626</td>
        </tr>
        <tr>
            <td>stała ucząca</td>
            <td>1.5461728272636294e-06</td>
            <td>1.3472851063516434e-06</td>
        </tr>
        <tr>
            <td>batch_size</td>
            <td>217</td>
            <td>328</td>
        </tr>
        <tr>
            <td>siła regularyzacji L2</td>
            <td>3.202440992612983e-05</td>
            <td>0.0002133217242908211</td>
        </tr>
    </tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Jak możemy zauważyć, w naszym teście lepiej wypadł RandomSampler. Pomimo mniejszego rozmiaru warstw ukrytych, udało mu się osiągnąć większy AUROC(83.91% vs 80.45%). Posiadał jednocześnie większy batch_size oraz lepszy wskaźnik F1.</p>
<p>Model wyuczony z wykorzystaniem TPE posiadał natomiast lepszą czułość oraz wymagał mniejszej regularyzacji.</p>

</div>
</div>
</div>
</div>
</body>







</html>
